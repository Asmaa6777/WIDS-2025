{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82aaa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pathlib import Path\n",
    "from scipy.stats import hmean\n",
    "import scipy\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be44016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just drop the path of your new data directory nothing more than that. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "path = r'C:\\Users\\Family\\Downloads\\widsdatathon2025 (3)'\n",
    "\n",
    "def read_data(base_path:str) -> pd.DataFrame :\n",
    "    path = Path(base_path)\n",
    "    trc=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    trq=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    trf=pd.read_csv(path   /'TRAIN_NEW'  / 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    trs=pd.read_excel(path /'TRAIN_NEW'  / 'TRAINING_SOLUTIONS.xlsx')  \n",
    "    tsc=pd.read_excel(path /'TEST'      / 'TEST_CATEGORICAL.xlsx')\n",
    "    tsq=pd.read_excel(path /'TEST'       / 'TEST_QUANTITATIVE_METADATA.xlsx')    \n",
    "    tsf=pd.read_csv(path   /'TEST'       / 'TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')    \n",
    "    sub=pd.read_excel(path / 'SAMPLE_SUBMISSION.xlsx')    \n",
    "    dic=pd.read_excel(path /'Data Dictionary.xlsx')\n",
    "    return trc, trq, trf, trs, tsc, tsq, tsf, sub, dic\n",
    "\n",
    "trc, trq, trf, trs, tsc, tsq, tsf, sub, dic = read_data(base_path=path)\n",
    "\n",
    "# Data Merging \n",
    "cq = pd.merge(trc, trq, on='participant_id', how='left')\n",
    "feat = pd.merge(cq, trf, on='participant_id', how='left')  \n",
    "qc = pd.merge(tsc, tsq, on='participant_id', how='left')\n",
    "train = pd.merge(feat, trs, on='participant_id', how='left') \n",
    "test = pd.merge(qc, tsf, on='participant_id', how='left')\n",
    "train_sex =train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b192f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = train['participant_id']\n",
    "test_ids = test['participant_id'] # I will store them for later usage in grouping in validation why?  I don't want the same user to appear in both train and test. \n",
    "num_feats = trq # numerical features\n",
    "cat_feats = trc # seperate categorical and numerical features help me reteriving them later easily for preprocessing.\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "groups = train_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753cbc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.220e+00, tolerance: 4.923e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.402e+00, tolerance: 5.646e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.501e+00, tolerance: 9.479e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.705368523078505, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.64947708428372, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.45652162254555, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.25303920154693, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.18342166085495, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 57.705368523078505, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 63.64947708428372, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 70.45652162254555, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.25303920154693, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.18342166085495, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.452079902461264, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.975659622461535, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.29784536501393, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.53646806970937, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56.452079902461264, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61.975659622461535, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68.29784536501393, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.53646806970937, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.38507271686103, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.38368596072542, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.25161778798793, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.1165836713626, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59.38507271686103, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.38368596072542, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 72.25161778798793, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 80.1165836713626, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.458702997420914, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.34644913248485, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.08736002753722, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.80683661869261, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 58.458702997420914, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64.34644913248485, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71.08736002753722, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:681: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.80683661869261, tolerance: 54.62246194279837\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+00, tolerance: 1.063e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.191e-01, tolerance: 1.249e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.220e+00, tolerance: 2.173e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train has 25 features/columns with missing values: ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'MRI_Track_Age_at_Scan']\n",
    "Test  has 23 features/columns with missing values: ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial']\n",
    "fMRI has no missing values\n",
    "Extra columns in train: ['MRI_Track_Age_at_Scan', 'MRI_Track_Scan_Location']\n",
    "'''\n",
    "\n",
    "# Find columns with missing values only\n",
    "train_missing_features_to_impute = train.columns[train.isnull().any()].tolist() # List of features with missing values in train, only 25 and no missing data in fMRI data\n",
    "test_missing_features_to_impute = test.columns[test.isnull().any()].tolist() # List of features with missing values in test, only 23 and no missing data in fMRI data\n",
    "\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = IterativeImputer(estimator=LassoCV(random_state=42), max_iter=5, random_state=42)\n",
    "\n",
    "# Impute in-place for train\n",
    "if train_missing_features_to_impute:\n",
    "\ttrain[train_missing_features_to_impute] = imputer.fit_transform(train[train_missing_features_to_impute])\n",
    "\n",
    "# Impute in-place for test\n",
    "if test_missing_features_to_impute:\n",
    "\ttest[test_missing_features_to_impute] = imputer.fit_transform(test[test_missing_features_to_impute])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd45b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum() # Check if there are any missing values left in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a82c5318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Basic_Demos_Enroll_Year</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>...</th>\n",
       "      <th>195throw_198thcolumn</th>\n",
       "      <th>195throw_199thcolumn</th>\n",
       "      <th>196throw_197thcolumn</th>\n",
       "      <th>196throw_198thcolumn</th>\n",
       "      <th>196throw_199thcolumn</th>\n",
       "      <th>197throw_198thcolumn</th>\n",
       "      <th>197throw_199thcolumn</th>\n",
       "      <th>198throw_199thcolumn</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00aIpNTbG5uh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.903324</td>\n",
       "      <td>32.871543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280312</td>\n",
       "      <td>0.037560</td>\n",
       "      <td>0.423037</td>\n",
       "      <td>0.242453</td>\n",
       "      <td>0.336213</td>\n",
       "      <td>0.402338</td>\n",
       "      <td>0.327915</td>\n",
       "      <td>0.539032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00fV0OyyoLfw</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332783</td>\n",
       "      <td>-0.332711</td>\n",
       "      <td>0.556939</td>\n",
       "      <td>0.475578</td>\n",
       "      <td>0.429196</td>\n",
       "      <td>0.457970</td>\n",
       "      <td>0.312571</td>\n",
       "      <td>0.595978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04X1eiS79T4B</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.387745</td>\n",
       "      <td>17.897575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>-0.175586</td>\n",
       "      <td>0.679183</td>\n",
       "      <td>0.290292</td>\n",
       "      <td>0.486680</td>\n",
       "      <td>0.255208</td>\n",
       "      <td>0.575017</td>\n",
       "      <td>0.605182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05ocQutkURd6</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199576</td>\n",
       "      <td>-0.216457</td>\n",
       "      <td>0.519074</td>\n",
       "      <td>0.298586</td>\n",
       "      <td>0.415466</td>\n",
       "      <td>0.511607</td>\n",
       "      <td>0.361204</td>\n",
       "      <td>0.446613</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06YUNBA9ZRLq</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845904</td>\n",
       "      <td>22.432518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.141012</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>0.515169</td>\n",
       "      <td>0.336139</td>\n",
       "      <td>0.316430</td>\n",
       "      <td>0.442230</td>\n",
       "      <td>0.177079</td>\n",
       "      <td>0.378278</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>zwjJWCRzKhDz</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.136452</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.112789</td>\n",
       "      <td>0.211312</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.587116</td>\n",
       "      <td>0.312695</td>\n",
       "      <td>0.485938</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.354333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>zwXD5v17Rx01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.253990</td>\n",
       "      <td>0.198741</td>\n",
       "      <td>0.648260</td>\n",
       "      <td>0.055241</td>\n",
       "      <td>0.491985</td>\n",
       "      <td>0.118676</td>\n",
       "      <td>0.404331</td>\n",
       "      <td>0.537121</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>zWzLCi3NTBTd</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044653</td>\n",
       "      <td>0.234887</td>\n",
       "      <td>0.538475</td>\n",
       "      <td>0.024265</td>\n",
       "      <td>0.472322</td>\n",
       "      <td>0.095624</td>\n",
       "      <td>0.205326</td>\n",
       "      <td>0.182633</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Zy9GTHDxUbXU</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035955</td>\n",
       "      <td>-0.062152</td>\n",
       "      <td>0.706214</td>\n",
       "      <td>0.183288</td>\n",
       "      <td>0.104987</td>\n",
       "      <td>0.420463</td>\n",
       "      <td>0.152727</td>\n",
       "      <td>0.706737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Zye7yYRQohXi</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180668</td>\n",
       "      <td>-0.228028</td>\n",
       "      <td>0.608149</td>\n",
       "      <td>0.116950</td>\n",
       "      <td>0.264398</td>\n",
       "      <td>0.559703</td>\n",
       "      <td>0.351096</td>\n",
       "      <td>0.301253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows  19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
       "0      00aIpNTbG5uh                     2019                       4   \n",
       "1      00fV0OyyoLfw                     2017                       1   \n",
       "2      04X1eiS79T4B                     2017                       1   \n",
       "3      05ocQutkURd6                     2018                       1   \n",
       "4      06YUNBA9ZRLq                     2018                       1   \n",
       "...             ...                      ...                     ...   \n",
       "1208   zwjJWCRzKhDz                     2019                       4   \n",
       "1209   zwXD5v17Rx01                     2018                       1   \n",
       "1210   zWzLCi3NTBTd                     2018                       3   \n",
       "1211   Zy9GTHDxUbXU                     2019                       4   \n",
       "1212   Zye7yYRQohXi                     2017                       1   \n",
       "\n",
       "      PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                                  1.0                          0.0   \n",
       "1                                  0.0                          9.0   \n",
       "2                                  1.0                          2.0   \n",
       "3                                  3.0                          8.0   \n",
       "4                                  0.0                          1.0   \n",
       "...                                ...                          ...   \n",
       "1208                               1.0                          1.0   \n",
       "1209                               0.0                          0.0   \n",
       "1210                               2.0                          3.0   \n",
       "1211                               0.0                          1.0   \n",
       "1212                               0.0                          0.0   \n",
       "\n",
       "      MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                         3.0                    21.0               45.000000   \n",
       "1                         2.0                    21.0                0.000000   \n",
       "2                         2.0                     9.0                0.000000   \n",
       "3                         2.0                    18.0               10.000000   \n",
       "4                         2.0                    12.0                0.000000   \n",
       "...                       ...                     ...                     ...   \n",
       "1208                      3.0                    12.0               15.136452   \n",
       "1209                      3.0                    21.0               40.000000   \n",
       "1210                      3.0                    21.0               40.000000   \n",
       "1211                      3.0                    18.0               35.000000   \n",
       "1212                      2.0                    18.0               35.000000   \n",
       "\n",
       "      Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  ...  \\\n",
       "0                  17.903324               32.871543  ...   \n",
       "1                  21.000000               45.000000  ...   \n",
       "2                  12.387745               17.897575  ...   \n",
       "3                  18.000000                0.000000  ...   \n",
       "4                  13.845904               22.432518  ...   \n",
       "...                      ...                     ...  ...   \n",
       "1208               15.000000                5.000000  ...   \n",
       "1209               21.000000               40.000000  ...   \n",
       "1210               21.000000               35.000000  ...   \n",
       "1211               18.000000               45.000000  ...   \n",
       "1212               15.000000               35.000000  ...   \n",
       "\n",
       "      195throw_198thcolumn  195throw_199thcolumn  196throw_197thcolumn  \\\n",
       "0                -0.280312              0.037560              0.423037   \n",
       "1                -0.332783             -0.332711              0.556939   \n",
       "2                -0.002132             -0.175586              0.679183   \n",
       "3                -0.199576             -0.216457              0.519074   \n",
       "4                -0.141012             -0.002865              0.515169   \n",
       "...                    ...                   ...                   ...   \n",
       "1208              0.112789              0.211312              0.601190   \n",
       "1209              0.253990              0.198741              0.648260   \n",
       "1210              0.044653              0.234887              0.538475   \n",
       "1211             -0.035955             -0.062152              0.706214   \n",
       "1212             -0.180668             -0.228028              0.608149   \n",
       "\n",
       "      196throw_198thcolumn  196throw_199thcolumn  197throw_198thcolumn  \\\n",
       "0                 0.242453              0.336213              0.402338   \n",
       "1                 0.475578              0.429196              0.457970   \n",
       "2                 0.290292              0.486680              0.255208   \n",
       "3                 0.298586              0.415466              0.511607   \n",
       "4                 0.336139              0.316430              0.442230   \n",
       "...                    ...                   ...                   ...   \n",
       "1208              0.587116              0.312695              0.485938   \n",
       "1209              0.055241              0.491985              0.118676   \n",
       "1210              0.024265              0.472322              0.095624   \n",
       "1211              0.183288              0.104987              0.420463   \n",
       "1212              0.116950              0.264398              0.559703   \n",
       "\n",
       "      197throw_199thcolumn  198throw_199thcolumn  ADHD_Outcome  Sex_F  \n",
       "0                 0.327915              0.539032             1      0  \n",
       "1                 0.312571              0.595978             1      0  \n",
       "2                 0.575017              0.605182             0      1  \n",
       "3                 0.361204              0.446613             0      1  \n",
       "4                 0.177079              0.378278             1      0  \n",
       "...                    ...                   ...           ...    ...  \n",
       "1208              0.189102              0.354333             0      1  \n",
       "1209              0.404331              0.537121             1      0  \n",
       "1210              0.205326              0.182633             1      1  \n",
       "1211              0.152727              0.706737             1      0  \n",
       "1212              0.351096              0.301253             0      1  \n",
       "\n",
       "[1213 rows x 19930 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1565edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Convert all categorical features to strings (to avoid mixed types)\\nfor feature in trc.columns:\\n    train[feature] = train[feature].astype(object)\\nfor feature in cat_feats:\\n    train[feature] = train[feature].astype(str)\\n    test[feature] = test[feature].astype(str)\\n\\n# One-Hot Encoding for categorical features\\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\\n\\nfor feature in cat_feats:\\n    if feature not in train.columns or feature not in test.columns:  # Skip if the feature is missing\\n        continue\\n\\n    # Apply OneHotEncoder\\n    train_encoded = encoder.fit_transform(train[[feature]])\\n    test_encoded = encoder.transform(test[[feature]])\\n\\n    # Convert encoded features to DataFrame and append them to the original data\\n    train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out([feature]))\\n    test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out([feature]))\\n\\n    # Drop the original feature and concatenate the new encoded columns\\n    train = pd.concat([train.drop(columns=[feature]), train_encoded_df], axis=1)\\n    test = pd.concat([test.drop(columns=[feature]), test_encoded_df], axis=1)\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Convert all categorical features to strings (to avoid mixed types)\n",
    "for feature in trc.columns:\n",
    "    train[feature] = train[feature].astype(object)\n",
    "for feature in cat_feats:\n",
    "    train[feature] = train[feature].astype(str)\n",
    "    test[feature] = test[feature].astype(str)\n",
    "\n",
    "# One-Hot Encoding for categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "for feature in cat_feats:\n",
    "    if feature not in train.columns or feature not in test.columns:  # Skip if the feature is missing\n",
    "        continue\n",
    "\n",
    "    # Apply OneHotEncoder\n",
    "    train_encoded = encoder.fit_transform(train[[feature]])\n",
    "    test_encoded = encoder.transform(test[[feature]])\n",
    "\n",
    "    # Convert encoded features to DataFrame and append them to the original data\n",
    "    train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "    test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "\n",
    "    # Drop the original feature and concatenate the new encoded columns\n",
    "    train = pd.concat([train.drop(columns=[feature]), train_encoded_df], axis=1)\n",
    "    test = pd.concat([test.drop(columns=[feature]), test_encoded_df], axis=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b830fbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Only apply scaling to numerical columns that are not part of the target or categorical features\n",
    "numerical_features = [col for col in train.columns if col not in target_cols and col not in cat_feats]\n",
    "\n",
    "# Fit scaler on the numerical features of the train set and transform train and test sets\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])  # Fit and transform for train set\n",
    "test[numerical_features] = scaler.transform(test[numerical_features]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c42e66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum() # Check if there are any missing values left in train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83eea20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sex = train['Sex_F']  \n",
    "y_adhd = train['ADHD_Outcome']  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ef369c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2568f463",
   "metadata": {},
   "source": [
    "# feature importance in sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e59f066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>Basic_Demos_Enroll_Year</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>...</th>\n",
       "      <th>195throw_198thcolumn</th>\n",
       "      <th>195throw_199thcolumn</th>\n",
       "      <th>196throw_197thcolumn</th>\n",
       "      <th>196throw_198thcolumn</th>\n",
       "      <th>196throw_199thcolumn</th>\n",
       "      <th>197throw_198thcolumn</th>\n",
       "      <th>197throw_199thcolumn</th>\n",
       "      <th>198throw_199thcolumn</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00aIpNTbG5uh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.903324</td>\n",
       "      <td>32.871543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.185011</td>\n",
       "      <td>0.141726</td>\n",
       "      <td>-0.890926</td>\n",
       "      <td>-0.677929</td>\n",
       "      <td>-0.180457</td>\n",
       "      <td>-0.554190</td>\n",
       "      <td>-0.835889</td>\n",
       "      <td>-0.024380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00fV0OyyoLfw</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.441008</td>\n",
       "      <td>-1.721379</td>\n",
       "      <td>-0.001464</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>-0.239836</td>\n",
       "      <td>-0.922257</td>\n",
       "      <td>0.310269</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04X1eiS79T4B</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.387745</td>\n",
       "      <td>17.897575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172175</td>\n",
       "      <td>-0.930766</td>\n",
       "      <td>0.810557</td>\n",
       "      <td>-0.436211</td>\n",
       "      <td>0.606624</td>\n",
       "      <td>-1.385552</td>\n",
       "      <td>0.554995</td>\n",
       "      <td>0.364357</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05ocQutkURd6</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.791115</td>\n",
       "      <td>-1.136420</td>\n",
       "      <td>-0.252985</td>\n",
       "      <td>-0.394303</td>\n",
       "      <td>0.234110</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>-0.648517</td>\n",
       "      <td>-0.567490</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06YUNBA9ZRLq</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845904</td>\n",
       "      <td>22.432518</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505395</td>\n",
       "      <td>-0.061681</td>\n",
       "      <td>-0.278927</td>\n",
       "      <td>-0.204557</td>\n",
       "      <td>-0.283942</td>\n",
       "      <td>-0.328775</td>\n",
       "      <td>-1.684912</td>\n",
       "      <td>-0.969062</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>zwjJWCRzKhDz</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.136452</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.732856</td>\n",
       "      <td>1.016003</td>\n",
       "      <td>0.292482</td>\n",
       "      <td>1.063558</td>\n",
       "      <td>-0.303480</td>\n",
       "      <td>-0.081801</td>\n",
       "      <td>-1.617241</td>\n",
       "      <td>-1.109779</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>zwXD5v17Rx01</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.421749</td>\n",
       "      <td>0.952747</td>\n",
       "      <td>0.605150</td>\n",
       "      <td>-1.623857</td>\n",
       "      <td>0.634374</td>\n",
       "      <td>-2.157031</td>\n",
       "      <td>-0.405763</td>\n",
       "      <td>-0.035614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>zWzLCi3NTBTd</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400430</td>\n",
       "      <td>1.134626</td>\n",
       "      <td>-0.124110</td>\n",
       "      <td>-1.780372</td>\n",
       "      <td>0.531519</td>\n",
       "      <td>-2.287286</td>\n",
       "      <td>-1.525919</td>\n",
       "      <td>-2.118786</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Zy9GTHDxUbXU</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>-0.359999</td>\n",
       "      <td>0.990114</td>\n",
       "      <td>-0.976870</td>\n",
       "      <td>-1.389992</td>\n",
       "      <td>-0.451771</td>\n",
       "      <td>-1.821987</td>\n",
       "      <td>0.961151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>Zye7yYRQohXi</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.698867</td>\n",
       "      <td>-1.194641</td>\n",
       "      <td>0.338708</td>\n",
       "      <td>-1.312060</td>\n",
       "      <td>-0.556121</td>\n",
       "      <td>0.335012</td>\n",
       "      <td>-0.705410</td>\n",
       "      <td>-1.421709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows  19930 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     participant_id  Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
       "0      00aIpNTbG5uh                     2019                       4   \n",
       "1      00fV0OyyoLfw                     2017                       1   \n",
       "2      04X1eiS79T4B                     2017                       1   \n",
       "3      05ocQutkURd6                     2018                       1   \n",
       "4      06YUNBA9ZRLq                     2018                       1   \n",
       "...             ...                      ...                     ...   \n",
       "1208   zwjJWCRzKhDz                     2019                       4   \n",
       "1209   zwXD5v17Rx01                     2018                       1   \n",
       "1210   zWzLCi3NTBTd                     2018                       3   \n",
       "1211   Zy9GTHDxUbXU                     2019                       4   \n",
       "1212   Zye7yYRQohXi                     2017                       1   \n",
       "\n",
       "      PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                                  1.0                          0.0   \n",
       "1                                  0.0                          9.0   \n",
       "2                                  1.0                          2.0   \n",
       "3                                  3.0                          8.0   \n",
       "4                                  0.0                          1.0   \n",
       "...                                ...                          ...   \n",
       "1208                               1.0                          1.0   \n",
       "1209                               0.0                          0.0   \n",
       "1210                               2.0                          3.0   \n",
       "1211                               0.0                          1.0   \n",
       "1212                               0.0                          0.0   \n",
       "\n",
       "      MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                         3.0                    21.0               45.000000   \n",
       "1                         2.0                    21.0                0.000000   \n",
       "2                         2.0                     9.0                0.000000   \n",
       "3                         2.0                    18.0               10.000000   \n",
       "4                         2.0                    12.0                0.000000   \n",
       "...                       ...                     ...                     ...   \n",
       "1208                      3.0                    12.0               15.136452   \n",
       "1209                      3.0                    21.0               40.000000   \n",
       "1210                      3.0                    21.0               40.000000   \n",
       "1211                      3.0                    18.0               35.000000   \n",
       "1212                      2.0                    18.0               35.000000   \n",
       "\n",
       "      Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  ...  \\\n",
       "0                  17.903324               32.871543  ...   \n",
       "1                  21.000000               45.000000  ...   \n",
       "2                  12.387745               17.897575  ...   \n",
       "3                  18.000000                0.000000  ...   \n",
       "4                  13.845904               22.432518  ...   \n",
       "...                      ...                     ...  ...   \n",
       "1208               15.000000                5.000000  ...   \n",
       "1209               21.000000               40.000000  ...   \n",
       "1210               21.000000               35.000000  ...   \n",
       "1211               18.000000               45.000000  ...   \n",
       "1212               15.000000               35.000000  ...   \n",
       "\n",
       "      195throw_198thcolumn  195throw_199thcolumn  196throw_197thcolumn  \\\n",
       "0                -1.185011              0.141726             -0.890926   \n",
       "1                -1.441008             -1.721379             -0.001464   \n",
       "2                 0.172175             -0.930766              0.810557   \n",
       "3                -0.791115             -1.136420             -0.252985   \n",
       "4                -0.505395             -0.061681             -0.278927   \n",
       "...                    ...                   ...                   ...   \n",
       "1208              0.732856              1.016003              0.292482   \n",
       "1209              1.421749              0.952747              0.605150   \n",
       "1210              0.400430              1.134626             -0.124110   \n",
       "1211              0.007159             -0.359999              0.990114   \n",
       "1212             -0.698867             -1.194641              0.338708   \n",
       "\n",
       "      196throw_198thcolumn  196throw_199thcolumn  197throw_198thcolumn  \\\n",
       "0                -0.677929             -0.180457             -0.554190   \n",
       "1                 0.499990              0.305932             -0.239836   \n",
       "2                -0.436211              0.606624             -1.385552   \n",
       "3                -0.394303              0.234110              0.063241   \n",
       "4                -0.204557             -0.283942             -0.328775   \n",
       "...                    ...                   ...                   ...   \n",
       "1208              1.063558             -0.303480             -0.081801   \n",
       "1209             -1.623857              0.634374             -2.157031   \n",
       "1210             -1.780372              0.531519             -2.287286   \n",
       "1211             -0.976870             -1.389992             -0.451771   \n",
       "1212             -1.312060             -0.556121              0.335012   \n",
       "\n",
       "      197throw_199thcolumn  198throw_199thcolumn  ADHD_Outcome  Sex_F  \n",
       "0                -0.835889             -0.024380             1      0  \n",
       "1                -0.922257              0.310269             1      0  \n",
       "2                 0.554995              0.364357             0      1  \n",
       "3                -0.648517             -0.567490             0      1  \n",
       "4                -1.684912             -0.969062             1      0  \n",
       "...                    ...                   ...           ...    ...  \n",
       "1208             -1.617241             -1.109779             0      1  \n",
       "1209             -0.405763             -0.035614             1      0  \n",
       "1210             -1.525919             -2.118786             1      1  \n",
       "1211             -1.821987              0.961151             1      0  \n",
       "1212             -0.705410             -1.421709             0      1  \n",
       "\n",
       "[1213 rows x 19930 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fd07a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 416, number of negative: 797\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.574558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5075431\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.574558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5075431\n",
      "[LightGBM] [Info] Number of data points in the train set: 1213, number of used features: 19927\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Number of data points in the train set: 1213, number of used features: 19927\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "\n",
      "Number of important features for Sex: 2310\n",
      "\n",
      "Top 10 important features for Sex prediction:\n",
      "                    Feature  Importance\n",
      "19098  158throw_191thcolumn          21\n",
      "16356  114throw_199thcolumn          15\n",
      "13249   83throw_192thcolumn          14\n",
      "17753  133throw_171thcolumn          11\n",
      "18830  152throw_184thcolumn          10\n",
      "14901   99throw_124thcolumn          10\n",
      "19896  191throw_197thcolumn           9\n",
      "19321  164throw_189thcolumn           9\n",
      "7861     44throw_69thcolumn           8\n",
      "12304    76throw_80thcolumn           8\n",
      "\n",
      "Number of important features for Sex: 2310\n",
      "\n",
      "Top 10 important features for Sex prediction:\n",
      "                    Feature  Importance\n",
      "19098  158throw_191thcolumn          21\n",
      "16356  114throw_199thcolumn          15\n",
      "13249   83throw_192thcolumn          14\n",
      "17753  133throw_171thcolumn          11\n",
      "18830  152throw_184thcolumn          10\n",
      "14901   99throw_124thcolumn          10\n",
      "19896  191throw_197thcolumn           9\n",
      "19321  164throw_189thcolumn           9\n",
      "7861     44throw_69thcolumn           8\n",
      "12304    76throw_80thcolumn           8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'train' and 'test' are your DataFrames\n",
    "# and target_cols is defined as ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Prepare features (X) - drop targets and participant_id\n",
    "X = train.drop(columns=target_cols + ['participant_id'])\n",
    "\n",
    "# Convert categorical features to dummy variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Encode target (y_sex should be your target Series)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_sex)\n",
    "\n",
    "# Initialize and fit the LGBM model for Sex prediction\n",
    "model_sex = lgb.LGBMClassifier(\n",
    "    class_weight='balanced',  # Important for imbalanced data\n",
    "    random_state=42\n",
    ")\n",
    "model_sex.fit(X, y)\n",
    "\n",
    "# Get feature importances and create a DataFrame\n",
    "importance_df_sex = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': model_sex.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Filter features with importance > 0 (or set a higher threshold)\n",
    "important_features_sex = importance_df_sex[importance_df_sex['Importance'] > 0]['Feature'].tolist()\n",
    "\n",
    "# Filter the data - ensure test has same features\n",
    "train_sex = train[important_features_sex]\n",
    "test_sex = test[important_features_sex]\n",
    "\n",
    "# Verify the filtered data\n",
    "print(f\"\\nNumber of important features for Sex: {len(important_features_sex)}\")\n",
    "print(\"\\nTop 10 important features for Sex prediction:\")\n",
    "print(importance_df_sex.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1e651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of > 0 threshold, consider:\n",
    "threshold = importance_df_sex['Importance'].quantile(0.98)  \n",
    "important_features_sex = importance_df_sex[importance_df_sex['Importance'] > threshold]['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd91125",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_sex=train[important_features_sex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a74e6beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Bag 1\n",
      "#########################\n",
      "=> Fold 1, => Fold 2, => Fold 2, => Fold 3, => Fold 3, => Fold 4, => Fold 4, => Fold 5, => Fold 5, \n",
      "Bag 1 Avg F1 - Sex: 0.7486\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, \n",
      "Bag 1 Avg F1 - Sex: 0.7486\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, => Fold 2, => Fold 2, => Fold 3, => Fold 3, => Fold 4, => Fold 4, => Fold 5, => Fold 5, \n",
      "Bag 2 Avg F1 - Sex: 0.7508\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, \n",
      "Bag 2 Avg F1 - Sex: 0.7508\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, => Fold 2, => Fold 2, => Fold 3, => Fold 3, => Fold 4, => Fold 4, => Fold 5, => Fold 5, \n",
      "Bag 3 Avg F1 - Sex: 0.7543\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, \n",
      "Bag 3 Avg F1 - Sex: 0.7543\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, => Fold 2, => Fold 2, => Fold 3, => Fold 3, => Fold 4, => Fold 4, => Fold 5, => Fold 5, \n",
      "Bag 4 Avg F1 - Sex: 0.7350\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, \n",
      "Bag 4 Avg F1 - Sex: 0.7350\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, => Fold 2, => Fold 2, => Fold 3, => Fold 3, => Fold 4, => Fold 4, => Fold 5, => Fold 5, \n",
      "Bag 5 Avg F1 - Sex: 0.7443\n",
      "\n",
      "##################################################\n",
      "Final Ensemble F1 - Sex: 0.7909\n",
      "Mean Bag F1 - Sex: 0.7466  0.0066\n",
      "\n",
      "Bag 5 Avg F1 - Sex: 0.7443\n",
      "\n",
      "##################################################\n",
      "Final Ensemble F1 - Sex: 0.7909\n",
      "Mean Bag F1 - Sex: 0.7466  0.0066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize storage\n",
    "oof_sex = np.zeros(len(important_features_sex))\n",
    "models_sep_sex = {}  # Initialize models_sep_sex as an empty dictionary\n",
    "bag_f1_sex = []\n",
    "\n",
    "BAGS = 5\n",
    "FOLDS = 5\n",
    "\n",
    "# Prepare data\n",
    "important_features_sex_filtered = important_features_sex.reset_index(drop=True)\n",
    "y_sex = y_sex.reset_index(drop=True)\n",
    "\n",
    "for bag in range(BAGS):\n",
    "    print('#'*25)\n",
    "    print(f'### Bag {bag+1}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    models_sep_sex[bag] = []\n",
    "    bag_pred_sex = np.zeros(len(important_features_sex))\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=bag*FOLDS)\n",
    "    fold_f1_sex = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X=important_features_sex_filtered, y=y_sex)):\n",
    "        print(f'=> Fold {fold+1}, ', end='')\n",
    "\n",
    "        # Dynamic class balancing\n",
    "        y_important_features_sex = y_sex.iloc[train_idx]\n",
    "        class_counts = y_important_features_sex.value_counts()\n",
    "        majority_class = class_counts.idxmax()\n",
    "        minority_class = 1 - majority_class\n",
    "        \n",
    "        majority_samples = y_important_features_sex[y_important_features_sex == majority_class]\n",
    "        minority_samples = y_important_features_sex[y_important_features_sex == minority_class]\n",
    "        \n",
    "        n_samples = len(minority_samples)\n",
    "        if len(majority_samples) < n_samples:\n",
    "            n_samples = len(majority_samples)\n",
    "        \n",
    "        downsampled_majority = majority_samples.sample(\n",
    "            n=n_samples, \n",
    "            replace=len(majority_samples) < len(minority_samples),\n",
    "            random_state=bag*BAGS+fold\n",
    "        )\n",
    "        \n",
    "        sex_train_idx = minority_samples.index.union(downsampled_majority.index)\n",
    "        X_important_features_sex = important_features_sex_filtered.iloc[sex_train_idx]\n",
    "        y_important_features_sex_balanced = y_sex.iloc[sex_train_idx]\n",
    "        X_valid_sex = important_features_sex_filtered.iloc[valid_idx]\n",
    "        y_valid_sex = y_sex.iloc[valid_idx]\n",
    "\n",
    "        # Model parameters\n",
    "        model_params = {\n",
    "            'n_estimators': 300,\n",
    "            'learning_rate': 0.175, \n",
    "            'metric': 'cross_entropy_lambda',\n",
    "            'objective': None,\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 31,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0009,\n",
    "            'early_stopping_round': 50,\n",
    "            'feature_fraction': 0.1,\n",
    "            'subsample': 0.8,\n",
    "            'verbose': -1\n",
    "        }\n",
    "\n",
    "        model_sep_sex = LGBMClassifier(**model_params)\n",
    "        model_sep_sex.fit(X_important_features_sex, y_important_features_sex_balanced,\n",
    "                          eval_set=[(X_valid_sex, y_valid_sex)])\n",
    "\n",
    "        sex_pred = model_sep_sex.predict(X_valid_sex)\n",
    "        fold_f1_sex.append(f1_score(y_valid_sex, sex_pred, average='macro'))\n",
    "        \n",
    "        bag_pred_sex[valid_idx] = model_sep_sex.predict_proba(X_valid_sex)[:, 1]\n",
    "        models_sep_sex[bag].append(model_sep_sex)\n",
    "\n",
    "    bag_avg_f1_sex = np.mean(fold_f1_sex)\n",
    "    bag_f1_sex.append(bag_avg_f1_sex)\n",
    "    print(f\"\\nBag {bag+1} Avg F1 - Sex: {bag_avg_f1_sex:.4f}\")\n",
    "    oof_sex += bag_pred_sex / BAGS\n",
    "\n",
    "# Final evaluation\n",
    "final_f1_sex = f1_score(y_sex, (oof_sex > 0.5).astype(int), average='macro')\n",
    "print('\\n' + '#'*50)\n",
    "print(f\"Final Ensemble F1 - Sex: {final_f1_sex:.4f}\")\n",
    "print(f\"Mean Bag F1 - Sex: {np.mean(bag_f1_sex):.4f}  {np.std(bag_f1_sex):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9a527a",
   "metadata": {},
   "source": [
    "# ADHD USING LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84280ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop only the columns from `trf` that are present in `train`\n",
    "columns_to_drop = [col for col in trf.columns if col in train.columns]\n",
    "train_adhd = train.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the target columns\n",
    "train_adhd = train_adhd.drop(columns=target_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541e33da",
   "metadata": {},
   "source": [
    "## LGBM WITH DOWNSAMPLING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87b4c0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Bag 1\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8013\n",
      "=> Fold 2, F1: 0.8013\n",
      "=> Fold 2, F1: 0.7682\n",
      "=> Fold 3, F1: 0.7682\n",
      "=> Fold 3, F1: 0.7810\n",
      "=> Fold 4, F1: 0.7810\n",
      "=> Fold 4, F1: 0.8037\n",
      "=> Fold 5, F1: 0.8037\n",
      "=> Fold 5, F1: 0.8287\n",
      "\n",
      "Bag 1 Avg F1: 0.7966\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8287\n",
      "\n",
      "Bag 1 Avg F1: 0.7966\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, F1: 0.7834\n",
      "=> Fold 2, F1: 0.7834\n",
      "=> Fold 2, F1: 0.8113\n",
      "=> Fold 3, F1: 0.8113\n",
      "=> Fold 3, F1: 0.7987\n",
      "=> Fold 4, F1: 0.7987\n",
      "=> Fold 4, F1: 0.7582\n",
      "=> Fold 5, F1: 0.7582\n",
      "=> Fold 5, F1: 0.8202\n",
      "\n",
      "Bag 2 Avg F1: 0.7944\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8202\n",
      "\n",
      "Bag 2 Avg F1: 0.7944\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, F1: 0.7974\n",
      "=> Fold 2, F1: 0.7974\n",
      "=> Fold 2, F1: 0.8091\n",
      "=> Fold 3, F1: 0.8091\n",
      "=> Fold 3, F1: 0.7925\n",
      "=> Fold 4, F1: 0.7925\n",
      "=> Fold 4, F1: 0.7821\n",
      "=> Fold 5, F1: 0.7821\n",
      "=> Fold 5, F1: 0.7923\n",
      "\n",
      "Bag 3 Avg F1: 0.7947\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, F1: 0.7923\n",
      "\n",
      "Bag 3 Avg F1: 0.7947\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8125\n",
      "=> Fold 2, F1: 0.8125\n",
      "=> Fold 2, F1: 0.7848\n",
      "=> Fold 3, F1: 0.7848\n",
      "=> Fold 3, F1: 0.7826\n",
      "=> Fold 4, F1: 0.7826\n",
      "=> Fold 4, F1: 0.8000\n",
      "=> Fold 5, F1: 0.8000\n",
      "=> Fold 5, F1: 0.7829\n",
      "\n",
      "Bag 4 Avg F1: 0.7926\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, F1: 0.7829\n",
      "\n",
      "Bag 4 Avg F1: 0.7926\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8115\n",
      "=> Fold 2, F1: 0.8115\n",
      "=> Fold 2, F1: 0.8103\n",
      "=> Fold 3, F1: 0.8103\n",
      "=> Fold 3, F1: 0.7821\n",
      "=> Fold 4, F1: 0.7821\n",
      "=> Fold 4, F1: 0.7821\n",
      "=> Fold 5, F1: 0.7821\n",
      "=> Fold 5, F1: 0.8131\n",
      "\n",
      "Bag 5 Avg F1: 0.7998\n",
      "\n",
      "##################################################\n",
      "==== Overall Results ===\n",
      "Mean F1: 0.7956\n",
      "F1 std: 0.0166\n",
      "\n",
      "Standard deviations of test sets:\n",
      "Fold 1: 0.4646\n",
      "Fold 2: 0.4662\n",
      "Fold 3: 0.4662\n",
      "Fold 4: 0.4651\n",
      "Fold 5: 0.4651\n",
      "Fold 6: 0.4646\n",
      "Fold 7: 0.4662\n",
      "Fold 8: 0.4662\n",
      "Fold 9: 0.4651\n",
      "Fold 10: 0.4651\n",
      "Fold 11: 0.4646\n",
      "Fold 12: 0.4662\n",
      "Fold 13: 0.4662\n",
      "Fold 14: 0.4651\n",
      "Fold 15: 0.4651\n",
      "Fold 16: 0.4646\n",
      "Fold 17: 0.4662\n",
      "Fold 18: 0.4662\n",
      "Fold 19: 0.4651\n",
      "Fold 20: 0.4651\n",
      "Fold 21: 0.4646\n",
      "Fold 22: 0.4662\n",
      "Fold 23: 0.4662\n",
      "Fold 24: 0.4651\n",
      "Fold 25: 0.4651\n",
      "\n",
      "Final OOF F1: 0.8084\n",
      "F1: 0.8131\n",
      "\n",
      "Bag 5 Avg F1: 0.7998\n",
      "\n",
      "##################################################\n",
      "==== Overall Results ===\n",
      "Mean F1: 0.7956\n",
      "F1 std: 0.0166\n",
      "\n",
      "Standard deviations of test sets:\n",
      "Fold 1: 0.4646\n",
      "Fold 2: 0.4662\n",
      "Fold 3: 0.4662\n",
      "Fold 4: 0.4651\n",
      "Fold 5: 0.4651\n",
      "Fold 6: 0.4646\n",
      "Fold 7: 0.4662\n",
      "Fold 8: 0.4662\n",
      "Fold 9: 0.4651\n",
      "Fold 10: 0.4651\n",
      "Fold 11: 0.4646\n",
      "Fold 12: 0.4662\n",
      "Fold 13: 0.4662\n",
      "Fold 14: 0.4651\n",
      "Fold 15: 0.4651\n",
      "Fold 16: 0.4646\n",
      "Fold 17: 0.4662\n",
      "Fold 18: 0.4662\n",
      "Fold 19: 0.4651\n",
      "Fold 20: 0.4651\n",
      "Fold 21: 0.4646\n",
      "Fold 22: 0.4662\n",
      "Fold 23: 0.4662\n",
      "Fold 24: 0.4651\n",
      "Fold 25: 0.4651\n",
      "\n",
      "Final OOF F1: 0.8084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Initialize storage\n",
    "oof_predictions = np.zeros(len(train))\n",
    "models = {}\n",
    "bag_f1_scores = []\n",
    "stds = []\n",
    "F1s = []\n",
    "\n",
    "BAGS = 5\n",
    "FOLDS = 5\n",
    "target_col = 'ADHD_Outcome'\n",
    "\n",
    "# Prepare data\n",
    "X = train.drop(columns=[target_col, 'participant_id', 'Sex_F'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = train[target_col]\n",
    "\n",
    "for bag in range(BAGS):\n",
    "    print('#'*25)\n",
    "    print(f'### Bag {bag+1}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    models[bag] = []\n",
    "    bag_pred = np.zeros(len(X))\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=bag*FOLDS)\n",
    "    fold_f1s = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f'=> Fold {fold}, ', end='')\n",
    "\n",
    "        # Your exact downsampling technique\n",
    "        y_train = y.iloc[train_idx]\n",
    "        class_counts = y_train.value_counts()\n",
    "        \n",
    "        if len(class_counts) > 1:\n",
    "            majority_class = class_counts.idxmax()\n",
    "            minority_class = 1 - majority_class\n",
    "            majority_samples = y_train[y_train == majority_class]\n",
    "            minority_samples = y_train[y_train == minority_class]\n",
    "            \n",
    "            n_samples = len(minority_samples)\n",
    "            downsampled_majority = majority_samples.sample(\n",
    "                n=n_samples, \n",
    "                replace=len(majority_samples) < len(minority_samples),\n",
    "                random_state=bag*BAGS+fold\n",
    "            )\n",
    "            balanced_idx = minority_samples.index.union(downsampled_majority.index)\n",
    "            X_train = X.iloc[balanced_idx]\n",
    "            y_train_balanced = y.iloc[balanced_idx]\n",
    "        else:\n",
    "            X_train = X.iloc[train_idx]\n",
    "            y_train_balanced = y.iloc[train_idx]\n",
    "\n",
    "        # Model training (unchanged)\n",
    "        model = LGBMClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.175,\n",
    "            num_leaves=31,\n",
    "            reg_alpha=0.0,\n",
    "            reg_lambda=0.0009,\n",
    "            feature_fraction=0.1,\n",
    "            subsample=0.8,\n",
    "            verbose=-1,\n",
    "            class_weight='balanced'\n",
    "        )\n",
    "        model.fit(X_train, y_train_balanced)\n",
    "        \n",
    "        # Get predictions\n",
    "        pred = model.predict(X.iloc[valid_idx])\n",
    "        fold_f1 = f1_score(y.iloc[valid_idx], pred)\n",
    "        fold_f1s.append(fold_f1)\n",
    "        print(f\"F1: {fold_f1:.4f}\")\n",
    "        \n",
    "        # Store predictions\n",
    "        bag_pred[valid_idx] = model.predict_proba(X.iloc[valid_idx])[:, 1]\n",
    "        models[bag].append(model)\n",
    "        \n",
    "        # Store validation set std for this fold\n",
    "        stds.append(y.iloc[valid_idx].std())\n",
    "    \n",
    "    # Bag-level results\n",
    "    bag_avg_f1 = np.mean(fold_f1s)\n",
    "    bag_f1_scores.append(bag_avg_f1)\n",
    "    print(f\"\\nBag {bag+1} Avg F1: {bag_avg_f1:.4f}\")\n",
    "    oof_predictions += bag_pred / BAGS\n",
    "    F1s.append(fold_f1s)\n",
    "\n",
    "# Convert to numpy array for calculations\n",
    "F1s = np.array(F1s)\n",
    "\n",
    "# Final evaluation (aligned with your original validation structure)\n",
    "print('\\n' + '#'*50)\n",
    "print(\"==== Overall Results ===\")\n",
    "print(f\"Mean F1: {np.mean(F1s):.4f}\")\n",
    "print(f\"F1 std: {np.std(F1s):.4f}\")\n",
    "\n",
    "print(\"\\nStandard deviations of test sets:\")\n",
    "for i, std in enumerate(stds):\n",
    "    print(f\"Fold {i+1}: {std:.4f}\")\n",
    "\n",
    "# Final OOF score calculation\n",
    "final_preds = (oof_predictions > 0.5).astype(int)\n",
    "final_f1 = f1_score(y, final_preds)\n",
    "print(f\"\\nFinal OOF F1: {final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7e905",
   "metadata": {},
   "source": [
    "## LGBM WITHOUT DOWNSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d101c274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Bag 1\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8453\n",
      "=> Fold 2, F1: 0.8453\n",
      "=> Fold 2, F1: 0.8385\n",
      "=> Fold 3, F1: 0.8385\n",
      "=> Fold 3, F1: 0.8689\n",
      "=> Fold 4, F1: 0.8689\n",
      "=> Fold 4, F1: 0.8556\n",
      "=> Fold 5, F1: 0.8556\n",
      "=> Fold 5, F1: 0.8501\n",
      "\n",
      "Bag 1 Avg F1: 0.8517\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8501\n",
      "\n",
      "Bag 1 Avg F1: 0.8517\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8478\n",
      "F1: 0.8478\n",
      "=> Fold 2, => Fold 2, F1: 0.8315\n",
      "=> Fold 3, F1: 0.8315\n",
      "=> Fold 3, F1: 0.8500\n",
      "F1: 0.8500\n",
      "=> Fold 4, => Fold 4, F1: 0.8453\n",
      "=> Fold 5, F1: 0.8453\n",
      "=> Fold 5, F1: 0.8595\n",
      "F1: 0.8595\n",
      "\n",
      "Bag 2 Avg F1: 0.8468\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, \n",
      "Bag 2 Avg F1: 0.8468\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8485\n",
      "=> Fold 2, F1: 0.8485\n",
      "=> Fold 2, F1: 0.8476\n",
      "=> Fold 3, F1: 0.8476\n",
      "=> Fold 3, F1: 0.8289\n",
      "=> Fold 4, F1: 0.8289\n",
      "=> Fold 4, F1: 0.8338\n",
      "=> Fold 5, F1: 0.8338\n",
      "=> Fold 5, F1: 0.8595\n",
      "\n",
      "Bag 3 Avg F1: 0.8437\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8595\n",
      "\n",
      "Bag 3 Avg F1: 0.8437\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8329\n",
      "=> Fold 2, F1: 0.8329\n",
      "=> Fold 2, F1: 0.8541\n",
      "=> Fold 3, F1: 0.8541\n",
      "=> Fold 3, F1: 0.8466\n",
      "=> Fold 4, F1: 0.8232\n",
      "=> Fold 5, F1: 0.8556\n",
      "\n",
      "Bag 4 Avg F1: 0.8425\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8418\n",
      "=> Fold 2, F1: 0.8871\n",
      "=> Fold 3, F1: 0.8509\n",
      "=> Fold 4, F1: 0.8556\n",
      "=> Fold 5, F1: 0.8315\n",
      "\n",
      "Bag 5 Avg F1: 0.8534\n",
      "\n",
      "##################################################\n",
      "==== Overall Results ===\n",
      "Mean F1 across bags: 0.8476  0.0043\n",
      "\n",
      "Fold-wise standard deviations:\n",
      "Fold 1: 0.4646\n",
      "Fold 2: 0.4662\n",
      "Fold 3: 0.4662\n",
      "Fold 4: 0.4651\n",
      "Fold 5: 0.4651\n",
      "\n",
      "Final OOF F1: 0.8506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize storage\n",
    "oof_predictions = np.zeros(len(train))\n",
    "models = {}\n",
    "bag_f1_scores = []\n",
    "stds = []\n",
    "F1s = []\n",
    "\n",
    "BAGS = 5\n",
    "FOLDS = 5\n",
    "target_col = 'ADHD_Outcome'\n",
    "\n",
    "# Prepare data\n",
    "X = train.drop(columns=[target_col, 'participant_id', 'Sex_F'])\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = train[target_col]\n",
    "\n",
    "for bag in range(BAGS):\n",
    "    print('#'*25)\n",
    "    print(f'### Bag {bag+1}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    models[bag] = []\n",
    "    bag_pred = np.zeros(len(X))\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=bag*FOLDS)\n",
    "    fold_f1s = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f'=> Fold {fold}, ', end='')\n",
    "\n",
    "        # Model training WITHOUT downsampling\n",
    "        model = LGBMClassifier(\n",
    "            n_estimators=300,\n",
    "            learning_rate=0.175,\n",
    "            num_leaves=31,\n",
    "            reg_alpha=0.0,\n",
    "            reg_lambda=0.0009,\n",
    "            feature_fraction=0.1,\n",
    "            subsample=0.8,\n",
    "            verbose=-1,\n",
    "            class_weight='balanced'  # Handling imbalance through class weights\n",
    "        )\n",
    "        model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        \n",
    "        # Get predictions\n",
    "        pred = model.predict(X.iloc[valid_idx])\n",
    "        fold_f1 = f1_score(y.iloc[valid_idx], pred)\n",
    "        fold_f1s.append(fold_f1)\n",
    "        print(f\"F1: {fold_f1:.4f}\")\n",
    "        \n",
    "        # Store predictions\n",
    "        bag_pred[valid_idx] = model.predict_proba(X.iloc[valid_idx])[:, 1]\n",
    "        models[bag].append(model)\n",
    "        \n",
    "        # Store validation set std for this fold\n",
    "        stds.append(y.iloc[valid_idx].std())\n",
    "    \n",
    "    # Bag-level results\n",
    "    bag_avg_f1 = np.mean(fold_f1s)\n",
    "    bag_f1_scores.append(bag_avg_f1)\n",
    "    print(f\"\\nBag {bag+1} Avg F1: {bag_avg_f1:.4f}\")\n",
    "    oof_predictions += bag_pred / BAGS\n",
    "    F1s.append(fold_f1s)\n",
    "\n",
    "# Final evaluation\n",
    "print('\\n' + '#'*50)\n",
    "print(\"==== Overall Results ===\")\n",
    "print(f\"Mean F1 across bags: {np.mean(bag_f1_scores):.4f}  {np.std(bag_f1_scores):.4f}\")\n",
    "\n",
    "print(\"\\nFold-wise standard deviations:\")\n",
    "for i, std in enumerate(stds[:FOLDS]):  # Show first fold's std as representative\n",
    "    print(f\"Fold {i+1}: {std:.4f}\")\n",
    "\n",
    "# Final OOF score\n",
    "final_preds = (oof_predictions > 0.5).astype(int)\n",
    "final_f1 = f1_score(y, final_preds)\n",
    "print(f\"\\nFinal OOF F1: {final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e61c8",
   "metadata": {},
   "source": [
    "## ONLY TRAIN_ADHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c681c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos_Enroll_Year</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Prosocial</th>\n",
       "      <th>MRI_Track_Age_at_Scan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.903324</td>\n",
       "      <td>32.871543</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>0.737479</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>1.052928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.662301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>1.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.387745</td>\n",
       "      <td>17.897575</td>\n",
       "      <td>0.549071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>1.815994</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>0.580116</td>\n",
       "      <td>2.108335</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>2.688906</td>\n",
       "      <td>2.271221</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>0.773597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029841</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-1.121665</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.834631</td>\n",
       "      <td>-0.566931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845904</td>\n",
       "      <td>22.432518</td>\n",
       "      <td>-1.203370</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948365</td>\n",
       "      <td>1.661920</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>1.795674</td>\n",
       "      <td>1.393175</td>\n",
       "      <td>1.238063</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>-0.612823</td>\n",
       "      <td>-1.793238</td>\n",
       "      <td>-1.572278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.136452</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>1.240007</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.018928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-0.259717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-0.635442</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-1.315707</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-1.327849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-2.012158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>0.275259</td>\n",
       "      <td>0.312987</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.394725</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.114512</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>-0.432709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533473</td>\n",
       "      <td>-0.341035</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-0.994939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.571919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.186962</td>\n",
       "      <td>-0.150523</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.037145</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-1.313935</td>\n",
       "      <td>-0.375272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
       "0                        2019                       4   \n",
       "1                        2017                       1   \n",
       "2                        2017                       1   \n",
       "3                        2018                       1   \n",
       "4                        2018                       1   \n",
       "...                       ...                     ...   \n",
       "1208                     2019                       4   \n",
       "1209                     2018                       1   \n",
       "1210                     2018                       3   \n",
       "1211                     2019                       4   \n",
       "1212                     2017                       1   \n",
       "\n",
       "      PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                                  1.0                          0.0   \n",
       "1                                  0.0                          9.0   \n",
       "2                                  1.0                          2.0   \n",
       "3                                  3.0                          8.0   \n",
       "4                                  0.0                          1.0   \n",
       "...                                ...                          ...   \n",
       "1208                               1.0                          1.0   \n",
       "1209                               0.0                          0.0   \n",
       "1210                               2.0                          3.0   \n",
       "1211                               0.0                          1.0   \n",
       "1212                               0.0                          0.0   \n",
       "\n",
       "      MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                         3.0                    21.0               45.000000   \n",
       "1                         2.0                    21.0                0.000000   \n",
       "2                         2.0                     9.0                0.000000   \n",
       "3                         2.0                    18.0               10.000000   \n",
       "4                         2.0                    12.0                0.000000   \n",
       "...                       ...                     ...                     ...   \n",
       "1208                      3.0                    12.0               15.136452   \n",
       "1209                      3.0                    21.0               40.000000   \n",
       "1210                      3.0                    21.0               40.000000   \n",
       "1211                      3.0                    18.0               35.000000   \n",
       "1212                      2.0                    18.0               35.000000   \n",
       "\n",
       "      Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
       "0                  17.903324               32.871543       0.818599  ...   \n",
       "1                  21.000000               45.000000       0.662301  ...   \n",
       "2                  12.387745               17.897575       0.549071  ...   \n",
       "3                  18.000000                0.000000       0.683936  ...   \n",
       "4                  13.845904               22.432518      -1.203370  ...   \n",
       "...                      ...                     ...            ...  ...   \n",
       "1208               15.000000                5.000000       0.818599  ...   \n",
       "1209               21.000000               40.000000      -0.259717  ...   \n",
       "1210               21.000000               35.000000      -2.012158  ...   \n",
       "1211               18.000000               45.000000       0.818599  ...   \n",
       "1212               15.000000               35.000000       0.571919  ...   \n",
       "\n",
       "      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
       "0                     0.459262                    0.737479   \n",
       "1                     1.451997                    1.199700   \n",
       "2                     0.459262                    1.815994   \n",
       "3                    -1.029841                   -1.111402   \n",
       "4                     1.948365                    1.661920   \n",
       "...                        ...                         ...   \n",
       "1208                  1.451997                    1.199700   \n",
       "1209                 -0.037106                   -1.111402   \n",
       "1210                 -0.037106                    0.275259   \n",
       "1211                 -0.533473                   -0.341035   \n",
       "1212                 -0.037106                   -0.186962   \n",
       "\n",
       "      SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
       "0                       0.776497               0.823227   \n",
       "1                       0.776497               1.309451   \n",
       "2                       2.167026               0.580116   \n",
       "3                      -1.077543              -1.121665   \n",
       "4                       2.167026               1.795674   \n",
       "...                          ...                    ...   \n",
       "1208                    1.240007               1.309451   \n",
       "1209                   -1.077543              -0.635442   \n",
       "1210                    0.312987               0.337004   \n",
       "1211                   -1.077543               0.093893   \n",
       "1212                   -0.150523               0.337004   \n",
       "\n",
       "      SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  SDQ_SDQ_Internalizing  \\\n",
       "0                      0.320435               0.880342               0.400556   \n",
       "1                      0.320435               0.880342               0.686599   \n",
       "2                      2.108335               0.522620               2.688906   \n",
       "3                     -1.467465              -0.908267              -0.743619   \n",
       "4                      1.393175               1.238063               0.972643   \n",
       "...                         ...                    ...                    ...   \n",
       "1208                   0.320435               0.880342               0.686599   \n",
       "1209                  -1.467465              -0.908267              -1.315707   \n",
       "1210                  -0.394725               0.522620               0.114512   \n",
       "1211                   0.320435               0.522620              -0.743619   \n",
       "1212                  -0.037145               0.522620              -0.743619   \n",
       "\n",
       "      SDQ_SDQ_Peer_Problems  SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
       "0                 -0.132149           0.603281               1.052928  \n",
       "1                  0.348525           0.123977               1.088973  \n",
       "2                  2.271221          -0.355327               0.773597  \n",
       "3                 -0.132149          -0.834631              -0.566931  \n",
       "4                 -0.612823          -1.793238              -1.572278  \n",
       "...                     ...                ...                    ...  \n",
       "1208              -0.132149           0.123977               0.018928  \n",
       "1209              -1.093497          -0.355327              -1.327849  \n",
       "1210              -0.132149           0.603281              -0.432709  \n",
       "1211              -0.132149          -0.355327              -0.994939  \n",
       "1212              -1.093497          -1.313935              -0.375272  \n",
       "\n",
       "[1213 rows x 27 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e48c92ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Bag 1\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8363\n",
      "=> Fold 2, F1: 0.7768\n",
      "=> Fold 3, F1: 0.8480\n",
      "=> Fold 4, F1: 0.8448\n",
      "=> Fold 5, F1: 0.8343\n",
      "\n",
      "Bag 1 Avg F1: 0.8280\n",
      "#########################\n",
      "### Bag 2\n",
      "#########################\n",
      "=> Fold 1, F1: 0.7977\n",
      "=> Fold 2, F1: 0.8131\n",
      "=> Fold 3, F1: 0.8443\n",
      "=> Fold 4, F1: 0.8503\n",
      "=> Fold 5, F1: 0.8496\n",
      "\n",
      "Bag 2 Avg F1: 0.8310\n",
      "#########################\n",
      "### Bag 3\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8204\n",
      "=> Fold 2, F1: 0.8446\n",
      "=> Fold 3, F1: 0.8276\n",
      "=> Fold 4, F1: 0.8353\n",
      "=> Fold 5, F1: 0.8354\n",
      "\n",
      "Bag 3 Avg F1: 0.8326\n",
      "#########################\n",
      "### Bag 4\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8094\n",
      "=> Fold 2, F1: 0.8174\n",
      "=> Fold 3, F1: 0.8319\n",
      "=> Fold 4, F1: 0.8546\n",
      "=> Fold 5, F1: 0.8494\n",
      "\n",
      "Bag 4 Avg F1: 0.8325\n",
      "#########################\n",
      "### Bag 5\n",
      "#########################\n",
      "=> Fold 1, F1: 0.8314\n",
      "=> Fold 2, F1: 0.8408\n",
      "=> Fold 3, F1: 0.8300\n",
      "=> Fold 4, F1: 0.8319\n",
      "=> Fold 5, F1: 0.8085\n",
      "\n",
      "Bag 5 Avg F1: 0.8285\n",
      "\n",
      "##################################################\n",
      "==== Overall Results ===\n",
      "Mean F1 across bags: 0.8305  0.0019\n",
      "\n",
      "Fold-wise standard deviations:\n",
      "Fold 1: 0.4646\n",
      "Fold 2: 0.4662\n",
      "Fold 3: 0.4662\n",
      "Fold 4: 0.4651\n",
      "Fold 5: 0.4651\n",
      "\n",
      "Final OOF F1: 0.8414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialize storage\n",
    "oof_predictions = np.zeros(len(train_adhd))\n",
    "models = {}\n",
    "bag_f1_scores = []\n",
    "stds = []\n",
    "F1s = []\n",
    "\n",
    "BAGS = 5\n",
    "FOLDS = 5\n",
    "target_col = 'ADHD_Outcome'\n",
    "\n",
    "# Prepare data\n",
    "X = train_adhd\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "y = train[target_col]\n",
    "\n",
    "for bag in range(BAGS):\n",
    "    print('#'*25)\n",
    "    print(f'### Bag {bag+1}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    models[bag] = []\n",
    "    bag_pred = np.zeros(len(X))\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=bag*FOLDS)\n",
    "    fold_f1s = []\n",
    "    \n",
    "    for fold, (train_adhd_idx, valid_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f'=> Fold {fold}, ', end='')\n",
    "\n",
    "        # Model train_adhding WITHOUT downsampling\n",
    "        model = LGBMClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.175,\n",
    "            num_leaves=31,\n",
    "            reg_alpha=0.0,\n",
    "            reg_lambda=0.0009,\n",
    "            feature_fraction=0.1,\n",
    "            subsample=0.8,\n",
    "            verbose=-1,\n",
    "            class_weight='balanced'  # Handling imbalance through class weights\n",
    "        )\n",
    "        model.fit(X.iloc[train_adhd_idx], y.iloc[train_adhd_idx])\n",
    "        \n",
    "        # Get predictions\n",
    "        pred = model.predict(X.iloc[valid_idx])\n",
    "        fold_f1 = f1_score(y.iloc[valid_idx], pred)\n",
    "        fold_f1s.append(fold_f1)\n",
    "        print(f\"F1: {fold_f1:.4f}\")\n",
    "        \n",
    "        # Store predictions\n",
    "        bag_pred[valid_idx] = model.predict_proba(X.iloc[valid_idx])[:, 1]\n",
    "        models[bag].append(model)\n",
    "        \n",
    "        # Store validation set std for this fold\n",
    "        stds.append(y.iloc[valid_idx].std())\n",
    "    \n",
    "    # Bag-level results\n",
    "    bag_avg_f1 = np.mean(fold_f1s)\n",
    "    bag_f1_scores.append(bag_avg_f1)\n",
    "    print(f\"\\nBag {bag+1} Avg F1: {bag_avg_f1:.4f}\")\n",
    "    oof_predictions += bag_pred / BAGS\n",
    "    F1s.append(fold_f1s)\n",
    "\n",
    "# Final evaluation\n",
    "print('\\n' + '#'*50)\n",
    "print(\"==== Overall Results ===\")\n",
    "print(f\"Mean F1 across bags: {np.mean(bag_f1_scores):.4f}  {np.std(bag_f1_scores):.4f}\")\n",
    "\n",
    "print(\"\\nFold-wise standard deviations:\")\n",
    "for i, std in enumerate(stds[:FOLDS]):  # Show first fold's std as representative\n",
    "    print(f\"Fold {i+1}: {std:.4f}\")\n",
    "\n",
    "# Final OOF score\n",
    "final_preds = (oof_predictions > 0.5).astype(int)\n",
    "final_f1 = f1_score(y, final_preds)\n",
    "print(f\"\\nFinal OOF F1: {final_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2506cdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ADHD F1 (harmonic mean): 0.8305\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import hmean\n",
    "\n",
    "# Using harmonic mean of bag scores (though mathematically similar for single metric)\n",
    "final_f1_hmean = hmean(bag_f1_scores)  \n",
    "print(f\"Final ADHD F1 (harmonic mean): {final_f1_hmean:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692ed093",
   "metadata": {},
   "source": [
    "# SEX USING LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "509a00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex -> Brier Score: 0.1517, F1: 0.7253\n",
      "\n",
      "=== Fold 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex -> Brier Score: 0.1670, F1: 0.6774\n",
      "\n",
      "=== Fold 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex -> Brier Score: 0.1756, F1: 0.6667\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex -> Brier Score: 0.2013, F1: 0.6630\n",
      "\n",
      "=== Fold 5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex -> Brier Score: 0.1757, F1: 0.6961\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean Brier Score: 0.1743\n",
      "Sex Mean F1: 0.6857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define variables\n",
    "FOLDS = 5\n",
    "REPEATS = 1\n",
    "SEED = fold * REPEATS\n",
    "\n",
    "def eval_metrics(y_true, y_pred, label=\"None\", thresh=0.16):\n",
    "    \"\"\"Evaluate predictions using Brier Score and F1 Score.\"\"\"\n",
    "    brier = brier_score_loss(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, (y_pred > thresh).astype(int))\n",
    "    print(f\"{label} -> Brier Score: {brier:.4f}, F1: {f1:.4f}\")\n",
    "    return brier, f1\n",
    "\n",
    "# Store OOF Brier and F1\n",
    "scores_sex = []\n",
    "sex_oof = np.zeros(len(y_sex))\n",
    "\n",
    "# Classification threshold\n",
    "t_sex = 0.3\n",
    "\n",
    "# CV Setup\n",
    "rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)\n",
    "skf = StratifiedKFold(n_splits=FOLDS)\n",
    "\n",
    "params_2 = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"Cs\": 10,\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "}\n",
    "\n",
    "model_2 = LogisticRegressionCV(**params_2)\n",
    "\n",
    "# Align indices of important_features_sex and y_sex\n",
    "important_features_sex = important_features_sex.reset_index(drop=True)\n",
    "y_sex = y_sex.reset_index(drop=True)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(rskf.split(important_features_sex, y_sex), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = important_features_sex.iloc[train_idx], important_features_sex.iloc[val_idx]\n",
    "    y_important_features_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]\n",
    "\n",
    "    # Train model on sex\n",
    "    model_2.fit(X_train, y_important_features_sex)\n",
    "\n",
    "    # Predict\n",
    "    sex_val = model_2.predict_proba(X_val)[:, 1]\n",
    "    sex_oof[val_idx] += sex_val / REPEATS\n",
    "\n",
    "    # Evaluate\n",
    "    sex_brier, sex_f1 = eval_metrics(y_val_sex, sex_val, label=\"Sex\", thresh=t_sex)\n",
    "    scores_sex.append((sex_brier, sex_f1))\n",
    "\n",
    "# Final CV Results\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Sex Mean Brier Score: {np.mean([s[0] for s in scores_sex]):.4f}\")\n",
    "print(f\"Sex Mean F1: {np.mean([s[1] for s in scores_sex]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426578c2",
   "metadata": {},
   "source": [
    "# ADHD using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5f57d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop only the columns from `trf` that are present in `train`\n",
    "columns_to_drop = [col for col in trf.columns if col in train.columns]\n",
    "train_adhd = train.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop the target columns\n",
    "train_adhd = train_adhd.drop(columns=target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420b6c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos_Enroll_Year</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Prosocial</th>\n",
       "      <th>MRI_Track_Age_at_Scan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.903324</td>\n",
       "      <td>32.871543</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>0.737479</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>1.052928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.662301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>1.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.387745</td>\n",
       "      <td>17.897575</td>\n",
       "      <td>0.549071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>1.815994</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>0.580116</td>\n",
       "      <td>2.108335</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>2.688906</td>\n",
       "      <td>2.271221</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>0.773597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029841</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-1.121665</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.834631</td>\n",
       "      <td>-0.566931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845904</td>\n",
       "      <td>22.432518</td>\n",
       "      <td>-1.203370</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948365</td>\n",
       "      <td>1.661920</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>1.795674</td>\n",
       "      <td>1.393175</td>\n",
       "      <td>1.238063</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>-0.612823</td>\n",
       "      <td>-1.793238</td>\n",
       "      <td>-1.572278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.136452</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>1.240007</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.018928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-0.259717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-0.635442</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-1.315707</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-1.327849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-2.012158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>0.275259</td>\n",
       "      <td>0.312987</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.394725</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.114512</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>-0.432709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533473</td>\n",
       "      <td>-0.341035</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-0.994939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.571919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.186962</td>\n",
       "      <td>-0.150523</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.037145</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-1.313935</td>\n",
       "      <td>-0.375272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
       "0                        2019                       4   \n",
       "1                        2017                       1   \n",
       "2                        2017                       1   \n",
       "3                        2018                       1   \n",
       "4                        2018                       1   \n",
       "...                       ...                     ...   \n",
       "1208                     2019                       4   \n",
       "1209                     2018                       1   \n",
       "1210                     2018                       3   \n",
       "1211                     2019                       4   \n",
       "1212                     2017                       1   \n",
       "\n",
       "      PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                                  1.0                          0.0   \n",
       "1                                  0.0                          9.0   \n",
       "2                                  1.0                          2.0   \n",
       "3                                  3.0                          8.0   \n",
       "4                                  0.0                          1.0   \n",
       "...                                ...                          ...   \n",
       "1208                               1.0                          1.0   \n",
       "1209                               0.0                          0.0   \n",
       "1210                               2.0                          3.0   \n",
       "1211                               0.0                          1.0   \n",
       "1212                               0.0                          0.0   \n",
       "\n",
       "      MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                         3.0                    21.0               45.000000   \n",
       "1                         2.0                    21.0                0.000000   \n",
       "2                         2.0                     9.0                0.000000   \n",
       "3                         2.0                    18.0               10.000000   \n",
       "4                         2.0                    12.0                0.000000   \n",
       "...                       ...                     ...                     ...   \n",
       "1208                      3.0                    12.0               15.136452   \n",
       "1209                      3.0                    21.0               40.000000   \n",
       "1210                      3.0                    21.0               40.000000   \n",
       "1211                      3.0                    18.0               35.000000   \n",
       "1212                      2.0                    18.0               35.000000   \n",
       "\n",
       "      Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
       "0                  17.903324               32.871543       0.818599  ...   \n",
       "1                  21.000000               45.000000       0.662301  ...   \n",
       "2                  12.387745               17.897575       0.549071  ...   \n",
       "3                  18.000000                0.000000       0.683936  ...   \n",
       "4                  13.845904               22.432518      -1.203370  ...   \n",
       "...                      ...                     ...            ...  ...   \n",
       "1208               15.000000                5.000000       0.818599  ...   \n",
       "1209               21.000000               40.000000      -0.259717  ...   \n",
       "1210               21.000000               35.000000      -2.012158  ...   \n",
       "1211               18.000000               45.000000       0.818599  ...   \n",
       "1212               15.000000               35.000000       0.571919  ...   \n",
       "\n",
       "      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
       "0                     0.459262                    0.737479   \n",
       "1                     1.451997                    1.199700   \n",
       "2                     0.459262                    1.815994   \n",
       "3                    -1.029841                   -1.111402   \n",
       "4                     1.948365                    1.661920   \n",
       "...                        ...                         ...   \n",
       "1208                  1.451997                    1.199700   \n",
       "1209                 -0.037106                   -1.111402   \n",
       "1210                 -0.037106                    0.275259   \n",
       "1211                 -0.533473                   -0.341035   \n",
       "1212                 -0.037106                   -0.186962   \n",
       "\n",
       "      SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
       "0                       0.776497               0.823227   \n",
       "1                       0.776497               1.309451   \n",
       "2                       2.167026               0.580116   \n",
       "3                      -1.077543              -1.121665   \n",
       "4                       2.167026               1.795674   \n",
       "...                          ...                    ...   \n",
       "1208                    1.240007               1.309451   \n",
       "1209                   -1.077543              -0.635442   \n",
       "1210                    0.312987               0.337004   \n",
       "1211                   -1.077543               0.093893   \n",
       "1212                   -0.150523               0.337004   \n",
       "\n",
       "      SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  SDQ_SDQ_Internalizing  \\\n",
       "0                      0.320435               0.880342               0.400556   \n",
       "1                      0.320435               0.880342               0.686599   \n",
       "2                      2.108335               0.522620               2.688906   \n",
       "3                     -1.467465              -0.908267              -0.743619   \n",
       "4                      1.393175               1.238063               0.972643   \n",
       "...                         ...                    ...                    ...   \n",
       "1208                   0.320435               0.880342               0.686599   \n",
       "1209                  -1.467465              -0.908267              -1.315707   \n",
       "1210                  -0.394725               0.522620               0.114512   \n",
       "1211                   0.320435               0.522620              -0.743619   \n",
       "1212                  -0.037145               0.522620              -0.743619   \n",
       "\n",
       "      SDQ_SDQ_Peer_Problems  SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
       "0                 -0.132149           0.603281               1.052928  \n",
       "1                  0.348525           0.123977               1.088973  \n",
       "2                  2.271221          -0.355327               0.773597  \n",
       "3                 -0.132149          -0.834631              -0.566931  \n",
       "4                 -0.612823          -1.793238              -1.572278  \n",
       "...                     ...                ...                    ...  \n",
       "1208              -0.132149           0.123977               0.018928  \n",
       "1209              -1.093497          -0.355327              -1.327849  \n",
       "1210              -0.132149           0.603281              -0.432709  \n",
       "1211              -0.132149          -0.355327              -0.994939  \n",
       "1212              -1.093497          -1.313935              -0.375272  \n",
       "\n",
       "[1213 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64e16017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features_adhd = ['Basic_Demos_Enroll_Year', 'Barratt_Barratt_P1_Edu',\n",
    "       'Barratt_Barratt_P2_Edu', 'EHQ_EHQ_Total', 'ColorVision_CV_Score',\n",
    "       'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
    "       'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP',\n",
    "       'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
    "       'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
    "       'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
    "       'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
    "       'MRI_Track_Age_at_Scan']\n",
    "\n",
    "# Features to be interacted with predicted probability of Sex_F = 1\n",
    "interactions = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\",\n",
    "    \"MRI_Track_Age_at_Scan\", \"SDQ_SDQ_Generating_Impact\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bb878ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos_Enroll_Year</th>\n",
       "      <th>Basic_Demos_Study_Site</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Ethnicity</th>\n",
       "      <th>PreInt_Demos_Fam_Child_Race</th>\n",
       "      <th>MRI_Track_Scan_Location</th>\n",
       "      <th>Barratt_Barratt_P1_Edu</th>\n",
       "      <th>Barratt_Barratt_P1_Occ</th>\n",
       "      <th>Barratt_Barratt_P2_Edu</th>\n",
       "      <th>Barratt_Barratt_P2_Occ</th>\n",
       "      <th>EHQ_EHQ_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>SDQ_SDQ_Conduct_Problems</th>\n",
       "      <th>SDQ_SDQ_Difficulties_Total</th>\n",
       "      <th>SDQ_SDQ_Emotional_Problems</th>\n",
       "      <th>SDQ_SDQ_Externalizing</th>\n",
       "      <th>SDQ_SDQ_Generating_Impact</th>\n",
       "      <th>SDQ_SDQ_Hyperactivity</th>\n",
       "      <th>SDQ_SDQ_Internalizing</th>\n",
       "      <th>SDQ_SDQ_Peer_Problems</th>\n",
       "      <th>SDQ_SDQ_Prosocial</th>\n",
       "      <th>MRI_Track_Age_at_Scan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>17.903324</td>\n",
       "      <td>32.871543</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>0.737479</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>0.823227</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.400556</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>1.052928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.662301</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>0.776497</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>1.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.387745</td>\n",
       "      <td>17.897575</td>\n",
       "      <td>0.549071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459262</td>\n",
       "      <td>1.815994</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>0.580116</td>\n",
       "      <td>2.108335</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>2.688906</td>\n",
       "      <td>2.271221</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>0.773597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.029841</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-1.121665</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.834631</td>\n",
       "      <td>-0.566931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.845904</td>\n",
       "      <td>22.432518</td>\n",
       "      <td>-1.203370</td>\n",
       "      <td>...</td>\n",
       "      <td>1.948365</td>\n",
       "      <td>1.661920</td>\n",
       "      <td>2.167026</td>\n",
       "      <td>1.795674</td>\n",
       "      <td>1.393175</td>\n",
       "      <td>1.238063</td>\n",
       "      <td>0.972643</td>\n",
       "      <td>-0.612823</td>\n",
       "      <td>-1.793238</td>\n",
       "      <td>-1.572278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.136452</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451997</td>\n",
       "      <td>1.199700</td>\n",
       "      <td>1.240007</td>\n",
       "      <td>1.309451</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.686599</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.123977</td>\n",
       "      <td>0.018928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-0.259717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-1.111402</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>-0.635442</td>\n",
       "      <td>-1.467465</td>\n",
       "      <td>-0.908267</td>\n",
       "      <td>-1.315707</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-1.327849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-2.012158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>0.275259</td>\n",
       "      <td>0.312987</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.394725</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>0.114512</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>0.603281</td>\n",
       "      <td>-0.432709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.818599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.533473</td>\n",
       "      <td>-0.341035</td>\n",
       "      <td>-1.077543</td>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.320435</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-0.132149</td>\n",
       "      <td>-0.355327</td>\n",
       "      <td>-0.994939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.571919</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.186962</td>\n",
       "      <td>-0.150523</td>\n",
       "      <td>0.337004</td>\n",
       "      <td>-0.037145</td>\n",
       "      <td>0.522620</td>\n",
       "      <td>-0.743619</td>\n",
       "      <td>-1.093497</td>\n",
       "      <td>-1.313935</td>\n",
       "      <td>-0.375272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Basic_Demos_Enroll_Year  Basic_Demos_Study_Site  \\\n",
       "0                        2019                       4   \n",
       "1                        2017                       1   \n",
       "2                        2017                       1   \n",
       "3                        2018                       1   \n",
       "4                        2018                       1   \n",
       "...                       ...                     ...   \n",
       "1208                     2019                       4   \n",
       "1209                     2018                       1   \n",
       "1210                     2018                       3   \n",
       "1211                     2019                       4   \n",
       "1212                     2017                       1   \n",
       "\n",
       "      PreInt_Demos_Fam_Child_Ethnicity  PreInt_Demos_Fam_Child_Race  \\\n",
       "0                                  1.0                          0.0   \n",
       "1                                  0.0                          9.0   \n",
       "2                                  1.0                          2.0   \n",
       "3                                  3.0                          8.0   \n",
       "4                                  0.0                          1.0   \n",
       "...                                ...                          ...   \n",
       "1208                               1.0                          1.0   \n",
       "1209                               0.0                          0.0   \n",
       "1210                               2.0                          3.0   \n",
       "1211                               0.0                          1.0   \n",
       "1212                               0.0                          0.0   \n",
       "\n",
       "      MRI_Track_Scan_Location  Barratt_Barratt_P1_Edu  Barratt_Barratt_P1_Occ  \\\n",
       "0                         3.0                    21.0               45.000000   \n",
       "1                         2.0                    21.0                0.000000   \n",
       "2                         2.0                     9.0                0.000000   \n",
       "3                         2.0                    18.0               10.000000   \n",
       "4                         2.0                    12.0                0.000000   \n",
       "...                       ...                     ...                     ...   \n",
       "1208                      3.0                    12.0               15.136452   \n",
       "1209                      3.0                    21.0               40.000000   \n",
       "1210                      3.0                    21.0               40.000000   \n",
       "1211                      3.0                    18.0               35.000000   \n",
       "1212                      2.0                    18.0               35.000000   \n",
       "\n",
       "      Barratt_Barratt_P2_Edu  Barratt_Barratt_P2_Occ  EHQ_EHQ_Total  ...  \\\n",
       "0                  17.903324               32.871543       0.818599  ...   \n",
       "1                  21.000000               45.000000       0.662301  ...   \n",
       "2                  12.387745               17.897575       0.549071  ...   \n",
       "3                  18.000000                0.000000       0.683936  ...   \n",
       "4                  13.845904               22.432518      -1.203370  ...   \n",
       "...                      ...                     ...            ...  ...   \n",
       "1208               15.000000                5.000000       0.818599  ...   \n",
       "1209               21.000000               40.000000      -0.259717  ...   \n",
       "1210               21.000000               35.000000      -2.012158  ...   \n",
       "1211               18.000000               45.000000       0.818599  ...   \n",
       "1212               15.000000               35.000000       0.571919  ...   \n",
       "\n",
       "      SDQ_SDQ_Conduct_Problems  SDQ_SDQ_Difficulties_Total  \\\n",
       "0                     0.459262                    0.737479   \n",
       "1                     1.451997                    1.199700   \n",
       "2                     0.459262                    1.815994   \n",
       "3                    -1.029841                   -1.111402   \n",
       "4                     1.948365                    1.661920   \n",
       "...                        ...                         ...   \n",
       "1208                  1.451997                    1.199700   \n",
       "1209                 -0.037106                   -1.111402   \n",
       "1210                 -0.037106                    0.275259   \n",
       "1211                 -0.533473                   -0.341035   \n",
       "1212                 -0.037106                   -0.186962   \n",
       "\n",
       "      SDQ_SDQ_Emotional_Problems  SDQ_SDQ_Externalizing  \\\n",
       "0                       0.776497               0.823227   \n",
       "1                       0.776497               1.309451   \n",
       "2                       2.167026               0.580116   \n",
       "3                      -1.077543              -1.121665   \n",
       "4                       2.167026               1.795674   \n",
       "...                          ...                    ...   \n",
       "1208                    1.240007               1.309451   \n",
       "1209                   -1.077543              -0.635442   \n",
       "1210                    0.312987               0.337004   \n",
       "1211                   -1.077543               0.093893   \n",
       "1212                   -0.150523               0.337004   \n",
       "\n",
       "      SDQ_SDQ_Generating_Impact  SDQ_SDQ_Hyperactivity  SDQ_SDQ_Internalizing  \\\n",
       "0                      0.320435               0.880342               0.400556   \n",
       "1                      0.320435               0.880342               0.686599   \n",
       "2                      2.108335               0.522620               2.688906   \n",
       "3                     -1.467465              -0.908267              -0.743619   \n",
       "4                      1.393175               1.238063               0.972643   \n",
       "...                         ...                    ...                    ...   \n",
       "1208                   0.320435               0.880342               0.686599   \n",
       "1209                  -1.467465              -0.908267              -1.315707   \n",
       "1210                  -0.394725               0.522620               0.114512   \n",
       "1211                   0.320435               0.522620              -0.743619   \n",
       "1212                  -0.037145               0.522620              -0.743619   \n",
       "\n",
       "      SDQ_SDQ_Peer_Problems  SDQ_SDQ_Prosocial  MRI_Track_Age_at_Scan  \n",
       "0                 -0.132149           0.603281               1.052928  \n",
       "1                  0.348525           0.123977               1.088973  \n",
       "2                  2.271221          -0.355327               0.773597  \n",
       "3                 -0.132149          -0.834631              -0.566931  \n",
       "4                 -0.612823          -1.793238              -1.572278  \n",
       "...                     ...                ...                    ...  \n",
       "1208              -0.132149           0.123977               0.018928  \n",
       "1209              -1.093497          -0.355327              -1.327849  \n",
       "1210              -0.132149           0.603281              -0.432709  \n",
       "1211              -0.132149          -0.355327              -0.994939  \n",
       "1212              -1.093497          -1.313935              -0.375272  \n",
       "\n",
       "[1213 rows x 27 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3aa6a1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F -> F1: 0.5139, ROC-AUC: 0.6287\n",
      "Sex_F -> F1: 0.5139, ROC-AUC: 0.6287\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8465\n",
      "\n",
      "=== Fold 2 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8465\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F -> F1: 0.4946, ROC-AUC: 0.5423\n",
      "Sex_F -> F1: 0.4946, ROC-AUC: 0.5423\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8256\n",
      "\n",
      "=== Fold 3 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8256\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F -> F1: 0.5357, ROC-AUC: 0.6349\n",
      "Sex_F -> F1: 0.5357, ROC-AUC: 0.6349\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7383\n",
      "\n",
      "=== Fold 4 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7383\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F -> F1: 0.5235, ROC-AUC: 0.6267\n",
      "Sex_F -> F1: 0.5235, ROC-AUC: 0.6267\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8133\n",
      "\n",
      "=== Fold 5 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8133\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F -> F1: 0.4453, ROC-AUC: 0.4910\n",
      "Sex_F -> F1: 0.4453, ROC-AUC: 0.4910\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7506\n",
      "\n",
      "=== Fold 6 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7506\n",
      "\n",
      "=== Fold 6 ===\n",
      "Sex_F -> F1: 0.5141, ROC-AUC: 0.6235\n",
      "Sex_F -> F1: 0.5141, ROC-AUC: 0.6235\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8409\n",
      "\n",
      "=== Fold 7 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8409\n",
      "\n",
      "=== Fold 7 ===\n",
      "Sex_F -> F1: 0.5421, ROC-AUC: 0.6052\n",
      "Sex_F -> F1: 0.5421, ROC-AUC: 0.6052\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7670\n",
      "\n",
      "=== Fold 8 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7670\n",
      "\n",
      "=== Fold 8 ===\n",
      "Sex_F -> F1: 0.4582, ROC-AUC: 0.4949\n",
      "Sex_F -> F1: 0.4582, ROC-AUC: 0.4949\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7899\n",
      "\n",
      "=== Fold 9 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7899\n",
      "\n",
      "=== Fold 9 ===\n",
      "Sex_F -> F1: 0.5069, ROC-AUC: 0.5925\n",
      "Sex_F -> F1: 0.5069, ROC-AUC: 0.5925\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8331\n",
      "\n",
      "=== Fold 10 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8331\n",
      "\n",
      "=== Fold 10 ===\n",
      "Sex_F -> F1: 0.5498, ROC-AUC: 0.5923\n",
      "Sex_F -> F1: 0.5498, ROC-AUC: 0.5923\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7471\n",
      "\n",
      "=== Fold 11 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7471\n",
      "\n",
      "=== Fold 11 ===\n",
      "Sex_F -> F1: 0.5387, ROC-AUC: 0.5699\n",
      "Sex_F -> F1: 0.5387, ROC-AUC: 0.5699\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8301\n",
      "\n",
      "=== Fold 12 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8301\n",
      "\n",
      "=== Fold 12 ===\n",
      "Sex_F -> F1: 0.4945, ROC-AUC: 0.5739\n",
      "Sex_F -> F1: 0.4945, ROC-AUC: 0.5739\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7464\n",
      "\n",
      "=== Fold 13 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7464\n",
      "\n",
      "=== Fold 13 ===\n",
      "Sex_F -> F1: 0.4899, ROC-AUC: 0.6218\n",
      "Sex_F -> F1: 0.4899, ROC-AUC: 0.6218\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8686\n",
      "\n",
      "=== Fold 14 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8686\n",
      "\n",
      "=== Fold 14 ===\n",
      "Sex_F -> F1: 0.5267, ROC-AUC: 0.5831\n",
      "Sex_F -> F1: 0.5267, ROC-AUC: 0.5831\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7793\n",
      "\n",
      "=== Fold 15 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7793\n",
      "\n",
      "=== Fold 15 ===\n",
      "Sex_F -> F1: 0.5385, ROC-AUC: 0.5827\n",
      "Sex_F -> F1: 0.5385, ROC-AUC: 0.5827\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7505\n",
      "\n",
      "=== Fold 16 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7505\n",
      "\n",
      "=== Fold 16 ===\n",
      "Sex_F -> F1: 0.4800, ROC-AUC: 0.5468\n",
      "Sex_F -> F1: 0.4800, ROC-AUC: 0.5468\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8086\n",
      "\n",
      "=== Fold 17 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8086\n",
      "\n",
      "=== Fold 17 ===\n",
      "Sex_F -> F1: 0.5519, ROC-AUC: 0.6121\n",
      "Sex_F -> F1: 0.5519, ROC-AUC: 0.6121\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8109\n",
      "\n",
      "=== Fold 18 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8109\n",
      "\n",
      "=== Fold 18 ===\n",
      "Sex_F -> F1: 0.5053, ROC-AUC: 0.5900\n",
      "Sex_F -> F1: 0.5053, ROC-AUC: 0.5900\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8111\n",
      "\n",
      "=== Fold 19 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8111\n",
      "\n",
      "=== Fold 19 ===\n",
      "Sex_F -> F1: 0.5221, ROC-AUC: 0.5454\n",
      "Sex_F -> F1: 0.5221, ROC-AUC: 0.5454\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7799\n",
      "\n",
      "=== Fold 20 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7799\n",
      "\n",
      "=== Fold 20 ===\n",
      "Sex_F -> F1: 0.4710, ROC-AUC: 0.5705\n",
      "Sex_F -> F1: 0.4710, ROC-AUC: 0.5705\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7841\n",
      "\n",
      "=== Fold 21 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.7841\n",
      "\n",
      "=== Fold 21 ===\n",
      "Sex_F -> F1: 0.4892, ROC-AUC: 0.5992\n",
      "Sex_F -> F1: 0.4892, ROC-AUC: 0.5992\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8078\n",
      "\n",
      "=== Fold 22 ===\n",
      "Outcome ADHD -> F1: 0.8146, ROC-AUC: 0.8078\n",
      "\n",
      "=== Fold 22 ===\n",
      "Sex_F -> F1: 0.5126, ROC-AUC: 0.5315\n",
      "Sex_F -> F1: 0.5126, ROC-AUC: 0.5315\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8057\n",
      "\n",
      "=== Fold 23 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.8057\n",
      "\n",
      "=== Fold 23 ===\n",
      "Sex_F -> F1: 0.4982, ROC-AUC: 0.5935\n",
      "Sex_F -> F1: 0.4982, ROC-AUC: 0.5935\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7562\n",
      "\n",
      "=== Fold 24 ===\n",
      "Outcome ADHD -> F1: 0.8117, ROC-AUC: 0.7562\n",
      "\n",
      "=== Fold 24 ===\n",
      "Sex_F -> F1: 0.5395, ROC-AUC: 0.6367\n",
      "Sex_F -> F1: 0.5395, ROC-AUC: 0.6367\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8288\n",
      "\n",
      "=== Fold 25 ===\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8288\n",
      "\n",
      "=== Fold 25 ===\n",
      "Sex_F -> F1: 0.5055, ROC-AUC: 0.5378\n",
      "Sex_F -> F1: 0.5055, ROC-AUC: 0.5378\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8161\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean roc auc Score: 0.5099\n",
      "Sex Mean F1: 0.5811\n",
      "ADHD Mean roc auc Score: 0.8131\n",
      "ADHD Mean F1: 0.7975\n",
      "Outcome ADHD -> F1: 0.8137, ROC-AUC: 0.8161\n",
      "\n",
      "=== CV Results ===\n",
      "Sex Mean roc auc Score: 0.5099\n",
      "Sex Mean F1: 0.5811\n",
      "ADHD Mean roc auc Score: 0.8131\n",
      "ADHD Mean F1: 0.7975\n"
     ]
    }
   ],
   "source": [
    "# Actual Validation and Modeling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "SEED = 42\n",
    "REPEATS = 5\n",
    "FOLDS = 5\n",
    "t_sex = 0.3\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Evaluation function\n",
    "def eval_metrics(y_true, y_pred, weights, label=\"None\", thresh=0.3):\n",
    "    \"\"\"Evaluate predictions using F1 Score and ROC-AUC.\"\"\"\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, (y_pred > thresh).astype(int), sample_weight=weights)\n",
    "    print(f\"{label} -> F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    return f1, roc_auc\n",
    "\n",
    "# Initialize lists to store scores and out-of-fold predictions\n",
    "scores_sex = []\n",
    "scores_adhd = []\n",
    "sex_oof = np.zeros(len(y_sex))\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Cross-validation setup\n",
    "rskf = RepeatedStratifiedKFold(n_splits=FOLDS, n_repeats=REPEATS, random_state=SEED)\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Logistic RegressionCV parameters\n",
    "logreg_params = {\n",
    "    \"penalty\": \"l2\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "}\n",
    "\n",
    "model_sex = LogisticRegressionCV(**logreg_params)\n",
    "model_adhd = LogisticRegressionCV(**logreg_params)\n",
    "\n",
    "# Start cross-validation loop\n",
    "for fold, (train_idx, val_idx) in enumerate(rskf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val = train_adhd.iloc[train_idx].copy(), train_adhd.iloc[val_idx].copy()\n",
    "    y_train_sex, y_val_sex = y_sex.iloc[train_idx], y_sex.iloc[val_idx]\n",
    "    y_train_adhd, y_val_adhd = y_adhd.iloc[train_idx], y_adhd.iloc[val_idx]\n",
    "\n",
    "    # Sample weights\n",
    "    weights_train = np.where(y_train_adhd == \"11\", 2, 1)  # Assign higher weight to ADHD positive samples\n",
    "    weights_val = np.where(y_val_adhd == \"11\", 2, 1)  # Assign higher weight to ADHD positive samples\n",
    "\n",
    "    # Train model to predict Sex_F\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=weights_train)\n",
    "    sex_train_pred = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_pred = model_sex.predict_proba(X_val)[:, 1]\n",
    "    sex_oof[val_idx] += sex_val_pred / REPEATS\n",
    "\n",
    "    sex_f1, sex_roc_auc = eval_metrics(y_val_sex, sex_val_pred, weights_val, \"Sex_F\", thresh=t_sex)\n",
    "    scores_sex.append((sex_f1, sex_roc_auc))\n",
    "\n",
    "    # Add predicted sex probabilities\n",
    "    X_train = X_train.assign(sex_proba=sex_train_pred)\n",
    "    X_val = X_val.assign(sex_proba=sex_val_pred)\n",
    "\n",
    "    # Create interaction features\n",
    "    for col in interactions:\n",
    "        X_train[f\"I_{col}\"] = X_train[col] * X_train[\"sex_proba\"]\n",
    "        X_val[f\"I_{col}\"] = X_val[col] * X_val[\"sex_proba\"]\n",
    "\n",
    "    # Train model to predict ADHD outcome\n",
    "    model_adhd.fit(X_train[features_adhd], y_train_adhd, sample_weight=weights_train)\n",
    "    adhd_val_pred = model_adhd.predict_proba(X_val[features_adhd])[:, 1]\n",
    "    adhd_oof[val_idx] += adhd_val_pred / REPEATS\n",
    "\n",
    "    adhd_f1, adhd_roc_auc = eval_metrics(y_val_adhd, adhd_val_pred, weights_val, \"Outcome ADHD\", thresh=t_adhd)\n",
    "    scores_adhd.append((adhd_f1, adhd_roc_auc))\n",
    "\n",
    "# Print final results\n",
    "print(f\"\\n=== CV Results ===\")\n",
    "print(f\"Sex Mean roc auc Score: {np.mean([b for b, _ in scores_sex]):.4f}\")\n",
    "print(f\"Sex Mean F1: {np.mean([f for _, f in scores_sex]):.4f}\")\n",
    "print(f\"ADHD Mean roc auc Score: {np.mean([b for b, _ in scores_adhd]):.4f}\")\n",
    "print(f\"ADHD Mean F1: {np.mean([f for _, f in scores_adhd]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86c63ce",
   "metadata": {},
   "source": [
    "## only features_adhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efb01474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2182\n",
      "Std Brier: 0.0008\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2182\n",
      "Std Brier: 0.0008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# Initialize storage\n",
    "scores_f1 = []\n",
    "scores_brier = []\n",
    "\n",
    "# Store OOF predictions\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Classification threshold\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "params = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "    }\n",
    "\n",
    "model = LogisticRegressionCV(**params)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Data split\n",
    "    X_train, X_val = train_adhd.iloc[train_idx], train_adhd.iloc[val_idx]\n",
    "    y_train = y_adhd.iloc[train_idx]\n",
    "    y_val = y_adhd.iloc[val_idx]\n",
    "    \n",
    "    # Sample weights as in the first script\n",
    "    weights_train = ((y_sex.iloc[train_idx] == 1) & (y_train == 1)).astype(int) + 1\n",
    "    weights_val = ((y_sex.iloc[val_idx] == 1) & (y_val == 1)).astype(int) + 1\n",
    "\n",
    "    # Column check\n",
    "    missing = [col for col in features_adhd if col not in X_train.columns]\n",
    "    if missing:\n",
    "        print(f\"Missing columns: {missing}\")\n",
    "    features_adhd_valid = [col for col in features_adhd if col in X_train.columns]\n",
    "\n",
    "    # Fit and predict\n",
    "    model.fit(X_train[features_adhd_valid], y_train, sample_weight=weights_train)\n",
    "    pred_proba = model.predict_proba(X_val[features_adhd_valid])[:, 1]\n",
    "    adhd_oof[val_idx] = pred_proba\n",
    "\n",
    "    # Calculate scores\n",
    "    brier = brier_score_loss(y_val, pred_proba)\n",
    "    f1 = f1_score(y_val, (pred_proba > t_adhd).astype(int), sample_weight=weights_val)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Brier Score: {brier:.4f}\")\n",
    "\n",
    "    scores_f1.append(f1)\n",
    "    scores_brier.append(brier)\n",
    "\n",
    "# ===== Results Summary =====\n",
    "\n",
    "scores_f1 = np.array(scores_f1)\n",
    "scores_brier = np.array(scores_brier)\n",
    "\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "print(f\"Mean F1: {scores_f1.mean():.4f}\")\n",
    "print(f\"Std F1: {scores_f1.std():.4f}\")\n",
    "print(f\"Mean Brier: {scores_brier.mean():.4f}\")\n",
    "print(f\"Std Brier: {scores_brier.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed3862",
   "metadata": {},
   "source": [
    "## all adhd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dd08e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8498, Brier Score: 0.2172\n",
      "\n",
      "=== Fold 2 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.1961\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8469, Brier Score: 0.1961\n",
      "\n",
      "=== Fold 3 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8481, Brier Score: 0.2192\n",
      "\n",
      "=== Fold 4 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8527, Brier Score: 0.2177\n",
      "\n",
      "=== Fold 5 ===\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2136\n",
      "Std Brier: 0.0088\n",
      "F1 Score: 0.8516, Brier Score: 0.2177\n",
      "\n",
      "=== Final Evaluation ===\n",
      "Mean F1: 0.8498\n",
      "Std F1: 0.0021\n",
      "Mean Brier: 0.2136\n",
      "Std Brier: 0.0088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import brier_score_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "# Initialize storage\n",
    "scores_f1 = []\n",
    "scores_brier = []\n",
    "\n",
    "# Store OOF predictions\n",
    "adhd_oof = np.zeros(len(y_adhd))\n",
    "\n",
    "# Classification threshold\n",
    "t_adhd = 0.4\n",
    "\n",
    "# Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "params = {\n",
    "    \"penalty\": \"l1\",\n",
    "    \"cv\": skf,\n",
    "    \"fit_intercept\": True,\n",
    "    \"scoring\": \"f1\",\n",
    "    \"random_state\": SEED,\n",
    "    \"solver\": \"saga\"\n",
    "}\n",
    "\n",
    "model = LogisticRegressionCV(**params)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_adhd, y_adhd), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    # Data split\n",
    "    X_train, X_val = train_adhd.iloc[train_idx], train_adhd.iloc[val_idx]\n",
    "    y_train = y_adhd.iloc[train_idx]\n",
    "    y_val = y_adhd.iloc[val_idx]\n",
    "    \n",
    "    # Sample weights as in the first script\n",
    "    weights_train = ((y_sex.iloc[train_idx] == 1) & (y_train == 1)).astype(int) + 1\n",
    "    weights_val = ((y_sex.iloc[val_idx] == 1) & (y_val == 1)).astype(int) + 1\n",
    "\n",
    "    \n",
    "    # Fit and predict\n",
    "    model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "    pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    adhd_oof[val_idx] = pred_proba\n",
    "\n",
    "    # Calculate scores\n",
    "    brier = brier_score_loss(y_val, pred_proba)\n",
    "    f1 = f1_score(y_val, (pred_proba > t_adhd).astype(int), sample_weight=weights_val)\n",
    "\n",
    "    print(f\"F1 Score: {f1:.4f}, Brier Score: {brier:.4f}\")\n",
    "\n",
    "    scores_f1.append(f1)\n",
    "    scores_brier.append(brier)\n",
    "\n",
    "# ===== Results Summary =====\n",
    "\n",
    "scores_f1 = np.array(scores_f1)\n",
    "scores_brier = np.array(scores_brier)\n",
    "\n",
    "print(\"\\n=== Final Evaluation ===\")\n",
    "print(f\"Mean F1: {scores_f1.mean():.4f}\")\n",
    "print(f\"Std F1: {scores_f1.std():.4f}\")\n",
    "print(f\"Mean Brier: {scores_brier.mean():.4f}\")\n",
    "print(f\"Std Brier: {scores_brier.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867d2b8",
   "metadata": {},
   "source": [
    "## prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acd489ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Boolean array expected for the condition, not float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6820\\3419686697.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Define train_sex_filtered to match the features used during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_sex_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimportant_features_sex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Predict the Sex target using the trained models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msex_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_clean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4087\u001b[0m         \u001b[1;31m# Do we have a (boolean) DataFrame?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4088\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4089\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4091\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4092\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, cond, other, inplace, axis, level)\u001b[0m\n\u001b[0;32m  10980\u001b[0m                         \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10981\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10983\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_where\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Family\\Desktop\\WIDS-Com\\myvenv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, cond, other, inplace, axis, level, warn)\u001b[0m\n\u001b[0;32m  10669\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10670\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10671\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_dt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10672\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_bool_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10673\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10674\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many_extension_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10675\u001b[0m                     \u001b[1;31m# GH51574: avoid object ndarray conversion later on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10676\u001b[0m                     cond = cond._constructor(\n",
      "\u001b[1;31mValueError\u001b[0m: Boolean array expected for the condition, not float64"
     ]
    }
   ],
   "source": [
    "# Define train_sex_filtered to match the features used during training\n",
    "train_sex_filtered = train_sex[important_features_sex]\n",
    "\n",
    "# Predict the Sex target using the trained models\n",
    "sex_pred = np.zeros(len(test_clean))\n",
    "\n",
    "for bag in range(BAGS):\n",
    "    for fold in range(FOLDS):\n",
    "        # Get the trained model for this bag and fold\n",
    "        model_sex = models_sep_sex[bag][fold]\n",
    "        \n",
    "        # Ensure test_clean contains only the features used during training\n",
    "        test_features_sex = train_sex_filtered.columns  # Use the same columns as in training for Sex\n",
    "        test_clean_sex = test_clean[test_features_sex]\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        sex_pred += model_sex.predict_proba(test_clean_sex)[:, 1] / (BAGS * FOLDS)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "sex_pred_binary = (sex_pred > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd8c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure test_clean is preprocessed similarly to train_clean\n",
    "test_clean_preprocessed = test_clean.fillna(test_clean.mean())\n",
    "\n",
    "# Predict ADHD outcomes using the pipeline\n",
    "adhd_pred = model_sep_adhd.predict(test_clean_preprocessed)\n",
    "adhd_pred_binary = (adhd_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file for Sex created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Ensure all arrays have the same length\n",
    "if len(id_test) == len(sex_pred_binary):\n",
    "    # Create a DataFrame for submission\n",
    "    submission = pd.DataFrame({\n",
    "        'participant_id': id_test,\n",
    "         'ADHD_Outcome' : adhd_pred_binary ,\n",
    "        'Sex_F': sex_pred_binary  \n",
    "    })\n",
    "\n",
    "    # Save the submission file\n",
    "    submission.to_csv('submission_Sex_0.7416_adhd_0.76417.csv', index=False)\n",
    "    print(\"Submission file for Sex created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

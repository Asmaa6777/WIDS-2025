{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the notebook in a nutshell \n",
    "- importing \n",
    "software dependencies we need\n",
    "- load_data (please read its description it supposed to be very easy to deal with it)\n",
    "\n",
    "###  preprocesssing \n",
    "- I stored some important variables, then I used log transformation for long tailed distributions\n",
    "\n",
    "- iterative imputer just like what `MAAB` Advised\n",
    "\n",
    "- transormed the categorical features to be from the string type just to avoid some fitting isssues cause by the \n",
    "OneHotEncoder.\n",
    "\n",
    "- droped the `participant_ID` after storing it for stratification\n",
    "\n",
    "- I scaled quantative data and also FMRI data \n",
    "\n",
    "### modeling\n",
    "- base model is logisitc regression with l2 regulization (fancy name for punishing the model to stop overfitting to noise) \n",
    "- wrapped inside a multioutput classifier that just gives it the ability to predict 2 targets simultaneously\n",
    "### validation \n",
    "- 5 splits stratifiedKFold works fine no need for grouping as participants are unique \n",
    "- regular stratified  = 0.5901173137436236\n",
    "- RepeatedStratifiedKFold =0.5865925294336686 with 7 minutese delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import hmean\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import scipy\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer #it might not work directly if not try the following code line\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold,StratifiedKFold,RepeatedStratifiedKFold\n",
    "from pathlib import Path\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just drop the path of your new data directory nothing more than that. \n",
    "\n",
    "\"\"\"\n",
    "path = r\"C:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\Data\\raw\"\n",
    "\n",
    "def read_data(base_path:str) -> pd.DataFrame :\n",
    "    path = Path(base_path)\n",
    "    trc=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    trq=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    trf=pd.read_csv(path   /'TRAIN_NEW'  / 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    trs=pd.read_excel(path /'TRAIN_NEW'  / 'TRAINING_SOLUTIONS.xlsx')  \n",
    "    tsc=pd.read_excel(path /'TEST'      / 'TEST_CATEGORICAL.xlsx')\n",
    "    tsq=pd.read_excel(path /'TEST'       / 'TEST_QUANTITATIVE_METADATA.xlsx')    \n",
    "    tsf=pd.read_csv(path   /'TEST'       / 'TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')    \n",
    "    sub=pd.read_excel(path / 'SAMPLE_SUBMISSION.xlsx')\n",
    "    dic=pd.read_excel(path /'Data Dictionary.xlsx')\n",
    "    return trc, trq, trf, trs, tsc, tsq, tsf, sub, dic\n",
    "\n",
    "trc, trq, trf, trs, tsc, tsq, tsf, sub, dic = read_data(base_path=path)\n",
    "\n",
    "# Data Merging \n",
    "cq = pd.merge(trc, trq, on='participant_id', how='left')\n",
    "feat = pd.merge(cq, trf, on='participant_id', how='left')  \n",
    "qc = pd.merge(tsc, tsq, on='participant_id', how='left')\n",
    "train = pd.merge(feat, trs, on='participant_id', how='left') \n",
    "test = pd.merge(qc, tsf, on='participant_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Features before Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your coefficients (estimated from your description)\n",
    "female_coefs = {\n",
    "    'ColorVision_CV_Score': 2.900,\n",
    "    'SDQ_SDQ_Emotional_Problems': 2.814,\n",
    "    'SDQ_SDQ_Prosocial': 2.661,\n",
    "    'SDQ_SDQ_Internalizing': 1.382,\n",
    "    'SDQ_SDQ_Conduct_Problems': 1.329,\n",
    "    'SDQ_SDQ_Generating_Impact': 1.109,\n",
    "    'APQ_P_APQ_P_PM': 0.642\n",
    "}\n",
    "\n",
    "male_coefs = {\n",
    "    'SDQ_SDQ_Hyperactivity': -3.088,\n",
    "    'APQ_P_APQ_P_PP': -1.903,\n",
    "    'SDQ_SDQ_Externalizing': -1.447,\n",
    "    'APQ_P_APQ_P_CP': -1.380,\n",
    "    'APQ_P_APQ_P_INV': -0.437,\n",
    "    'APQ_P_APQ_P_OPD': -0.676,\n",
    "    'SDQ_SDQ_Peer_Problems': -0.596\n",
    "}\n",
    "\n",
    "# Compute weighted sums\n",
    "train['female_symptom_score'] = sum(train[feat] * coef for feat, coef in female_coefs.items())\n",
    "train['male_symptom_score'] = sum(train[feat] * coef for feat, coef in male_coefs.items())\n",
    "\n",
    "test['female_symptom_score'] = sum(test[feat] * coef for feat, coef in female_coefs.items())\n",
    "test['male_symptom_score'] = sum(test[feat] * coef for feat, coef in male_coefs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'MRI_Track_Age_at_Scan', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu',\n",
    "    'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu',\n",
    "    'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total'\n",
    "]\n",
    "\n",
    "train_ids = train['participant_id']\n",
    "test_ids = test['participant_id'] # I will store them for later usage in grouping in validation why?  I don't want the same user to appear in both train and test. \n",
    "\n",
    "\n",
    "for df in (train, test):\n",
    "    df.set_index('participant_id', inplace=True)\n",
    "    df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# for df in (train,test):\n",
    "#     # df.drop(columns=['participant_id'], inplace=True) \n",
    "#     df.set_index('participant_id', inplace=True)\n",
    "#     df.drop(columns=['EHQ_EHQ_Total'], inplace=True) \n",
    "#     df.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting important variables. \n",
    "# note that I did't deal with the quantative data trq as categorical\n",
    "# I will use the OneHotEncoder for the categorical data as we have some data trap that I don't think we can use the label encoder for. \n",
    "\n",
    "# for feature in trc.columns:\n",
    "#     train[feature] = train[feature].astype(object)\n",
    "num_feats = [feature for feature in train.columns if train[feature].dtype == 'float64']\n",
    "cat_feats = [feature for feature in train.columns if train[feature].dtype == 'object'] # seperate categorical and numerical features help me reteriving them later easily for preprocessing.\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with positive skewness and non-negative values: apply log transformation\n",
    "# num_feats[:18] Don't transform fMRI data because it has negative values\n",
    "log_features = [f for f in num_feats[:18] if (train[f] >= 0).all() and scipy.stats.skew(train[f]) > 0.5]  # Only apply to features with significant positive skew\n",
    "\n",
    "# Apply log transformation for the selected features\n",
    "for feature in log_features:\n",
    "    train[feature] = np.log1p(train[feature])  # Apply log(x+1) to handle skewed features\n",
    "    test[feature] = np.log1p(test[feature])    # Apply log(x+1) to test data as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with missing values only\n",
    "train_missing_features_to_impute = train.columns[train.isnull().any()].tolist() # List of features with missing values in train, only 25 and no missing data in fMRI data\n",
    "test_missing_features_to_impute = test.columns[test.isnull().any()].tolist() # List of features with missing values in test, only 23 and no missing data in fMRI data\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = IterativeImputer(estimator=LassoCV(random_state=42), max_iter=5, random_state=42)\n",
    "\n",
    "# Impute in-place\n",
    "train[train_missing_features_to_impute] = imputer.fit_transform(train[train_missing_features_to_impute])\n",
    "test[test_missing_features_to_impute] = imputer.fit_transform(test[test_missing_features_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all categorical features have been dropped so no need for this.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"all categorical features have been dropped so no need for this.\"\"\"\n",
    "\n",
    "# # Convert all categorical features to strings (to avoid mixed types)\n",
    "# for feature in cat_feats:\n",
    "#     train[feature] = train[feature].astype(str)\n",
    "#     test[feature] = test[feature].astype(str)\n",
    "\n",
    "# # One-Hot Encoding for categorical features\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# for feature in cat_feats:\n",
    "#     if feature == 'participant_id':  # Skip participant_id since it's not a feature\n",
    "#         continue\n",
    "\n",
    "#     # Apply OneHotEncoder\n",
    "#     train_encoded = encoder.fit_transform(train[[feature]])\n",
    "#     test_encoded = encoder.transform(test[[feature]])\n",
    "\n",
    "#     # Convert encoded features to DataFrame and append them to the original data\n",
    "#     train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "#     test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "\n",
    "#     # Drop the original feature and concatenate the new encoded columns\n",
    "#     train = pd.concat([train.drop(columns=[feature]), train_encoded_df], axis=1)\n",
    "#     test = pd.concat([test.drop(columns=[feature]), test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Only apply scaling to numerical columns that are not part of the target or categorical features\n",
    "numerical_features = [col for col in train.columns if col not in target_cols and col not in cat_feats]\n",
    "\n",
    "# Fit scaler on the numerical features of the train set and transform train and test sets\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])  # Fit and transform for train set\n",
    "test[numerical_features] = scaler.transform(test[numerical_features])        # Only transform for test set (avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'female_symptom_score', 'male_symptom_score']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "print(non_connectome_features)\n",
    "print(len(non_connectome_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data (fMRI and symtpoms) used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7391\n",
      "ADHD_Outcome F1: 0.4228\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.7345\n",
      "ADHD_Outcome F1: 0.4407\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.6424\n",
      "ADHD_Outcome F1: 0.4536\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.6984\n",
      "ADHD_Outcome F1: 0.4429\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.7077\n",
      "ADHD_Outcome F1: 0.4737\n",
      "\n",
      "=== Competition Results ===\n",
      "Sex_F F1: 0.7044 ± 0.0346\n",
      "ADHD F1: 0.4467 ± 0.0167\n",
      "\n",
      "Competition Score (Normal Mean): 0.5756\n",
      "Mean Sex_F F1: 0.7044 ± 0.0346\n",
      "Mean ADHD_Outcome F1: 0.4467 ± 0.0167\n",
      "\n",
      "Competition Score (Harmonic Mean): 0.5467\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "ADHD_WEIGHT = 2  # 2x weight for female ADHD cases\n",
    "\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models with competition-optimized parameters\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Configure cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store competition metrics\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Define important features for interaction (update with your actual features)\n",
    "interaction_features = [    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "                        \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score']  # Use actual column names\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Extract targets\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Calculate competition weights\n",
    "    train_weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) * (ADHD_WEIGHT - 1) + 1\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) * (ADHD_WEIGHT - 1) + 1\n",
    "\n",
    "    # --- Sex Prediction ---\n",
    "    # Train sex model\n",
    "    model_sex.fit(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']), y_train_sex, sample_weight=train_weights)\n",
    "    \n",
    "    # Get sex probabilities\n",
    "    sex_train_proba = model_sex.predict_proba(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "\n",
    "    # --- ADHD Prediction with Interaction Features ---\n",
    "    # Create enhanced features\n",
    "    X_train_adhd = X_train.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    X_val_adhd = X_val.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    \n",
    "    # Add sex probability feature\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "    \n",
    "    # Add interaction terms\n",
    "    for col in interaction_features:\n",
    "        X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "        X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    # Train ADHD model\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # --- Competition Validation ---\n",
    "    sex_pred = model_sex.predict(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Calculate weighted F1 scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# --- Final Competition Scoring ---\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (average of both F1 scores)\n",
    "final_score = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score:.4f}\")\n",
    "\n",
    "print(f\"Mean Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Mean ADHD_Outcome F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (harmonic mean of average F1s)\n",
    "final_score = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Harmonic Mean): {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data (fMRI and symtpoms) used, added more female symptoms features to interaction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7391\n",
      "ADHD_Outcome F1: 0.4228\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.7345\n",
      "ADHD_Outcome F1: 0.4512\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.6424\n",
      "ADHD_Outcome F1: 0.4642\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m     X_val_adhd[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_x_sex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X_val_adhd[col] \u001b[38;5;241m*\u001b[39m X_val_adhd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_proba\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Train ADHD model\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[43mmodel_adhd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_adhd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_adhd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# --- Competition Validation ---\u001b[39;00m\n\u001b[0;32m     85\u001b[0m sex_pred \u001b[38;5;241m=\u001b[39m model_sex\u001b[38;5;241m.\u001b[39mpredict(X_val\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex_F\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:543\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    540\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[0;32m    541\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[1;32m--> 543\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[0;32m    564\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[1;32m--> 323\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[0;32m    348\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    351\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models with competition-optimized parameters\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Configure cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store competition metrics\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Define important features for interaction (update with your actual features)\n",
    "interaction_features = [ \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "                        \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "                        'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "                        'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Extract targets\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Calculate competition weights\n",
    "    train_weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Prediction ---\n",
    "    # Train sex model\n",
    "    model_sex.fit(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']), y_train_sex, sample_weight=train_weights)\n",
    "    \n",
    "    # Get sex probabilities\n",
    "    sex_train_proba = model_sex.predict_proba(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "\n",
    "    # --- ADHD Prediction with Interaction Features ---\n",
    "    # Create enhanced features\n",
    "    X_train_adhd = X_train.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    X_val_adhd = X_val.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    \n",
    "    # Add sex probability feature\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "    \n",
    "    # Add interaction terms\n",
    "    for col in interaction_features:\n",
    "        X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "        X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    # Train ADHD model\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # --- Competition Validation ---\n",
    "    sex_pred = model_sex.predict(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Calculate weighted F1 scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# --- Final Competition Scoring ---\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (average of both F1 scores)\n",
    "final_score = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score:.4f}\")\n",
    "\n",
    "print(f\"Mean Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Mean ADHD_Outcome F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (harmonic mean of average F1s)\n",
    "final_score = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Harmonic Mean): {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptoms only used (no fMRI), added more female symptoms features to interaction_features same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.4407\n",
      "ADHD_Outcome F1: 0.8894\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.4978\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5415\n",
      "ADHD_Outcome F1: 0.8486\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5250\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5804\n",
      "ADHD_Outcome F1: 0.8874\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5171 ± 0.0466\n",
      "Average ADHD F1: 0.8762 ± 0.0154\n",
      "\n",
      "Competition Score (Normal Mean): 0.6966\n",
      "Competition Score (Harmonic Mean of Averages): 0.6503\n",
      "Competition Score (Average of Harmonic Means): 0.6489\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify based on Sex_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.5344\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.5225\n",
      "ADHD_Outcome F1: 0.8756\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5316\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5103\n",
      "ADHD_Outcome F1: 0.8973\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5299\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5258 ± 0.0087\n",
      "Average ADHD F1: 0.8835 ± 0.0097\n",
      "\n",
      "Competition Score (Normal Mean): 0.7046\n",
      "Competition Score (Harmonic Mean of Averages): 0.6592\n",
      "Competition Score (Average of Harmonic Means): 0.6591\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C=10 for Sex, Stratify on Sex, No fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Fold 1 ===\n",
      "Sex_F -> F1: 0.4910\n",
      "ADHD_Outcome -> F1: 0.8681\n",
      "\n",
      "==== Fold 2 ===\n",
      "Sex_F -> F1: 0.4819\n",
      "ADHD_Outcome -> F1: 0.8475\n",
      "\n",
      "==== Fold 3 ===\n",
      "Sex_F -> F1: 0.4734\n",
      "ADHD_Outcome -> F1: 0.8523\n",
      "\n",
      "==== Fold 4 ===\n",
      "Sex_F -> F1: 0.4767\n",
      "ADHD_Outcome -> F1: 0.8753\n",
      "\n",
      "==== Fold 5 ===\n",
      "Sex_F -> F1: 0.4790\n",
      "ADHD_Outcome -> F1: 0.8644\n",
      "\n",
      "==== Overall Results ===\n",
      "Mean F1-scores:\n",
      "    ADHD_Outcome -> F1: 0.8615\n",
      "    Sex_F -> F1: 0.4804\n",
      "\n",
      "F1-score stds:\n",
      "    ADHD_Outcome -> Std: 0.0103\n",
      "    Sex_F -> Std: 0.0060\n",
      "\n",
      "Standard deviations of test sets:\n",
      "    {'ADHD_Outcome': 0.46115656157267876, 'Sex_F': 0.4752128960101643}\n",
      "    {'ADHD_Outcome': 0.47788916775847196, 'Sex_F': 0.4752128960101643}\n",
      "    {'ADHD_Outcome': 0.4693800748445646, 'Sex_F': 0.47657075200345245}\n",
      "    {'ADHD_Outcome': 0.44628480198336107, 'Sex_F': 0.475687132835641}\n",
      "    {'ADHD_Outcome': 0.46833112435802715, 'Sex_F': 0.475687132835641}\n",
      "\n",
      "score mean (ADHD Sex):  [0.86152011 0.48042091]\n",
      "\n",
      "Final Overall Harmonic Mean (Mimic Leaderboard):  0.6167636839329982\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']  # Define target columns\n",
    "\n",
    "# Define non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "F1s = []\n",
    "stds = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n==== Fold {fold_number} ===\")\n",
    "    \n",
    "    train_v = train.iloc[train_index]\n",
    "    test_v = train.iloc[test_index]\n",
    "    \n",
    "    # Sample weights\n",
    "    weights = ((train_v['Sex_F'] == 1) & (train_v['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(\n",
    "        train_v[non_connectome_features], \n",
    "        train_v['Sex_F'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    sex_pred = model_sex.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    model_adhd.fit(\n",
    "        train_v[non_connectome_features],\n",
    "        train_v['ADHD_Outcome'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    adhd_pred = model_adhd.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # Validation\n",
    "    valid_idx = test_v[target_cols].notna().all(axis=1)\n",
    "    valid_testset = test_v.loc[valid_idx, target_cols]\n",
    "\n",
    "    sex_f1 = f1_score(valid_testset['Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(valid_testset['ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome -> F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "    stds.append(test_v[target_cols].std())\n",
    "\n",
    "# Final scoring\n",
    "F1s = np.array(F1s)\n",
    "mean_f1_scores = F1s.mean(axis=0)\n",
    "print(\"\\n==== Overall Results ===\")\n",
    "print(\"Mean F1-scores:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> F1: {mean_f1_scores[i]:.4f}\")\n",
    "\n",
    "f1_stds = F1s.std(axis=0)\n",
    "print(\"\\nF1-score stds:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> Std: {f1_stds[i]:.4f}\")\n",
    "\n",
    "print(\"\\nStandard deviations of test sets:\")\n",
    "for std in stds:\n",
    "    print(f\"    {std.to_dict()}\")\n",
    "\n",
    "# Final harmonic mean score\n",
    "print(\"\\nscore mean (ADHD Sex): \", np.mean(F1s, axis=0))\n",
    "score = hmean(F1s, axis=0)  # Harmonic mean per fold\n",
    "score = hmean(score)        # Then overall harmonic mean\n",
    "print(\"\\nFinal Overall Harmonic Mean (Mimic Leaderboard): \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.5418\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.5286\n",
      "ADHD_Outcome F1: 0.8756\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5246\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5301\n",
      "ADHD_Outcome F1: 0.8973\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5272\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5305 ± 0.0060\n",
      "Average ADHD F1: 0.8835 ± 0.0097\n",
      "\n",
      "Competition Score (Normal Mean): 0.7070\n",
      "Competition Score (Harmonic Mean of Averages): 0.6629\n",
      "Competition Score (Average of Harmonic Means): 0.6629\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUNNING YOUR ORIGINAL APPROACH\n",
      "========================================\n",
      "\n",
      "\n",
      "=== YOUR FINAL RESULTS ===\n",
      "Average Sex_F F1: 0.7010 ± 0.0189\n",
      "Average ADHD F1: 0.4598 ± 0.0263\n",
      "\n",
      "YOUR Competition Score (Normal Mean): 0.5804\n",
      "YOUR Competition Score (Harmonic Mean of Averages): 0.5554\n",
      "YOUR Competition Score (Average of Harmonic Means): 0.5545\n",
      "\n",
      "========================================\n",
      "RUNNING AHMED'S APPROACH\n",
      "========================================\n",
      "\n",
      "\n",
      "==== Fold 1 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5467 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8250 (Ahmed)\n",
      "\n",
      "==== Fold 2 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5782 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8418 (Ahmed)\n",
      "\n",
      "==== Fold 3 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.4552 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.7925 (Ahmed)\n",
      "\n",
      "==== Fold 4 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5072 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8483 (Ahmed)\n",
      "\n",
      "==== Fold 5 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5017 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8344 (Ahmed)\n",
      "\n",
      "==== AHMED'S OVERALL RESULTS ====\n",
      "Mean F1-scores:\n",
      "    ADHD_Outcome -> F1: 0.8284\n",
      "    Sex_F -> F1: 0.5178\n",
      "\n",
      "=== RUNNING YOUR APPROACH ===\n",
      "\n",
      "\n",
      "=== RUNNING AHMED'S APPROACH ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Approach\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1 (mean)                |          0.7010 |          0.5178\n",
      "ADHD F1 (mean)                 |          0.4598 |          0.8284\n",
      "Normal Mean                    |          0.5804 |          0.6731\n",
      "Harmonic Mean of Averages      |          0.5554 |          0.6373\n",
      "Average of Harmonic Means      |          0.5545 |          0.6366\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH (ORIGINAL)\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RUNNING YOUR ORIGINAL APPROACH\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# [Rest of your original code up to the final scoring]\n",
    "# ... [All your original code remains unchanged until the final scoring]\n",
    "\n",
    "# Final results - Your approach\n",
    "print(\"\\n=== YOUR FINAL RESULTS ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Your scoring methods\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nYOUR Competition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"YOUR Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"YOUR Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RUNNING AHMED'S APPROACH\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# Re-initialize models for Ahmed's approach\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,  # Using Ahmed's C value\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Ahmed's addition\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,  # Using Ahmed's C value\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Ahmed's addition\n",
    ")\n",
    "\n",
    "# Ahmed's score containers\n",
    "F1s = []\n",
    "stds = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(cv.split(train[non_connectome_features], train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n==== Fold {fold_number} === (Ahmed's Approach)\")\n",
    "    \n",
    "    train_v = train.iloc[train_index]\n",
    "    test_v = train.iloc[test_index]\n",
    "    \n",
    "    # Ahmed's weight calculation (same as yours)\n",
    "    weights = ((train_v['Sex_F'] == 1) & (train_v['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex_ahmed.fit(\n",
    "        train_v[non_connectome_features], \n",
    "        train_v['Sex_F'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    sex_pred = model_sex_ahmed.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    model_adhd_ahmed.fit(\n",
    "        train_v[non_connectome_features],\n",
    "        train_v['ADHD_Outcome'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    adhd_pred = model_adhd_ahmed.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # Ahmed's validation with null check\n",
    "    valid_idx = test_v[target_cols].notna().all(axis=1)\n",
    "    valid_testset = test_v.loc[valid_idx, target_cols]\n",
    "\n",
    "    sex_f1 = f1_score(valid_testset['Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(valid_testset['ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f} (Ahmed)\")\n",
    "    print(f\"ADHD_Outcome -> F1: {adhd_f1:.4f} (Ahmed)\")\n",
    "\n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "    stds.append(test_v[target_cols].std())\n",
    "\n",
    "# Ahmed's final scoring\n",
    "F1s = np.array(F1s)\n",
    "mean_f1_scores = F1s.mean(axis=0)\n",
    "print(\"\\n==== AHMED'S OVERALL RESULTS ====\")\n",
    "print(\"Mean F1-scores:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> F1: {mean_f1_scores[i]:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING YOUR APPROACH ===\\n\")\n",
    "\n",
    "# [Your original code execution...]\n",
    "\n",
    "your_results = {\n",
    "    \"Sex_F F1 (mean)\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1 (mean)\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Harmonic Mean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING AHMED'S APPROACH ===\\n\")\n",
    "\n",
    "# [Ahmed's code execution...]\n",
    "\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1 (mean)\": F1s[:,1].mean(),\n",
    "    \"ADHD F1 (mean)\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"Harmonic Mean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    \"Double Harmonic Mean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "# ========================\n",
    "# SIDE-BY-SIDE COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Approach\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_results[key]))\n",
    "# Show Ahmed's special score separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING YOUR APPROACH ===\n",
      "\n",
      "\n",
      "=== RUNNING AHMED'S APPROACH ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Approach\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1 (mean)                |          0.7010 |          0.5178\n",
      "ADHD F1 (mean)                 |          0.4598 |          0.8284\n",
      "Normal Mean                    |          0.5804 |          0.6731\n",
      "Harmonic Mean of Averages      |          0.5554 |          0.6373\n",
      "Average of Harmonic Means      |          0.5545 |          0.6366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING YOUR APPROACH ===\\n\")\n",
    "\n",
    "# [Your original code execution...]\n",
    "\n",
    "your_results = {\n",
    "    \"Sex_F F1 (mean)\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1 (mean)\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Harmonic Mean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING AHMED'S APPROACH ===\\n\")\n",
    "\n",
    "# [Ahmed's code execution...]\n",
    "\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1 (mean)\": F1s[:,1].mean(),\n",
    "    \"ADHD F1 (mean)\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"Harmonic Mean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    \"Double Harmonic Mean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "# ========================\n",
    "# SIDE-BY-SIDE COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Approach\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_results[key]))\n",
    "# Show Ahmed's special score separately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train ADHD model on symptoms only, sex model on all data or fMRI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== Fold 1 (Adjusted) ===\n",
      "Sex_F F1: 0.7221\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 (Adjusted) ===\n",
      "Sex_F F1: 0.6894\n",
      "ADHD_Outcome F1: 0.8736\n",
      "\n",
      "=== Fold 3 (Adjusted) ===\n",
      "Sex_F F1: 0.7251\n",
      "ADHD_Outcome F1: 0.8680\n",
      "\n",
      "=== Fold 4 (Adjusted) ===\n",
      "Sex_F F1: 0.6783\n",
      "ADHD_Outcome F1: 0.8977\n",
      "\n",
      "=== Fold 5 (Adjusted) ===\n",
      "Sex_F F1: 0.6901\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== AHMED'S APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== Fold 1 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6167\n",
      "ADHD_Outcome F1: 0.8681\n",
      "\n",
      "=== Fold 2 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6066\n",
      "ADHD_Outcome F1: 0.8475\n",
      "\n",
      "=== Fold 3 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6441\n",
      "ADHD_Outcome F1: 0.8523\n",
      "\n",
      "=== Fold 4 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.5749\n",
      "ADHD_Outcome F1: 0.8753\n",
      "\n",
      "=== Fold 5 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.5887\n",
      "ADHD_Outcome F1: 0.8644\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Adjusted\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1                       |          0.5305 |          0.6062\n",
      "ADHD F1                        |          0.8835 |          0.8615\n",
      "Normal Mean                    |          0.7070 |          0.7339\n",
      "HMean of Averages              |          0.6629 |          0.7116\n",
      "Avg of HMeans                  |          0.6629 |          0.7112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Feature selection\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous initialization code remains the same...]\n",
    "\n",
    "# Key fix: Use the same features for stratification as for training\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Cross-validation - stratify on the full features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use ALL features ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use only non-connectome features ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=train_weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Your adjusted results\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# [Rest of the code remains the same...]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize Ahmed's models with your requested changes\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=10,  # Changed from 0.02 to 10 for sex model\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=0.02,  # Kept original C value for ADHD\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Cross-validation - now stratifying by Sex_F\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Ahmed Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use full feature set ---\n",
    "    full_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Validation\n",
    "    valid_idx = X_val[target_cols].notna().all(axis=1)\n",
    "    sex_f1 = f1_score(X_val.loc[valid_idx, 'Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(X_val.loc[valid_idx, 'ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "\n",
    "F1s = np.array(F1s)\n",
    "\n",
    "# Adjusted results without Double Harmonic Mean\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s])\n",
    "    # Removed \"Double HMean\"\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_adjusted_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_adjusted_results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Adjusted\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1                       |          0.7010 |          0.6062\n",
      "ADHD F1                        |          0.8828 |          0.8615\n",
      "Normal Mean                    |          0.7919 |          0.7339\n",
      "HMean of Averages              |          0.7814 |          0.7116\n",
      "Avg of HMeans                  |          0.7812 |          0.7112\n",
      "Double HMean                   |          0.7811 |          0.7110\n"
     ]
    }
   ],
   "source": [
    "# Adding double hmean\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous code remains identical until the results section...]\n",
    "\n",
    "# Your adjusted results - now with teammate's scoring method\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous code remains identical until the results section...]\n",
    "\n",
    "# Ahmed's adjusted results - now with teammate's scoring method\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON (WITH BETTER ORDERING)\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define the preferred order of metrics\n",
    "preferred_order = [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]\n",
    "\n",
    "# Print metrics in the specified order\n",
    "for key in preferred_order:\n",
    "    your_val = your_adjusted_results.get(key, \"-\")\n",
    "    ahmed_val = ahmed_adjusted_results.get(key, \"-\")\n",
    "    \n",
    "    if isinstance(your_val, float):\n",
    "        your_val = f\"{your_val:.4f}\"\n",
    "    if isinstance(ahmed_val, float):\n",
    "        ahmed_val = f\"{ahmed_val:.4f}\"\n",
    "    \n",
    "    print(\"{:<30} | {:>15} | {:>15}\".format(key, your_val, ahmed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Feature selection\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous initialization code remains the same...]\n",
    "\n",
    "# Key fix: Use the same features for stratification as for training\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Cross-validation - stratify on the full features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use ALL features ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use only non-connectome features ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=train_weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Your adjusted results\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize Ahmed's models with your requested changes\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=10,  # Changed from 0.02 to 10 for sex model\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=0.02,  # Kept original C value for ADHD\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Cross-validation - now stratifying by Sex_F\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Ahmed Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use full feature set ---\n",
    "    full_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Validation\n",
    "    valid_idx = X_val[target_cols].notna().all(axis=1)\n",
    "    sex_f1 = f1_score(X_val.loc[valid_idx, 'Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(X_val.loc[valid_idx, 'ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "\n",
    "F1s = np.array(F1s)\n",
    "\n",
    "# Adjusted results without Double Harmonic Mean\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON (WITH BETTER ORDERING)\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define the preferred order of metrics\n",
    "preferred_order = [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]\n",
    "\n",
    "# Print metrics in the specified order\n",
    "for key in preferred_order:\n",
    "    your_val = your_adjusted_results.get(key, \"-\")\n",
    "    ahmed_val = ahmed_adjusted_results.get(key, \"-\")\n",
    "    \n",
    "    if isinstance(your_val, float):\n",
    "        your_val = f\"{your_val:.4f}\"\n",
    "    if isinstance(ahmed_val, float):\n",
    "        ahmed_val = f\"{ahmed_val:.4f}\"\n",
    "    \n",
    "    print(\"{:<30} | {:>15} | {:>15}\".format(key, your_val, ahmed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (FIXED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric          |         Your |      Ahmed's\n",
      "---------------------------------------------\n",
      "Sex_F F1        |       0.7010 |       0.7010\n",
      "ADHD F1         |       0.8828 |       0.8828\n",
      "Double HMean    |       0.7811 |       0.7811\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - stratify using ALL features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "\n",
    "    # Correct sample weights for validation set\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Double HMean\": hmean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (FIXED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (FIXED) ===\\n\")\n",
    "\n",
    "# Initialize models (same as yours)\n",
    "model_sex_ahmed = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd_ahmed = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - identical splitting\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # Scores\n",
    "    F1s.append([\n",
    "        f1_score(X_val['ADHD_Outcome'], adhd_pred, sample_weight=val_weights),\n",
    "        f1_score(X_val['Sex_F'], sex_pred, sample_weight=val_weights)\n",
    "    ])\n",
    "    \n",
    "\n",
    "F1s = np.array(F1s)\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# FINAL COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<15} | {:>12} | {:>12}\".format(\"Metric\", \"Your\", \"Ahmed's\"))\n",
    "print(\"-\" * 45)\n",
    "for metric in [\"Sex_F F1\", \"ADHD F1\", \"Double HMean\"]:\n",
    "    print(\"{:<15} | {:>12.4f} | {:>12.4f}\".format(\n",
    "        metric, \n",
    "        your_results[metric], \n",
    "        ahmed_results[metric]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing seed to see if CV is overfitting or consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (FIXED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric          |         Your |      Ahmed's\n",
      "---------------------------------------------\n",
      "Sex_F F1        |       0.7088 |       0.7088\n",
      "ADHD F1         |       0.8801 |       0.8801\n",
      "Double HMean    |       0.7848 |       0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n=== FINAL COMPARISON ===\\nMetric          |         Your |      Ahmed's\\n---------------------------------------------\\nSex_F F1        |       0.7010 |       0.7010\\nADHD F1         |       0.8828 |       0.8828\\nDouble HMean    |       0.7811 |       0.7811\\n\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment with different seed, default thresholding\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - stratify using ALL features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "\n",
    "    # Correct sample weights for validation set\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Double HMean\": hmean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (FIXED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (FIXED) ===\\n\")\n",
    "\n",
    "# Initialize models (same as yours)\n",
    "model_sex_ahmed = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd_ahmed = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - identical splitting\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # Scores\n",
    "    F1s.append([\n",
    "        f1_score(X_val['ADHD_Outcome'], adhd_pred, sample_weight=val_weights),\n",
    "        f1_score(X_val['Sex_F'], sex_pred, sample_weight=val_weights)\n",
    "    ])\n",
    "    \n",
    "\n",
    "F1s = np.array(F1s)\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# FINAL COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<15} | {:>12} | {:>12}\".format(\"Metric\", \"Your\", \"Ahmed's\"))\n",
    "print(\"-\" * 45)\n",
    "for metric in [\"Sex_F F1\", \"ADHD F1\", \"Double HMean\"]:\n",
    "    print(\"{:<15} | {:>12.4f} | {:>12.4f}\".format(\n",
    "        metric, \n",
    "        your_results[metric], \n",
    "        ahmed_results[metric]\n",
    "    ))\n",
    "\n",
    "\"\"\"\n",
    "Output\n",
    "Seed: 42 Normal thresholds: 0.5\n",
    "=== FINAL COMPARISON ===\n",
    "Metric          |         Your |      Ahmed's\n",
    "---------------------------------------------\n",
    "Sex_F F1        |       0.7010 |       0.7010\n",
    "ADHD F1         |       0.8828 |       0.8828\n",
    "Double HMean    |       0.7811 |       0.7811\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Thresholds: 0.3 sex, 0.4 adhd\n",
    "=== FINAL COMPARISON ===\n",
    "Metric          |         Your |      Ahmed's\n",
    "---------------------------------------------\n",
    "Sex_F F1        |       0.7088 |       0.7088\n",
    "ADHD F1         |       0.8801 |       0.8801\n",
    "Double HMean    |       0.7848 |       0.7848\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold: Sex 0.3 all data, ADHD 0.4 only connectome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F -> F1: 0.6798\n",
      "Outcome ADHD -> F1: 0.9213\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F -> F1: 0.7104\n",
      "Outcome ADHD -> F1: 0.8547\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F -> F1: 0.7088\n",
      "Outcome ADHD -> F1: 0.8815\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F -> F1: 0.6786\n",
      "Outcome ADHD -> F1: 0.8705\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F -> F1: 0.7024\n",
      "Outcome ADHD -> F1: 0.8973\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach\n",
      "--------------------------------------------------\n",
      "Sex_F F1                       |          0.6960\n",
      "ADHD F1                        |          0.8850\n",
      "Normal Mean                    |          0.7905\n",
      "HMean of Averages              |          0.7792\n",
      "Avg of HMeans                  |          0.7789\n",
      "Double HMean                   |          0.7788\n"
     ]
    }
   ],
   "source": [
    "#Threshold: Sex 0.3 all data, ADHD 0.4 only connectome data\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED) WITH THRESHOLDS\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "SEX_THRESHOLD = 0.3\n",
    "ADHD_THRESHOLD = 0.4\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Train and predict for Sex\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_proba = model_sex.predict_proba(X_val[full_features])[:, 1]\n",
    "    sex_pred = (sex_proba >= SEX_THRESHOLD).astype(int)\n",
    "\n",
    "    # --- Train and predict for ADHD\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_proba = model_adhd.predict_proba(X_val[non_connectome_features])[:, 1]\n",
    "    adhd_pred = (adhd_proba >= ADHD_THRESHOLD).astype(int)\n",
    "\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "    # === Fold Output\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f}\")\n",
    "    print(f\"Outcome ADHD -> F1: {adhd_f1:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# FINAL RESULTS\n",
    "# ========================\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "# Clean and simplified output\n",
    "print(\"=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15}\".format(\"Metric\", \"Your Approach\"))\n",
    "print(\"-\" * 50)\n",
    "for key in [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]:\n",
    "    print(\"{:<30} | {:>15.4f}\".format(key, your_results[key]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Output:\n",
    "=== YOUR APPROACH (ADJUSTED) ===\n",
    "\n",
    "=== Fold 1 ===\n",
    "Sex_F -> F1: 0.6798\n",
    "Outcome ADHD -> F1: 0.9213\n",
    "\n",
    "=== Fold 2 ===\n",
    "Sex_F -> F1: 0.7104\n",
    "Outcome ADHD -> F1: 0.8547\n",
    "\n",
    "=== Fold 3 ===\n",
    "Sex_F -> F1: 0.7088\n",
    "Outcome ADHD -> F1: 0.8815\n",
    "\n",
    "=== Fold 4 ===\n",
    "Sex_F -> F1: 0.6786\n",
    "Outcome ADHD -> F1: 0.8705\n",
    "\n",
    "=== Fold 5 ===\n",
    "Sex_F -> F1: 0.7024\n",
    "Outcome ADHD -> F1: 0.8973\n",
    "\n",
    "=== FINAL COMPARISON ===\n",
    "Metric                         |   Your Approach\n",
    "--------------------------------------------------\n",
    "Sex_F F1                       |          0.6960\n",
    "ADHD F1                        |          0.8850\n",
    "Normal Mean                    |          0.7905\n",
    "HMean of Averages              |          0.7792\n",
    "Avg of HMeans                  |          0.7789\n",
    "Double HMean                   |          0.7788\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ALL FEATURES) ===\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m weights \u001b[38;5;241m=\u001b[39m ((y_train_sex \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (y_train_adhd \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- Train and predict for Sex (using all features)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[43mmodel_sex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfull_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m sex_proba \u001b[38;5;241m=\u001b[39m model_sex\u001b[38;5;241m.\u001b[39mpredict_proba(X_val[full_features])[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     36\u001b[0m sex_pred \u001b[38;5;241m=\u001b[39m (sex_proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m SEX_THRESHOLD)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:543\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    540\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[0;32m    541\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[1;32m--> 543\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[0;32m    564\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[1;32m--> 323\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[0;32m    348\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    351\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# All data for both models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "import numpy as np\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH (ALL FEATURES FOR BOTH MODELS)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ALL FEATURES) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "SEX_THRESHOLD = 0.3\n",
    "ADHD_THRESHOLD = 0.4\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Train and predict for Sex (using all features)\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_proba = model_sex.predict_proba(X_val[full_features])[:, 1]\n",
    "    sex_pred = (sex_proba >= SEX_THRESHOLD).astype(int)\n",
    "\n",
    "    # --- Train and predict for ADHD (now also using all features)\n",
    "    model_adhd.fit(X_train[full_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_proba = model_adhd.predict_proba(X_val[full_features])[:, 1]\n",
    "    adhd_pred = (adhd_proba >= ADHD_THRESHOLD).astype(int)\n",
    "\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "    # === Fold Output\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f}\")\n",
    "    print(f\"Outcome ADHD -> F1: {adhd_f1:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# FINAL RESULTS\n",
    "# ========================\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "# Clean and simplified output\n",
    "print(\"=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15}\".format(\"Metric\", \"Your Approach\"))\n",
    "print(\"-\" * 50)\n",
    "for key in [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]:\n",
    "    print(\"{:<30} | {:>15.4f}\".format(key, your_results[key]))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "output incomplete becuz of error:\n",
    "=== YOUR APPROACH (ALL FEATURES) ===\n",
    "\n",
    "=== Fold 1 ===\n",
    "Sex_F -> F1: 0.6798\n",
    "Outcome ADHD -> F1: 0.5130\n",
    "\n",
    "=== Fold 2 ===\n",
    "Sex_F -> F1: 0.7104\n",
    "Outcome ADHD -> F1: 0.3852\n",
    "\n",
    "=== Fold 3 ===\n",
    "Sex_F -> F1: 0.7088\n",
    "Outcome ADHD -> F1: 0.4422\n",
    "\n",
    "=== Fold 4 ===\n",
    "Sex_F -> F1: 0.6786\n",
    "Outcome ADHD -> F1: 0.4859\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (LIGHTGBM) ===\n",
      "\n",
      "[LightGBM] [Warning] Unknown parameter: verbos\n",
      "[LightGBM] [Warning] Unknown parameter: verbos\n",
      "[LightGBM] [Info] Number of positive: 333, number of negative: 637\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "import numpy as np\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH (LIGHTGBM)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (LIGHTGBM) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "SEX_THRESHOLD = 0.3\n",
    "ADHD_THRESHOLD = 0.4\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LGBMClassifier(random_state=SEED, n_estimators=100, learning_rate=0.05, verbos = -1)\n",
    "model_adhd = LGBMClassifier(random_state=SEED, n_estimators=100, learning_rate=0.05, verbos = -1)\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Train and predict for Sex (all features)\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_proba = model_sex.predict_proba(X_val[full_features])[:, 1]\n",
    "    sex_pred = (sex_proba >= SEX_THRESHOLD).astype(int)\n",
    "\n",
    "    # --- Train and predict for ADHD (all features)\n",
    "    model_adhd.fit(X_train[full_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_proba = model_adhd.predict_proba(X_val[full_features])[:, 1]\n",
    "    adhd_pred = (adhd_proba >= ADHD_THRESHOLD).astype(int)\n",
    "\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "    # === Fold Output\n",
    "    print(f\"=== Fold {fold} ===\")\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f}\")\n",
    "    print(f\"Outcome ADHD -> F1: {adhd_f1:.4f}\\n\")\n",
    "\n",
    "\n",
    "# ========================\n",
    "# FINAL RESULTS\n",
    "# ========================\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "# Clean and simplified output\n",
    "print(\"=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15}\".format(\"Metric\", \"Your Approach\"))\n",
    "print(\"-\" * 50)\n",
    "for key in [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]:\n",
    "    print(\"{:<30} | {:>15.4f}\".format(key, your_results[key]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the notebook in a nutshell \n",
    "- importing \n",
    "software dependencies we need\n",
    "- load_data (please read its description it supposed to be very easy to deal with it)\n",
    "\n",
    "###  preprocesssing \n",
    "- I stored some important variables, then I used log transformation for long tailed distributions\n",
    "\n",
    "- iterative imputer just like what `MAAB` Advised\n",
    "\n",
    "- transormed the categorical features to be from the string type just to avoid some fitting isssues cause by the \n",
    "OneHotEncoder.\n",
    "\n",
    "- droped the `participant_ID` after storing it for stratification\n",
    "\n",
    "- I scaled quantative data and also FMRI data \n",
    "\n",
    "### modeling\n",
    "- base model is logisitc regression with l2 regulization (fancy name for punishing the model to stop overfitting to noise) \n",
    "- wrapped inside a multioutput classifier that just gives it the ability to predict 2 targets simultaneously\n",
    "### validation \n",
    "- 5 splits stratifiedKFold works fine no need for grouping as participants are unique \n",
    "- regular stratified  = 0.5901173137436236\n",
    "- RepeatedStratifiedKFold =0.5865925294336686 with 7 minutese delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import hmean\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import scipy\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer #it might not work directly if not try the following code line\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold,StratifiedKFold,RepeatedStratifiedKFold\n",
    "from pathlib import Path\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just drop the path of your new data directory nothing more than that. \n",
    "\n",
    "\"\"\"\n",
    "path = r\"C:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\Data\\raw\"\n",
    "\n",
    "def read_data(base_path:str) -> pd.DataFrame :\n",
    "    path = Path(base_path)\n",
    "    trc=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    trq=pd.read_excel(path /'TRAIN_NEW'  / 'TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    trf=pd.read_csv(path   /'TRAIN_NEW'  / 'TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    trs=pd.read_excel(path /'TRAIN_NEW'  / 'TRAINING_SOLUTIONS.xlsx')  \n",
    "    tsc=pd.read_excel(path /'TEST'      / 'TEST_CATEGORICAL.xlsx')\n",
    "    tsq=pd.read_excel(path /'TEST'       / 'TEST_QUANTITATIVE_METADATA.xlsx')    \n",
    "    tsf=pd.read_csv(path   /'TEST'       / 'TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')    \n",
    "    sub=pd.read_excel(path / 'SAMPLE_SUBMISSION.xlsx')\n",
    "    dic=pd.read_excel(path /'Data Dictionary.xlsx')\n",
    "    return trc, trq, trf, trs, tsc, tsq, tsf, sub, dic\n",
    "\n",
    "trc, trq, trf, trs, tsc, tsq, tsf, sub, dic = read_data(base_path=path)\n",
    "\n",
    "# Data Merging \n",
    "cq = pd.merge(trc, trq, on='participant_id', how='left')\n",
    "feat = pd.merge(cq, trf, on='participant_id', how='left')  \n",
    "qc = pd.merge(tsc, tsq, on='participant_id', how='left')\n",
    "train = pd.merge(feat, trs, on='participant_id', how='left') \n",
    "test = pd.merge(qc, tsf, on='participant_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Features before Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your coefficients (estimated from your description)\n",
    "female_coefs = {\n",
    "    'ColorVision_CV_Score': 2.900,\n",
    "    'SDQ_SDQ_Emotional_Problems': 2.814,\n",
    "    'SDQ_SDQ_Prosocial': 2.661,\n",
    "    'SDQ_SDQ_Internalizing': 1.382,\n",
    "    'SDQ_SDQ_Conduct_Problems': 1.329,\n",
    "    'SDQ_SDQ_Generating_Impact': 1.109,\n",
    "    'APQ_P_APQ_P_PM': 0.642\n",
    "}\n",
    "\n",
    "male_coefs = {\n",
    "    'SDQ_SDQ_Hyperactivity': -3.088,\n",
    "    'APQ_P_APQ_P_PP': -1.903,\n",
    "    'SDQ_SDQ_Externalizing': -1.447,\n",
    "    'APQ_P_APQ_P_CP': -1.380,\n",
    "    'APQ_P_APQ_P_INV': -0.437,\n",
    "    'APQ_P_APQ_P_OPD': -0.676,\n",
    "    'SDQ_SDQ_Peer_Problems': -0.596\n",
    "}\n",
    "\n",
    "# Compute weighted sums\n",
    "train['female_symptom_score'] = sum(train[feat] * coef for feat, coef in female_coefs.items())\n",
    "train['male_symptom_score'] = sum(train[feat] * coef for feat, coef in male_coefs.items())\n",
    "\n",
    "test['female_symptom_score'] = sum(test[feat] * coef for feat, coef in female_coefs.items())\n",
    "test['male_symptom_score'] = sum(test[feat] * coef for feat, coef in male_coefs.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    'MRI_Track_Age_at_Scan', 'Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site',\n",
    "    'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "    'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu',\n",
    "    'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu',\n",
    "    'Barratt_Barratt_P2_Occ', 'EHQ_EHQ_Total'\n",
    "]\n",
    "\n",
    "train_ids = train['participant_id']\n",
    "test_ids = test['participant_id'] # I will store them for later usage in grouping in validation why?  I don't want the same user to appear in both train and test. \n",
    "\n",
    "\n",
    "for df in (train, test):\n",
    "    df.set_index('participant_id', inplace=True)\n",
    "    df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n",
    "\n",
    "# for df in (train,test):\n",
    "#     # df.drop(columns=['participant_id'], inplace=True) \n",
    "#     df.set_index('participant_id', inplace=True)\n",
    "#     df.drop(columns=['EHQ_EHQ_Total'], inplace=True) \n",
    "#     df.drop(columns=['MRI_Track_Age_at_Scan'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting important variables. \n",
    "# note that I did't deal with the quantative data trq as categorical\n",
    "# I will use the OneHotEncoder for the categorical data as we have some data trap that I don't think we can use the label encoder for. \n",
    "\n",
    "# for feature in trc.columns:\n",
    "#     train[feature] = train[feature].astype(object)\n",
    "num_feats = [feature for feature in train.columns if train[feature].dtype == 'float64']\n",
    "cat_feats = [feature for feature in train.columns if train[feature].dtype == 'object'] # seperate categorical and numerical features help me reteriving them later easily for preprocessing.\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features with positive skewness and non-negative values: apply log transformation\n",
    "# num_feats[:18] Don't transform fMRI data because it has negative values\n",
    "log_features = [f for f in num_feats[:18] if (train[f] >= 0).all() and scipy.stats.skew(train[f]) > 0.5]  # Only apply to features with significant positive skew\n",
    "\n",
    "# Apply log transformation for the selected features\n",
    "for feature in log_features:\n",
    "    train[feature] = np.log1p(train[feature])  # Apply log(x+1) to handle skewed features\n",
    "    test[feature] = np.log1p(test[feature])    # Apply log(x+1) to test data as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find columns with missing values only\n",
    "train_missing_features_to_impute = train.columns[train.isnull().any()].tolist() # List of features with missing values in train, only 25 and no missing data in fMRI data\n",
    "test_missing_features_to_impute = test.columns[test.isnull().any()].tolist() # List of features with missing values in test, only 23 and no missing data in fMRI data\n",
    "\n",
    "# Initialize the imputer\n",
    "imputer = IterativeImputer(estimator=LassoCV(random_state=42), max_iter=5, random_state=42)\n",
    "\n",
    "# Impute in-place\n",
    "train[train_missing_features_to_impute] = imputer.fit_transform(train[train_missing_features_to_impute])\n",
    "test[test_missing_features_to_impute] = imputer.fit_transform(test[test_missing_features_to_impute])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all categorical features have been dropped so no need for this.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"all categorical features have been dropped so no need for this.\"\"\"\n",
    "\n",
    "# # Convert all categorical features to strings (to avoid mixed types)\n",
    "# for feature in cat_feats:\n",
    "#     train[feature] = train[feature].astype(str)\n",
    "#     test[feature] = test[feature].astype(str)\n",
    "\n",
    "# # One-Hot Encoding for categorical features\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# for feature in cat_feats:\n",
    "#     if feature == 'participant_id':  # Skip participant_id since it's not a feature\n",
    "#         continue\n",
    "\n",
    "#     # Apply OneHotEncoder\n",
    "#     train_encoded = encoder.fit_transform(train[[feature]])\n",
    "#     test_encoded = encoder.transform(test[[feature]])\n",
    "\n",
    "#     # Convert encoded features to DataFrame and append them to the original data\n",
    "#     train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "#     test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out([feature]))\n",
    "\n",
    "#     # Drop the original feature and concatenate the new encoded columns\n",
    "#     train = pd.concat([train.drop(columns=[feature]), train_encoded_df], axis=1)\n",
    "#     test = pd.concat([test.drop(columns=[feature]), test_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Only apply scaling to numerical columns that are not part of the target or categorical features\n",
    "numerical_features = [col for col in train.columns if col not in target_cols and col not in cat_feats]\n",
    "\n",
    "# Fit scaler on the numerical features of the train set and transform train and test sets\n",
    "train[numerical_features] = scaler.fit_transform(train[numerical_features])  # Fit and transform for train set\n",
    "test[numerical_features] = scaler.transform(test[numerical_features])        # Only transform for test set (avoid data leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'female_symptom_score', 'male_symptom_score']\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "print(non_connectome_features)\n",
    "print(len(non_connectome_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data (fMRI and symtpoms) used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7391\n",
      "ADHD_Outcome F1: 0.4228\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.7345\n",
      "ADHD_Outcome F1: 0.4407\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.6424\n",
      "ADHD_Outcome F1: 0.4536\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.6984\n",
      "ADHD_Outcome F1: 0.4429\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.7077\n",
      "ADHD_Outcome F1: 0.4737\n",
      "\n",
      "=== Competition Results ===\n",
      "Sex_F F1: 0.7044 ± 0.0346\n",
      "ADHD F1: 0.4467 ± 0.0167\n",
      "\n",
      "Competition Score (Normal Mean): 0.5756\n",
      "Mean Sex_F F1: 0.7044 ± 0.0346\n",
      "Mean ADHD_Outcome F1: 0.4467 ± 0.0167\n",
      "\n",
      "Competition Score (Harmonic Mean): 0.5467\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "ADHD_WEIGHT = 2  # 2x weight for female ADHD cases\n",
    "\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models with competition-optimized parameters\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Configure cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store competition metrics\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Define important features for interaction (update with your actual features)\n",
    "interaction_features = [    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "                        \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score']  # Use actual column names\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Extract targets\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Calculate competition weights\n",
    "    train_weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) * (ADHD_WEIGHT - 1) + 1\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) * (ADHD_WEIGHT - 1) + 1\n",
    "\n",
    "    # --- Sex Prediction ---\n",
    "    # Train sex model\n",
    "    model_sex.fit(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']), y_train_sex, sample_weight=train_weights)\n",
    "    \n",
    "    # Get sex probabilities\n",
    "    sex_train_proba = model_sex.predict_proba(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "\n",
    "    # --- ADHD Prediction with Interaction Features ---\n",
    "    # Create enhanced features\n",
    "    X_train_adhd = X_train.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    X_val_adhd = X_val.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    \n",
    "    # Add sex probability feature\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "    \n",
    "    # Add interaction terms\n",
    "    for col in interaction_features:\n",
    "        X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "        X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    # Train ADHD model\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # --- Competition Validation ---\n",
    "    sex_pred = model_sex.predict(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Calculate weighted F1 scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# --- Final Competition Scoring ---\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (average of both F1 scores)\n",
    "final_score = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score:.4f}\")\n",
    "\n",
    "print(f\"Mean Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Mean ADHD_Outcome F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (harmonic mean of average F1s)\n",
    "final_score = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Harmonic Mean): {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data (fMRI and symtpoms) used, added more female symptoms features to interaction_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7391\n",
      "ADHD_Outcome F1: 0.4228\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.7345\n",
      "ADHD_Outcome F1: 0.4512\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.6424\n",
      "ADHD_Outcome F1: 0.4642\n",
      "\n",
      "=== Fold 4 ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[52], line 82\u001b[0m\n",
      "\u001b[0;32m     79\u001b[0m     X_val_adhd[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_x_sex\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m X_val_adhd[col] \u001b[38;5;241m*\u001b[39m X_val_adhd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex_proba\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Train ADHD model\u001b[39;00m\n",
      "\u001b[1;32m---> 82\u001b[0m \u001b[43mmodel_adhd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_adhd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_adhd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_weights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# --- Competition Validation ---\u001b[39;00m\n",
      "\u001b[0;32m     85\u001b[0m sex_pred \u001b[38;5;241m=\u001b[39m model_sex\u001b[38;5;241m.\u001b[39mpredict(X_val\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex_F\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1387\u001b[0m     )\n",
      "\u001b[0;32m   1388\u001b[0m ):\n",
      "\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1350\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m   1348\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m-> 1350\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1353\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1360\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1375\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n",
      "\u001b[0;32m   1376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[0;32m     76\u001b[0m )\n",
      "\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[1;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:543\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n",
      "\u001b[0;32m    540\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n",
      "\u001b[0;32m    541\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n",
      "\u001b[1;32m--> 543\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n",
      "\u001b[0;32m    562\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    563\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n",
      "\u001b[0;32m    564\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Maab\\Desktop\\ADHD_Kaggle_Competition\\Repo\\WiDS-Datathon-2025\\venv2\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n",
      "\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n",
      "\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    320\u001b[0m     )\n",
      "\u001b[0;32m    322\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n",
      "\u001b[1;32m--> 323\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n",
      "\u001b[0;32m    348\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n",
      "\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    350\u001b[0m         ConvergenceWarning,\n",
      "\u001b[0;32m    351\u001b[0m     )\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models with competition-optimized parameters\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Configure cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Store competition metrics\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Define important features for interaction (update with your actual features)\n",
    "interaction_features = [ \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "                        \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "                        'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "                        'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Extract targets\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Calculate competition weights\n",
    "    train_weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Prediction ---\n",
    "    # Train sex model\n",
    "    model_sex.fit(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']), y_train_sex, sample_weight=train_weights)\n",
    "    \n",
    "    # Get sex probabilities\n",
    "    sex_train_proba = model_sex.predict_proba(X_train.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))[:, 1]\n",
    "\n",
    "    # --- ADHD Prediction with Interaction Features ---\n",
    "    # Create enhanced features\n",
    "    X_train_adhd = X_train.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    X_val_adhd = X_val.drop(columns=['Sex_F', 'ADHD_Outcome']).copy()\n",
    "    \n",
    "    # Add sex probability feature\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "    \n",
    "    # Add interaction terms\n",
    "    for col in interaction_features:\n",
    "        X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "        X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    # Train ADHD model\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # --- Competition Validation ---\n",
    "    sex_pred = model_sex.predict(X_val.drop(columns=['Sex_F', 'ADHD_Outcome']))\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Calculate weighted F1 scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# --- Final Competition Scoring ---\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (average of both F1 scores)\n",
    "final_score = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score:.4f}\")\n",
    "\n",
    "print(f\"Mean Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Mean ADHD_Outcome F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Calculate final leaderboard score (harmonic mean of average F1s)\n",
    "final_score = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "print(f\"\\nCompetition Score (Harmonic Mean): {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symptoms only used (no fMRI), added more female symptoms features to interaction_features same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.4407\n",
      "ADHD_Outcome F1: 0.8894\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.4978\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5415\n",
      "ADHD_Outcome F1: 0.8486\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5250\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5804\n",
      "ADHD_Outcome F1: 0.8874\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5171 ± 0.0466\n",
      "Average ADHD F1: 0.8762 ± 0.0154\n",
      "\n",
      "Competition Score (Normal Mean): 0.6966\n",
      "Competition Score (Harmonic Mean of Averages): 0.6503\n",
      "Competition Score (Average of Harmonic Means): 0.6489\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratify based on Sex_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.5344\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.5225\n",
      "ADHD_Outcome F1: 0.8756\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5316\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5103\n",
      "ADHD_Outcome F1: 0.8973\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5299\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5258 ± 0.0087\n",
      "Average ADHD F1: 0.8835 ± 0.0097\n",
      "\n",
      "Competition Score (Normal Mean): 0.7046\n",
      "Competition Score (Harmonic Mean of Averages): 0.6592\n",
      "Competition Score (Average of Harmonic Means): 0.6591\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C=10 for Sex, Stratify on Sex, No fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Fold 1 ===\n",
      "Sex_F -> F1: 0.4910\n",
      "ADHD_Outcome -> F1: 0.8681\n",
      "\n",
      "==== Fold 2 ===\n",
      "Sex_F -> F1: 0.4819\n",
      "ADHD_Outcome -> F1: 0.8475\n",
      "\n",
      "==== Fold 3 ===\n",
      "Sex_F -> F1: 0.4734\n",
      "ADHD_Outcome -> F1: 0.8523\n",
      "\n",
      "==== Fold 4 ===\n",
      "Sex_F -> F1: 0.4767\n",
      "ADHD_Outcome -> F1: 0.8753\n",
      "\n",
      "==== Fold 5 ===\n",
      "Sex_F -> F1: 0.4790\n",
      "ADHD_Outcome -> F1: 0.8644\n",
      "\n",
      "==== Overall Results ===\n",
      "Mean F1-scores:\n",
      "    ADHD_Outcome -> F1: 0.8615\n",
      "    Sex_F -> F1: 0.4804\n",
      "\n",
      "F1-score stds:\n",
      "    ADHD_Outcome -> Std: 0.0103\n",
      "    Sex_F -> Std: 0.0060\n",
      "\n",
      "Standard deviations of test sets:\n",
      "    {'ADHD_Outcome': 0.46115656157267876, 'Sex_F': 0.4752128960101643}\n",
      "    {'ADHD_Outcome': 0.47788916775847196, 'Sex_F': 0.4752128960101643}\n",
      "    {'ADHD_Outcome': 0.4693800748445646, 'Sex_F': 0.47657075200345245}\n",
      "    {'ADHD_Outcome': 0.44628480198336107, 'Sex_F': 0.475687132835641}\n",
      "    {'ADHD_Outcome': 0.46833112435802715, 'Sex_F': 0.475687132835641}\n",
      "\n",
      "score mean (ADHD Sex):  [0.86152011 0.48042091]\n",
      "\n",
      "Final Overall Harmonic Mean (Mimic Leaderboard):  0.6167636839329982\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']  # Define target columns\n",
    "\n",
    "# Define non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "F1s = []\n",
    "stds = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n==== Fold {fold_number} ===\")\n",
    "    \n",
    "    train_v = train.iloc[train_index]\n",
    "    test_v = train.iloc[test_index]\n",
    "    \n",
    "    # Sample weights\n",
    "    weights = ((train_v['Sex_F'] == 1) & (train_v['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(\n",
    "        train_v[non_connectome_features], \n",
    "        train_v['Sex_F'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    sex_pred = model_sex.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    model_adhd.fit(\n",
    "        train_v[non_connectome_features],\n",
    "        train_v['ADHD_Outcome'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    adhd_pred = model_adhd.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # Validation\n",
    "    valid_idx = test_v[target_cols].notna().all(axis=1)\n",
    "    valid_testset = test_v.loc[valid_idx, target_cols]\n",
    "\n",
    "    sex_f1 = f1_score(valid_testset['Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(valid_testset['ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome -> F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "    stds.append(test_v[target_cols].std())\n",
    "\n",
    "# Final scoring\n",
    "F1s = np.array(F1s)\n",
    "mean_f1_scores = F1s.mean(axis=0)\n",
    "print(\"\\n==== Overall Results ===\")\n",
    "print(\"Mean F1-scores:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> F1: {mean_f1_scores[i]:.4f}\")\n",
    "\n",
    "f1_stds = F1s.std(axis=0)\n",
    "print(\"\\nF1-score stds:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> Std: {f1_stds[i]:.4f}\")\n",
    "\n",
    "print(\"\\nStandard deviations of test sets:\")\n",
    "for std in stds:\n",
    "    print(f\"    {std.to_dict()}\")\n",
    "\n",
    "# Final harmonic mean score\n",
    "print(\"\\nscore mean (ADHD Sex): \", np.mean(F1s, axis=0))\n",
    "score = hmean(F1s, axis=0)  # Harmonic mean per fold\n",
    "score = hmean(score)        # Then overall harmonic mean\n",
    "print(\"\\nFinal Overall Harmonic Mean (Mimic Leaderboard): \", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.5418\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.5286\n",
      "ADHD_Outcome F1: 0.8756\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.5246\n",
      "ADHD_Outcome F1: 0.8700\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.5301\n",
      "ADHD_Outcome F1: 0.8973\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.5272\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.5305 ± 0.0060\n",
      "Average ADHD F1: 0.8835 ± 0.0097\n",
      "\n",
      "Competition Score (Normal Mean): 0.7070\n",
      "Competition Score (Harmonic Mean of Averages): 0.6629\n",
      "Competition Score (Average of Harmonic Means): 0.6629\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "# Restrict to non-connectome features\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Restrict features to non-connectome\n",
    "    X_train = X_train_full[non_connectome_features].copy()\n",
    "    X_val = X_val_full[non_connectome_features].copy()\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "RUNNING YOUR ORIGINAL APPROACH\n",
      "========================================\n",
      "\n",
      "\n",
      "=== YOUR FINAL RESULTS ===\n",
      "Average Sex_F F1: 0.7010 ± 0.0189\n",
      "Average ADHD F1: 0.4598 ± 0.0263\n",
      "\n",
      "YOUR Competition Score (Normal Mean): 0.5804\n",
      "YOUR Competition Score (Harmonic Mean of Averages): 0.5554\n",
      "YOUR Competition Score (Average of Harmonic Means): 0.5545\n",
      "\n",
      "========================================\n",
      "RUNNING AHMED'S APPROACH\n",
      "========================================\n",
      "\n",
      "\n",
      "==== Fold 1 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5467 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8250 (Ahmed)\n",
      "\n",
      "==== Fold 2 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5782 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8418 (Ahmed)\n",
      "\n",
      "==== Fold 3 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.4552 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.7925 (Ahmed)\n",
      "\n",
      "==== Fold 4 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5072 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8483 (Ahmed)\n",
      "\n",
      "==== Fold 5 === (Ahmed's Approach)\n",
      "Sex_F -> F1: 0.5017 (Ahmed)\n",
      "ADHD_Outcome -> F1: 0.8344 (Ahmed)\n",
      "\n",
      "==== AHMED'S OVERALL RESULTS ====\n",
      "Mean F1-scores:\n",
      "    ADHD_Outcome -> F1: 0.8284\n",
      "    Sex_F -> F1: 0.5178\n",
      "\n",
      "=== RUNNING YOUR APPROACH ===\n",
      "\n",
      "\n",
      "=== RUNNING AHMED'S APPROACH ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Approach\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1 (mean)                |          0.7010 |          0.5178\n",
      "ADHD F1 (mean)                 |          0.4598 |          0.8284\n",
      "Normal Mean                    |          0.5804 |          0.6731\n",
      "Harmonic Mean of Averages      |          0.5554 |          0.6373\n",
      "Average of Harmonic Means      |          0.5545 |          0.6366\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH (ORIGINAL)\n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RUNNING YOUR ORIGINAL APPROACH\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# [Rest of your original code up to the final scoring]\n",
    "# ... [All your original code remains unchanged until the final scoring]\n",
    "\n",
    "# Final results - Your approach\n",
    "print(\"\\n=== YOUR FINAL RESULTS ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# Your scoring methods\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nYOUR Competition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"YOUR Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"YOUR Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"RUNNING AHMED'S APPROACH\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# Re-initialize models for Ahmed's approach\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,  # Using Ahmed's C value\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Ahmed's addition\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,  # Using Ahmed's C value\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    "    class_weight='balanced'  # Ahmed's addition\n",
    ")\n",
    "\n",
    "# Ahmed's score containers\n",
    "F1s = []\n",
    "stds = []\n",
    "\n",
    "for fold_number, (train_index, test_index) in enumerate(cv.split(train[non_connectome_features], train['ADHD_Outcome']), 1):\n",
    "    print(f\"\\n==== Fold {fold_number} === (Ahmed's Approach)\")\n",
    "    \n",
    "    train_v = train.iloc[train_index]\n",
    "    test_v = train.iloc[test_index]\n",
    "    \n",
    "    # Ahmed's weight calculation (same as yours)\n",
    "    weights = ((train_v['Sex_F'] == 1) & (train_v['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex_ahmed.fit(\n",
    "        train_v[non_connectome_features], \n",
    "        train_v['Sex_F'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    sex_pred = model_sex_ahmed.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    model_adhd_ahmed.fit(\n",
    "        train_v[non_connectome_features],\n",
    "        train_v['ADHD_Outcome'],\n",
    "        sample_weight=weights\n",
    "    )\n",
    "    adhd_pred = model_adhd_ahmed.predict(test_v[non_connectome_features])\n",
    "\n",
    "    # Ahmed's validation with null check\n",
    "    valid_idx = test_v[target_cols].notna().all(axis=1)\n",
    "    valid_testset = test_v.loc[valid_idx, target_cols]\n",
    "\n",
    "    sex_f1 = f1_score(valid_testset['Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(valid_testset['ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "\n",
    "    print(f\"Sex_F -> F1: {sex_f1:.4f} (Ahmed)\")\n",
    "    print(f\"ADHD_Outcome -> F1: {adhd_f1:.4f} (Ahmed)\")\n",
    "\n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "    stds.append(test_v[target_cols].std())\n",
    "\n",
    "# Ahmed's final scoring\n",
    "F1s = np.array(F1s)\n",
    "mean_f1_scores = F1s.mean(axis=0)\n",
    "print(\"\\n==== AHMED'S OVERALL RESULTS ====\")\n",
    "print(\"Mean F1-scores:\")\n",
    "for i, target in enumerate(target_cols):\n",
    "    print(f\"    {target} -> F1: {mean_f1_scores[i]:.4f}\")\n",
    "\n",
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING YOUR APPROACH ===\\n\")\n",
    "\n",
    "# [Your original code execution...]\n",
    "\n",
    "your_results = {\n",
    "    \"Sex_F F1 (mean)\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1 (mean)\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Harmonic Mean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING AHMED'S APPROACH ===\\n\")\n",
    "\n",
    "# [Ahmed's code execution...]\n",
    "\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1 (mean)\": F1s[:,1].mean(),\n",
    "    \"ADHD F1 (mean)\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"Harmonic Mean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    \"Double Harmonic Mean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "# ========================\n",
    "# SIDE-BY-SIDE COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Approach\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_results[key]))\n",
    "# Show Ahmed's special score separately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RUNNING YOUR APPROACH ===\n",
      "\n",
      "\n",
      "=== RUNNING AHMED'S APPROACH ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Approach\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1 (mean)                |          0.7010 |          0.5178\n",
      "ADHD F1 (mean)                 |          0.4598 |          0.8284\n",
      "Normal Mean                    |          0.5804 |          0.6731\n",
      "Harmonic Mean of Averages      |          0.5554 |          0.6373\n",
      "Average of Harmonic Means      |          0.5545 |          0.6366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING YOUR APPROACH ===\\n\")\n",
    "\n",
    "# [Your original code execution...]\n",
    "\n",
    "your_results = {\n",
    "    \"Sex_F F1 (mean)\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1 (mean)\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Harmonic Mean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== RUNNING AHMED'S APPROACH ===\\n\")\n",
    "\n",
    "# [Ahmed's code execution...]\n",
    "\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1 (mean)\": F1s[:,1].mean(),\n",
    "    \"ADHD F1 (mean)\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"Harmonic Mean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Average of Harmonic Means\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    \"Double Harmonic Mean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "# ========================\n",
    "# SIDE-BY-SIDE COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Approach\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_results[key]))\n",
    "# Show Ahmed's special score separately\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train ADHD model on symptoms only, sex model on all data or fMRI only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== Fold 1 (Adjusted) ===\n",
      "Sex_F F1: 0.7221\n",
      "ADHD_Outcome F1: 0.8856\n",
      "\n",
      "=== Fold 2 (Adjusted) ===\n",
      "Sex_F F1: 0.6894\n",
      "ADHD_Outcome F1: 0.8736\n",
      "\n",
      "=== Fold 3 (Adjusted) ===\n",
      "Sex_F F1: 0.7251\n",
      "ADHD_Outcome F1: 0.8680\n",
      "\n",
      "=== Fold 4 (Adjusted) ===\n",
      "Sex_F F1: 0.6783\n",
      "ADHD_Outcome F1: 0.8977\n",
      "\n",
      "=== Fold 5 (Adjusted) ===\n",
      "Sex_F F1: 0.6901\n",
      "ADHD_Outcome F1: 0.8889\n",
      "\n",
      "=== AHMED'S APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== Fold 1 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6167\n",
      "ADHD_Outcome F1: 0.8681\n",
      "\n",
      "=== Fold 2 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6066\n",
      "ADHD_Outcome F1: 0.8475\n",
      "\n",
      "=== Fold 3 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.6441\n",
      "ADHD_Outcome F1: 0.8523\n",
      "\n",
      "=== Fold 4 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.5749\n",
      "ADHD_Outcome F1: 0.8753\n",
      "\n",
      "=== Fold 5 (Ahmed Adjusted) ===\n",
      "Sex_F F1: 0.5887\n",
      "ADHD_Outcome F1: 0.8644\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Adjusted\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1                       |          0.5305 |          0.6062\n",
      "ADHD F1                        |          0.8835 |          0.8615\n",
      "Normal Mean                    |          0.7070 |          0.7339\n",
      "HMean of Averages              |          0.6629 |          0.7116\n",
      "Avg of HMeans                  |          0.6629 |          0.7112\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Feature selection\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous initialization code remains the same...]\n",
    "\n",
    "# Key fix: Use the same features for stratification as for training\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Cross-validation - stratify on the full features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use ALL features ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use only non-connectome features ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=train_weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Your adjusted results\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# [Rest of the code remains the same...]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize Ahmed's models with your requested changes\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=10,  # Changed from 0.02 to 10 for sex model\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=0.02,  # Kept original C value for ADHD\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Cross-validation - now stratifying by Sex_F\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Ahmed Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use full feature set ---\n",
    "    full_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Validation\n",
    "    valid_idx = X_val[target_cols].notna().all(axis=1)\n",
    "    sex_f1 = f1_score(X_val.loc[valid_idx, 'Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(X_val.loc[valid_idx, 'ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "\n",
    "F1s = np.array(F1s)\n",
    "\n",
    "# Adjusted results without Double Harmonic Mean\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s])\n",
    "    # Removed \"Double HMean\"\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "for key in your_results:\n",
    "    if key in ahmed_adjusted_results:\n",
    "        print(\"{:<30} | {:>15.4f} | {:>15.4f}\".format(key, your_results[key], ahmed_adjusted_results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric                         |   Your Approach | Ahmed's Adjusted\n",
      "----------------------------------------------------------------------\n",
      "Sex_F F1                       |          0.7010 |          0.6062\n",
      "ADHD F1                        |          0.8828 |          0.8615\n",
      "Normal Mean                    |          0.7919 |          0.7339\n",
      "HMean of Averages              |          0.7814 |          0.7116\n",
      "Avg of HMeans                  |          0.7812 |          0.7112\n",
      "Double HMean                   |          0.7811 |          0.7110\n"
     ]
    }
   ],
   "source": [
    "# Adding double hmean\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous code remains identical until the results section...]\n",
    "\n",
    "# Your adjusted results - now with teammate's scoring method\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous code remains identical until the results section...]\n",
    "\n",
    "# Ahmed's adjusted results - now with teammate's scoring method\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON (WITH BETTER ORDERING)\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define the preferred order of metrics\n",
    "preferred_order = [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]\n",
    "\n",
    "# Print metrics in the specified order\n",
    "for key in preferred_order:\n",
    "    your_val = your_adjusted_results.get(key, \"-\")\n",
    "    ahmed_val = ahmed_adjusted_results.get(key, \"-\")\n",
    "    \n",
    "    if isinstance(your_val, float):\n",
    "        your_val = f\"{your_val:.4f}\"\n",
    "    if isinstance(ahmed_val, float):\n",
    "        ahmed_val = f\"{ahmed_val:.4f}\"\n",
    "    \n",
    "    print(\"{:<30} | {:>15} | {:>15}\".format(key, your_val, ahmed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "target_cols = ['ADHD_Outcome', 'Sex_F']\n",
    "\n",
    "# Feature selection\n",
    "non_connectome_features = [\n",
    "    feature for feature in train.columns \n",
    "    if 'throw' not in feature and feature not in target_cols\n",
    "]\n",
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# [Previous initialization code remains the same...]\n",
    "\n",
    "# Key fix: Use the same features for stratification as for training\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Cross-validation - stratify on the full features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use ALL features ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use only non-connectome features ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=train_weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Your adjusted results\n",
    "your_adjusted_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(np.column_stack([sex_f1_scores, adhd_f1_scores]), axis=0))\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize Ahmed's models with your requested changes\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=10,  # Changed from 0.02 to 10 for sex model\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=0.02,  # Kept original C value for ADHD\n",
    "    random_state=SEED,\n",
    "    solver='saga', \n",
    "    max_iter=1000,\n",
    "    # Removed class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Cross-validation - now stratifying by Sex_F\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[non_connectome_features], train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} (Ahmed Adjusted) ===\")\n",
    "    \n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model: use full feature set ---\n",
    "    full_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    \n",
    "    # Validation\n",
    "    valid_idx = X_val[target_cols].notna().all(axis=1)\n",
    "    sex_f1 = f1_score(X_val.loc[valid_idx, 'Sex_F'], sex_pred[valid_idx])\n",
    "    adhd_f1 = f1_score(X_val.loc[valid_idx, 'ADHD_Outcome'], adhd_pred[valid_idx])\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    F1s.append([adhd_f1, sex_f1])\n",
    "\n",
    "F1s = np.array(F1s)\n",
    "\n",
    "# Adjusted results without Double Harmonic Mean\n",
    "ahmed_adjusted_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Normal Mean\": np.mean(F1s.mean(axis=0)),\n",
    "    \"HMean of Averages\": hmean(F1s.mean(axis=0)),\n",
    "    \"Avg of HMeans\": np.mean([hmean(fold) for fold in F1s]),\n",
    "    # Teammate's scoring method added:\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# UPDATED COMPARISON (WITH BETTER ORDERING)\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<30} | {:>15} | {:>15}\".format(\"Metric\", \"Your Approach\", \"Ahmed's Adjusted\"))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define the preferred order of metrics\n",
    "preferred_order = [\n",
    "    \"Sex_F F1\",\n",
    "    \"ADHD F1\",\n",
    "    \"Normal Mean\", \n",
    "    \"HMean of Averages\",\n",
    "    \"Avg of HMeans\",\n",
    "    \"Double HMean\"\n",
    "]\n",
    "\n",
    "# Print metrics in the specified order\n",
    "for key in preferred_order:\n",
    "    your_val = your_adjusted_results.get(key, \"-\")\n",
    "    ahmed_val = ahmed_adjusted_results.get(key, \"-\")\n",
    "    \n",
    "    if isinstance(your_val, float):\n",
    "        your_val = f\"{your_val:.4f}\"\n",
    "    if isinstance(ahmed_val, float):\n",
    "        ahmed_val = f\"{ahmed_val:.4f}\"\n",
    "    \n",
    "    print(\"{:<30} | {:>15} | {:>15}\".format(key, your_val, ahmed_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (FIXED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric          |         Your |      Ahmed's\n",
      "---------------------------------------------\n",
      "Sex_F F1        |       0.7010 |       0.7010\n",
      "ADHD F1         |       0.8828 |       0.8828\n",
      "Double HMean    |       0.7811 |       0.7811\n"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - stratify using ALL features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "\n",
    "    # Correct sample weights for validation set\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Double HMean\": hmean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (FIXED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (FIXED) ===\\n\")\n",
    "\n",
    "# Initialize models (same as yours)\n",
    "model_sex_ahmed = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd_ahmed = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - identical splitting\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # Scores\n",
    "    F1s.append([\n",
    "        f1_score(X_val['ADHD_Outcome'], adhd_pred, sample_weight=val_weights),\n",
    "        f1_score(X_val['Sex_F'], sex_pred, sample_weight=val_weights)\n",
    "    ])\n",
    "    \n",
    "\n",
    "F1s = np.array(F1s)\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# FINAL COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<15} | {:>12} | {:>12}\".format(\"Metric\", \"Your\", \"Ahmed's\"))\n",
    "print(\"-\" * 45)\n",
    "for metric in [\"Sex_F F1\", \"ADHD F1\", \"Double HMean\"]:\n",
    "    print(\"{:<15} | {:>12.4f} | {:>12.4f}\".format(\n",
    "        metric, \n",
    "        your_results[metric], \n",
    "        ahmed_results[metric]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing seed to see if CV is overfitting or consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== AHMED'S APPROACH (FIXED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric          |         Your |      Ahmed's\n",
      "---------------------------------------------\n",
      "Sex_F F1        |       0.7088 |       0.7088\n",
      "ADHD F1         |       0.8801 |       0.8801\n",
      "Double HMean    |       0.7848 |       0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n=== FINAL COMPARISON ===\\nMetric          |         Your |      Ahmed's\\n---------------------------------------------\\nSex_F F1        |       0.7010 |       0.7010\\nADHD F1         |       0.8828 |       0.8828\\nDouble HMean    |       0.7811 |       0.7811\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED)\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - stratify using ALL features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_pred = model_sex.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_pred = model_adhd.predict(X_val[non_connectome_features])\n",
    "\n",
    "    # Correct sample weights for validation set\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Double HMean\": hmean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# AHMED'S APPROACH (FIXED)\n",
    "# ========================\n",
    "print(\"\\n=== AHMED'S APPROACH (FIXED) ===\\n\")\n",
    "\n",
    "# Initialize models (same as yours)\n",
    "model_sex_ahmed = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd_ahmed = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Cross-validation - identical splitting\n",
    "F1s = []\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "    sex_pred = model_sex_ahmed.predict(X_val[full_features])\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "    adhd_pred = model_adhd_ahmed.predict(X_val[non_connectome_features])\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # Scores\n",
    "    F1s.append([\n",
    "        f1_score(X_val['ADHD_Outcome'], adhd_pred, sample_weight=val_weights),\n",
    "        f1_score(X_val['Sex_F'], sex_pred, sample_weight=val_weights)\n",
    "    ])\n",
    "    \n",
    "\n",
    "F1s = np.array(F1s)\n",
    "ahmed_results = {\n",
    "    \"Sex_F F1\": F1s[:,1].mean(),\n",
    "    \"ADHD F1\": F1s[:,0].mean(),\n",
    "    \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "}\n",
    "\n",
    "# ========================\n",
    "# FINAL COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<15} | {:>12} | {:>12}\".format(\"Metric\", \"Your\", \"Ahmed's\"))\n",
    "print(\"-\" * 45)\n",
    "for metric in [\"Sex_F F1\", \"ADHD F1\", \"Double HMean\"]:\n",
    "    print(\"{:<15} | {:>12.4f} | {:>12.4f}\".format(\n",
    "        metric, \n",
    "        your_results[metric], \n",
    "        ahmed_results[metric]\n",
    "    ))\n",
    "\n",
    "\"\"\"\n",
    "Normal thresholds: 0.5\n",
    "=== FINAL COMPARISON ===\n",
    "Metric          |         Your |      Ahmed's\n",
    "---------------------------------------------\n",
    "Sex_F F1        |       0.7010 |       0.7010\n",
    "ADHD F1         |       0.8828 |       0.8828\n",
    "Double HMean    |       0.7811 |       0.7811\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Thresholds: 0.3 sex, 0.4 adhd\n",
    "=== FINAL COMPARISON ===\n",
    "Metric          |         Your |      Ahmed's\n",
    "---------------------------------------------\n",
    "Sex_F F1        |       0.7088 |       0.7088\n",
    "ADHD F1         |       0.8801 |       0.8801\n",
    "Double HMean    |       0.7848 |       0.7848\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Threshold: Sex 0.3 all data, ADHD 0.4 only connectome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== YOUR APPROACH (ADJUSTED) ===\n",
      "\n",
      "\n",
      "=== FINAL COMPARISON ===\n",
      "Metric          |       Result \n",
      "---------------------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 2 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[89], line 106\u001b[0m\n",
      "\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m45\u001b[39m)\n",
      "\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSex_F F1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADHD F1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDouble HMean\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{:<15}\u001b[39;49;00m\u001b[38;5;124;43m | \u001b[39;49m\u001b[38;5;132;43;01m{:>12.4f}\u001b[39;49;00m\u001b[38;5;124;43m | \u001b[39;49m\u001b[38;5;132;43;01m{:>12.4f}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n",
      "\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43myour_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ahmed_results[metric]\u001b[39;49;00m\n",
      "\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n",
      "\n",
      "\u001b[1;31mIndexError\u001b[0m: Replacement index 2 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH (ADJUSTED) WITH THRESHOLDS\n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH (ADJUSTED) ===\\n\")\n",
    "\n",
    "SEED = 42\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "model_adhd = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# Thresholds\n",
    "SEX_THRESHOLD = 0.3\n",
    "ADHD_THRESHOLD = 0.4\n",
    "\n",
    "# Cross-validation - stratify using ALL features\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores, sex_f1_scores = [], []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "    # Data prep\n",
    "    X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex, y_val_sex = X_train['Sex_F'], X_val['Sex_F']\n",
    "    y_train_adhd, y_val_adhd = X_train['ADHD_Outcome'], X_val['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    \n",
    "    # --- Sex model (all features) ---\n",
    "    model_sex.fit(X_train[full_features], y_train_sex, sample_weight=weights)\n",
    "    sex_proba = model_sex.predict_proba(X_val[full_features])[:, 1]  # Get probabilities\n",
    "    sex_pred = (sex_proba >= SEX_THRESHOLD).astype(int)  # Apply threshold\n",
    "    \n",
    "    # --- ADHD model (non-connectome only) ---\n",
    "    model_adhd.fit(X_train[non_connectome_features], y_train_adhd, sample_weight=weights)\n",
    "    adhd_proba = model_adhd.predict_proba(X_val[non_connectome_features])[:, 1]  # Get probabilities\n",
    "    adhd_pred = (adhd_proba >= ADHD_THRESHOLD).astype(int)  # Apply threshold\n",
    "\n",
    "    # Validation weights\n",
    "    val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "    # Calculate scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Double HMean\": hmean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n",
    "\n",
    "\n",
    "# # ========================\n",
    "# # AHMED'S APPROACH (FIXED) WITH THRESHOLDS\n",
    "# # ========================\n",
    "# print(\"\\n=== AHMED'S APPROACH (FIXED) ===\\n\")\n",
    "\n",
    "# # Initialize models (same as yours)\n",
    "# model_sex_ahmed = LogisticRegression(penalty='l2', C=10, random_state=SEED, solver='saga', max_iter=1000)\n",
    "# model_adhd_ahmed = LogisticRegression(penalty='l2', C=0.02, random_state=SEED, solver='saga', max_iter=1000)\n",
    "\n",
    "# # Cross-validation - identical splitting\n",
    "# F1s = []\n",
    "# for fold, (train_idx, val_idx) in enumerate(cv.split(train[full_features], train['Sex_F']), 1):\n",
    "#     # Data prep\n",
    "#     X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "#     weights = ((X_train['Sex_F'] == 1) & (X_train['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "    \n",
    "#     # --- Sex model (all features) ---\n",
    "#     model_sex_ahmed.fit(X_train[full_features], X_train['Sex_F'], sample_weight=weights)\n",
    "#     sex_proba = model_sex_ahmed.predict_proba(X_val[full_features])[:, 1]\n",
    "#     sex_pred = (sex_proba >= SEX_THRESHOLD).astype(int)\n",
    "    \n",
    "#     # --- ADHD model (non-connectome only) ---\n",
    "#     model_adhd_ahmed.fit(X_train[non_connectome_features], X_train['ADHD_Outcome'], sample_weight=weights)\n",
    "#     adhd_proba = model_adhd_ahmed.predict_proba(X_val[non_connectome_features])[:, 1]\n",
    "#     adhd_pred = (adhd_proba >= ADHD_THRESHOLD).astype(int)\n",
    "    \n",
    "#     # Validation weights\n",
    "#     val_weights = ((X_val['Sex_F'] == 1) & (X_val['ADHD_Outcome'] == 1)).astype(int) + 1\n",
    "\n",
    "#     # Scores\n",
    "#     F1s.append([\n",
    "#         f1_score(X_val['ADHD_Outcome'], adhd_pred, sample_weight=val_weights),\n",
    "#         f1_score(X_val['Sex_F'], sex_pred, sample_weight=val_weights)\n",
    "#     ])\n",
    "\n",
    "# F1s = np.array(F1s)\n",
    "# ahmed_results = {\n",
    "#     \"Sex_F F1\": F1s[:,1].mean(),\n",
    "#     \"ADHD F1\": F1s[:,0].mean(),\n",
    "#     \"Double HMean\": hmean(hmean(F1s, axis=0))\n",
    "# }\n",
    "\n",
    "# ========================\n",
    "# FINAL COMPARISON\n",
    "# ========================\n",
    "print(\"\\n=== FINAL COMPARISON ===\")\n",
    "print(\"{:<15} | {:>12} \".format(\"Metric\", \"Result\"))\n",
    "# print(\"{:<15} | {:>12} | {:>12}\".format(\"Metric\", \"Your\", \"Ahmed's\"))\n",
    "print(\"-\" * 45)\n",
    "for metric in [\"Sex_F F1\", \"ADHD F1\", \"Double HMean\"]:\n",
    "    print(\"{:<15} | {:>12.4f} | {:>12.4f}\".format(\n",
    "        metric, \n",
    "        your_results[metric]\n",
    "        # ahmed_results[metric]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data including fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH ===\\n\")\n",
    "\n",
    "# Initialize your models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2', C=10, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2', C=0.02, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features for interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\",\n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score',\n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems',\n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex model: use full feature set ---\n",
    "    sex_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex.fit(X_train_full[sex_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_proba_train = model_sex.predict_proba(X_train_full[sex_features])[:, 1]\n",
    "    sex_proba_val = model_sex.predict_proba(X_val_full[sex_features])[:, 1]\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features only ---\n",
    "    X_train_adhd = X_train_full[non_connectome_features].copy()\n",
    "    X_val_adhd = X_val_full[non_connectome_features].copy()\n",
    "    X_train_adhd['sex_proba'] = sex_proba_train\n",
    "    X_val_adhd['sex_proba'] = sex_proba_val\n",
    "\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "    \n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # Predictions\n",
    "    sex_pred = model_sex.predict(X_val_full[sex_features])\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results dictionary stays the same\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7221\n",
      "ADHD_Outcome F1: 0.4551\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.6894\n",
      "ADHD_Outcome F1: 0.4519\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.7251\n",
      "ADHD_Outcome F1: 0.4184\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.6783\n",
      "ADHD_Outcome F1: 0.4771\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.6901\n",
      "ADHD_Outcome F1: 0.4966\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.7010 ± 0.0189\n",
      "Average ADHD F1: 0.4598 ± 0.0263\n",
      "\n",
      "Competition Score (Normal Mean): 0.5804\n",
      "Competition Score (Harmonic Mean of Averages): 0.5554\n",
      "Competition Score (Average of Harmonic Means): 0.5545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Use all features except the target columns\n",
    "    feature_cols = [col for col in train.columns if col not in ['Sex_F', 'ADHD_Outcome']]\n",
    "    X_train = X_train_full[feature_cols].copy()\n",
    "    X_val = X_val_full[feature_cols].copy()\n",
    "\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "=== Fold 1 ===\n",
    "Sex_F F1: 0.7221\n",
    "ADHD_Outcome F1: 0.4551\n",
    "\n",
    "=== Fold 2 ===\n",
    "Sex_F F1: 0.6894\n",
    "ADHD_Outcome F1: 0.4519\n",
    "\n",
    "=== Fold 3 ===\n",
    "Sex_F F1: 0.7251\n",
    "ADHD_Outcome F1: 0.4184\n",
    "\n",
    "=== Fold 4 ===\n",
    "Sex_F F1: 0.6783\n",
    "ADHD_Outcome F1: 0.4771\n",
    "\n",
    "=== Fold 5 ===\n",
    "Sex_F F1: 0.6901\n",
    "ADHD_Outcome F1: 0.4966\n",
    "\n",
    "=== Competition Results ===\n",
    "Average Sex_F F1: 0.7010 ± 0.0189\n",
    "Average ADHD F1: 0.4598 ± 0.0263\n",
    "\n",
    "Competition Score (Normal Mean): 0.5804\n",
    "Competition Score (Harmonic Mean of Averages): 0.5554\n",
    "Competition Score (Average of Harmonic Means): 0.5545\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Submission for Your Approach ===\n",
      "✅ Your approach submission saved\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training for Your Approach ---\n",
    "print(\"\\n=== Creating Submission for Your Approach ===\")\n",
    "\n",
    "# Get all features except targets\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Train sex model on all features\n",
    "model_sex.fit(train[full_features], train['Sex_F'])\n",
    "sex_test_proba = model_sex.predict_proba(test[full_features])[:, 1]\n",
    "\n",
    "# Train ADHD model on non-connectome features only\n",
    "model_adhd.fit(train[non_connectome_features], train['ADHD_Outcome'])\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = model_sex.predict(test[full_features])\n",
    "adhd_pred_test = model_adhd.predict(test[non_connectome_features])\n",
    "\n",
    "# Create submission\n",
    "submission_yours = test.reset_index()[['participant_id']].copy()\n",
    "submission_yours['Sex_F'] = sex_pred_test\n",
    "submission_yours['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save\n",
    "submission_yours.to_csv('YourApproach_Submission.csv', index=False)\n",
    "print(\"✅ Your approach submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Submission for Ahmed's Approach ===\n",
      "✅ Ahmed's approach submission saved\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training for Ahmed's Approach ---\n",
    "print(\"\\n=== Creating Submission for Ahmed's Approach ===\")\n",
    "\n",
    "# Re-initialize models with Ahmed's parameters\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', C=10, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', C=0.02, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "# Train sex model on all features\n",
    "model_sex_ahmed.fit(train[full_features], train['Sex_F'])\n",
    "\n",
    "# Train ADHD model on non-connectome features\n",
    "model_adhd_ahmed.fit(train[non_connectome_features], train['ADHD_Outcome'])\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = model_sex_ahmed.predict(test[full_features])\n",
    "adhd_pred_test = model_adhd_ahmed.predict(test[non_connectome_features])\n",
    "\n",
    "# Create submission\n",
    "submission_ahmed = test.reset_index()[['participant_id']].copy()\n",
    "submission_ahmed['Sex_F'] = sex_pred_test\n",
    "submission_ahmed['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save\n",
    "submission_ahmed.to_csv('AhmedApproach_Submission.csv', index=False)\n",
    "print(\"✅ Ahmed's approach submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importances (Sorted by Coefficient Sign) ===\n",
      "                         feature  coefficient\n",
      "           SDQ_SDQ_Hyperactivity     0.516202\n",
      "           SDQ_SDQ_Externalizing     0.299540\n",
      "       SDQ_SDQ_Generating_Impact     0.267966\n",
      "     SDQ_SDQ_Hyperactivity_x_sex     0.203472\n",
      "      SDQ_SDQ_Difficulties_Total     0.179835\n",
      " SDQ_SDQ_Generating_Impact_x_sex     0.077879\n",
      "                  APQ_P_APQ_P_PM     0.047455\n",
      "               SDQ_SDQ_Prosocial     0.040775\n",
      "         SDQ_SDQ_Prosocial_x_sex     0.027435\n",
      "           SDQ_SDQ_Peer_Problems     0.025528\n",
      "            female_symptom_score     0.012339\n",
      "      female_symptom_score_x_sex    -0.009089\n",
      "      ColorVision_CV_Score_x_sex    -0.015238\n",
      "                 APQ_P_APQ_P_OPD    -0.016949\n",
      "           SDQ_SDQ_Internalizing    -0.018389\n",
      "                  APQ_P_APQ_P_ID    -0.021111\n",
      "     SDQ_SDQ_Internalizing_x_sex    -0.029022\n",
      "                       sex_proba    -0.038428\n",
      "                  APQ_P_APQ_P_PP    -0.038470\n",
      "           APQ_P_APQ_P_INV_x_sex    -0.046142\n",
      "SDQ_SDQ_Emotional_Problems_x_sex    -0.047508\n",
      "            ColorVision_CV_Score    -0.052742\n",
      "      SDQ_SDQ_Emotional_Problems    -0.054403\n",
      "            APQ_P_APQ_P_PP_x_sex    -0.069594\n",
      "                 APQ_P_APQ_P_INV    -0.095372\n",
      "        male_symptom_score_x_sex    -0.102914\n",
      "        SDQ_SDQ_Conduct_Problems    -0.105255\n",
      "                  APQ_P_APQ_P_CP    -0.118671\n",
      "              male_symptom_score    -0.329130\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = X_train_adhd.columns\n",
    "coefficients = model_adhd.coef_[0]\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by coefficient value (descending: positive to negative)\n",
    "importance_df_sorted = importance_df.sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "# Print sorted features\n",
    "print(\"\\n=== Feature Importances (Sorted by Coefficient Sign) ===\")\n",
    "print(importance_df_sorted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submission saved to 'NormalMean6966HMean6503.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training on Full Data ---\n",
    "X_full = train[non_connectome_features].copy()\n",
    "y_sex = train['Sex_F']\n",
    "y_adhd = train['ADHD_Outcome']\n",
    "\n",
    "# Train sex model on full data\n",
    "model_sex.fit(X_full, y_sex)\n",
    "sex_test_proba = model_sex.predict_proba(test[non_connectome_features])[:, 1]\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test[non_connectome_features].copy()\n",
    "X_test['sex_proba'] = sex_test_proba\n",
    "\n",
    "# Add interaction features to test set\n",
    "for col in interaction_features:\n",
    "    if col in X_test.columns:\n",
    "        X_test[f'{col}_x_sex'] = X_test[col] * X_test['sex_proba']\n",
    "\n",
    "# Train ADHD model on full data with interaction features\n",
    "X_full_adhd = X_full.copy()\n",
    "X_full_adhd['sex_proba'] = model_sex.predict_proba(X_full)[:, 1]\n",
    "\n",
    "for col in interaction_features:\n",
    "    if col in X_full_adhd.columns:\n",
    "        X_full_adhd[f'{col}_x_sex'] = X_full_adhd[col] * X_full_adhd['sex_proba']\n",
    "\n",
    "model_adhd.fit(X_full_adhd, y_adhd)\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = np.ones(len(test), dtype=int)\n",
    "adhd_pred_test = model_adhd.predict(X_test)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = test.reset_index()[['participant_id']].copy()\n",
    "submission['Sex_F'] = sex_pred_test\n",
    "submission['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('NormalMean6966HMean6503Sex1.csv', index=False)\n",
    "print(\"\\n✅ Submission saved to 'NormalMean6966HMean6503.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data including fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================\n",
    "# YOUR APPROACH \n",
    "# ========================\n",
    "print(\"\\n=== YOUR APPROACH ===\\n\")\n",
    "\n",
    "# Initialize your models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2', C=10, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2', C=0.02, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features for interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\",\n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score',\n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems',\n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "    \n",
    "    # Weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # --- Sex model: use full feature set ---\n",
    "    sex_features = [col for col in train.columns if col not in target_cols]\n",
    "    model_sex.fit(X_train_full[sex_features], y_train_sex, sample_weight=train_weights)\n",
    "    sex_proba_train = model_sex.predict_proba(X_train_full[sex_features])[:, 1]\n",
    "    sex_proba_val = model_sex.predict_proba(X_val_full[sex_features])[:, 1]\n",
    "    \n",
    "    # --- ADHD model: use non-connectome features only ---\n",
    "    X_train_adhd = X_train_full[non_connectome_features].copy()\n",
    "    X_val_adhd = X_val_full[non_connectome_features].copy()\n",
    "    X_train_adhd['sex_proba'] = sex_proba_train\n",
    "    X_val_adhd['sex_proba'] = sex_proba_val\n",
    "\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "    \n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "    \n",
    "    # Predictions\n",
    "    sex_pred = model_sex.predict(X_val_full[sex_features])\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "    \n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "    \n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "    \n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Results dictionary stays the same\n",
    "your_results = {\n",
    "    \"Sex_F F1\": np.mean(sex_f1_scores),\n",
    "    \"ADHD F1\": np.mean(adhd_f1_scores),\n",
    "    \"Normal Mean\": np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"HMean of Averages\": hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)]),\n",
    "    \"Avg of HMeans\": np.mean([hmean([s, a]) for s, a in zip(sex_f1_scores, adhd_f1_scores)])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Sex_F F1: 0.7221\n",
      "ADHD_Outcome F1: 0.4551\n",
      "\n",
      "=== Fold 2 ===\n",
      "Sex_F F1: 0.6894\n",
      "ADHD_Outcome F1: 0.4519\n",
      "\n",
      "=== Fold 3 ===\n",
      "Sex_F F1: 0.7251\n",
      "ADHD_Outcome F1: 0.4184\n",
      "\n",
      "=== Fold 4 ===\n",
      "Sex_F F1: 0.6783\n",
      "ADHD_Outcome F1: 0.4771\n",
      "\n",
      "=== Fold 5 ===\n",
      "Sex_F F1: 0.6901\n",
      "ADHD_Outcome F1: 0.4966\n",
      "\n",
      "=== Competition Results ===\n",
      "Average Sex_F F1: 0.7010 ± 0.0189\n",
      "Average ADHD F1: 0.4598 ± 0.0263\n",
      "\n",
      "Competition Score (Normal Mean): 0.5804\n",
      "Competition Score (Harmonic Mean of Averages): 0.5554\n",
      "Competition Score (Average of Harmonic Means): 0.5545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.stats import hmean\n",
    "\n",
    "# Constants\n",
    "SEED = 7\n",
    "N_SPLITS = 5\n",
    "\n",
    "\n",
    "# Initialize models\n",
    "model_sex = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=10,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "model_adhd = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=0.02,\n",
    "    random_state=SEED,\n",
    "    solver='saga',\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Score containers\n",
    "adhd_f1_scores = []\n",
    "sex_f1_scores = []\n",
    "\n",
    "# Features used in interaction\n",
    "interaction_features = [\n",
    "    \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_PP\", \"SDQ_SDQ_Hyperactivity\", \n",
    "    \"SDQ_SDQ_Generating_Impact\", 'female_symptom_score', 'male_symptom_score', \n",
    "    'ColorVision_CV_Score', 'SDQ_SDQ_Emotional_Problems', \n",
    "    'SDQ_SDQ_Prosocial', 'SDQ_SDQ_Internalizing'\n",
    "] \n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train, train['Sex_F']), 1):\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "\n",
    "    X_train_full, X_val_full = train.iloc[train_idx], train.iloc[val_idx]\n",
    "    \n",
    "    # Targets\n",
    "    y_train_sex = X_train_full['Sex_F']\n",
    "    y_val_sex = X_val_full['Sex_F']\n",
    "    y_train_adhd = X_train_full['ADHD_Outcome']\n",
    "    y_val_adhd = X_val_full['ADHD_Outcome']\n",
    "\n",
    "    # Sample weights\n",
    "    train_weights = ((y_train_sex == 1) & (y_train_adhd == 1)).astype(int) + 1\n",
    "    val_weights = ((y_val_sex == 1) & (y_val_adhd == 1)).astype(int) + 1\n",
    "\n",
    "    # Use all features except the target columns\n",
    "    feature_cols = [col for col in train.columns if col not in ['Sex_F', 'ADHD_Outcome']]\n",
    "    X_train = X_train_full[feature_cols].copy()\n",
    "    X_val = X_val_full[feature_cols].copy()\n",
    "\n",
    "\n",
    "    # --- Sex Model ---\n",
    "    model_sex.fit(X_train, y_train_sex, sample_weight=train_weights)\n",
    "    sex_train_proba = model_sex.predict_proba(X_train)[:, 1]\n",
    "    sex_val_proba = model_sex.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- ADHD Model ---\n",
    "    X_train_adhd = X_train.copy()\n",
    "    X_val_adhd = X_val.copy()\n",
    "\n",
    "    X_train_adhd['sex_proba'] = sex_train_proba\n",
    "    X_val_adhd['sex_proba'] = sex_val_proba\n",
    "\n",
    "    # Add interaction features\n",
    "    for col in interaction_features:\n",
    "        if col in X_train_adhd.columns:\n",
    "            X_train_adhd[f'{col}_x_sex'] = X_train_adhd[col] * X_train_adhd['sex_proba']\n",
    "            X_val_adhd[f'{col}_x_sex'] = X_val_adhd[col] * X_val_adhd['sex_proba']\n",
    "\n",
    "    model_adhd.fit(X_train_adhd, y_train_adhd, sample_weight=train_weights)\n",
    "\n",
    "    # Predict\n",
    "    sex_pred = model_sex.predict(X_val)\n",
    "    adhd_pred = model_adhd.predict(X_val_adhd)\n",
    "\n",
    "    # Scores\n",
    "    sex_f1 = f1_score(y_val_sex, sex_pred, sample_weight=val_weights)\n",
    "    adhd_f1 = f1_score(y_val_adhd, adhd_pred, sample_weight=val_weights)\n",
    "\n",
    "    print(f\"Sex_F F1: {sex_f1:.4f}\")\n",
    "    print(f\"ADHD_Outcome F1: {adhd_f1:.4f}\")\n",
    "\n",
    "    sex_f1_scores.append(sex_f1)\n",
    "    adhd_f1_scores.append(adhd_f1)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n=== Competition Results ===\")\n",
    "print(f\"Average Sex_F F1: {np.mean(sex_f1_scores):.4f} ± {np.std(sex_f1_scores):.4f}\")\n",
    "print(f\"Average ADHD F1: {np.mean(adhd_f1_scores):.4f} ± {np.std(adhd_f1_scores):.4f}\")\n",
    "\n",
    "# NEW: Calculate harmonic mean per fold first\n",
    "per_fold_hmeans = [hmean([sex, adhd]) for sex, adhd in zip(sex_f1_scores, adhd_f1_scores)]\n",
    "final_score_hmean_foldwise = np.mean(per_fold_hmeans)\n",
    "\n",
    "# Original approach for comparison\n",
    "final_score_mean = np.mean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "final_score_hmean = hmean([np.mean(sex_f1_scores), np.mean(adhd_f1_scores)])\n",
    "\n",
    "print(f\"\\nCompetition Score (Normal Mean): {final_score_mean:.4f}\")\n",
    "print(f\"Competition Score (Harmonic Mean of Averages): {final_score_hmean:.4f}\")\n",
    "print(f\"Competition Score (Average of Harmonic Means): {final_score_hmean_foldwise:.4f}\")  # This is likely what leaderboard uses\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "=== Fold 1 ===\n",
    "Sex_F F1: 0.7221\n",
    "ADHD_Outcome F1: 0.4551\n",
    "\n",
    "=== Fold 2 ===\n",
    "Sex_F F1: 0.6894\n",
    "ADHD_Outcome F1: 0.4519\n",
    "\n",
    "=== Fold 3 ===\n",
    "Sex_F F1: 0.7251\n",
    "ADHD_Outcome F1: 0.4184\n",
    "\n",
    "=== Fold 4 ===\n",
    "Sex_F F1: 0.6783\n",
    "ADHD_Outcome F1: 0.4771\n",
    "\n",
    "=== Fold 5 ===\n",
    "Sex_F F1: 0.6901\n",
    "ADHD_Outcome F1: 0.4966\n",
    "\n",
    "=== Competition Results ===\n",
    "Average Sex_F F1: 0.7010 ± 0.0189\n",
    "Average ADHD F1: 0.4598 ± 0.0263\n",
    "\n",
    "Competition Score (Normal Mean): 0.5804\n",
    "Competition Score (Harmonic Mean of Averages): 0.5554\n",
    "Competition Score (Average of Harmonic Means): 0.5545\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Submission for Your Approach ===\n",
      "✅ Your approach submission saved\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training for Your Approach ---\n",
    "print(\"\\n=== Creating Submission for Your Approach ===\")\n",
    "\n",
    "# Get all features except targets\n",
    "full_features = [col for col in train.columns if col not in target_cols]\n",
    "\n",
    "# Train sex model on all features\n",
    "model_sex.fit(train[full_features], train['Sex_F'])\n",
    "sex_test_proba = model_sex.predict_proba(test[full_features])[:, 1]\n",
    "\n",
    "# Train ADHD model on non-connectome features only\n",
    "model_adhd.fit(train[non_connectome_features], train['ADHD_Outcome'])\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = model_sex.predict(test[full_features])\n",
    "adhd_pred_test = model_adhd.predict(test[non_connectome_features])\n",
    "\n",
    "# Create submission\n",
    "submission_yours = test.reset_index()[['participant_id']].copy()\n",
    "submission_yours['Sex_F'] = sex_pred_test\n",
    "submission_yours['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save\n",
    "submission_yours.to_csv('YourApproach_Submission.csv', index=False)\n",
    "print(\"✅ Your approach submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Submission for Ahmed's Approach ===\n",
      "✅ Ahmed's approach submission saved\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training for Ahmed's Approach ---\n",
    "print(\"\\n=== Creating Submission for Ahmed's Approach ===\")\n",
    "\n",
    "# Re-initialize models with Ahmed's parameters\n",
    "model_sex_ahmed = LogisticRegression(\n",
    "    penalty='l2', C=10, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "model_adhd_ahmed = LogisticRegression(\n",
    "    penalty='l2', C=0.02, random_state=SEED,\n",
    "    solver='saga', max_iter=1000\n",
    ")\n",
    "\n",
    "# Train sex model on all features\n",
    "model_sex_ahmed.fit(train[full_features], train['Sex_F'])\n",
    "\n",
    "# Train ADHD model on non-connectome features\n",
    "model_adhd_ahmed.fit(train[non_connectome_features], train['ADHD_Outcome'])\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = model_sex_ahmed.predict(test[full_features])\n",
    "adhd_pred_test = model_adhd_ahmed.predict(test[non_connectome_features])\n",
    "\n",
    "# Create submission\n",
    "submission_ahmed = test.reset_index()[['participant_id']].copy()\n",
    "submission_ahmed['Sex_F'] = sex_pred_test\n",
    "submission_ahmed['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save\n",
    "submission_ahmed.to_csv('AhmedApproach_Submission.csv', index=False)\n",
    "print(\"✅ Ahmed's approach submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importances (Sorted by Coefficient Sign) ===\n",
      "                         feature  coefficient\n",
      "           SDQ_SDQ_Hyperactivity     0.516202\n",
      "           SDQ_SDQ_Externalizing     0.299540\n",
      "       SDQ_SDQ_Generating_Impact     0.267966\n",
      "     SDQ_SDQ_Hyperactivity_x_sex     0.203472\n",
      "      SDQ_SDQ_Difficulties_Total     0.179835\n",
      " SDQ_SDQ_Generating_Impact_x_sex     0.077879\n",
      "                  APQ_P_APQ_P_PM     0.047455\n",
      "               SDQ_SDQ_Prosocial     0.040775\n",
      "         SDQ_SDQ_Prosocial_x_sex     0.027435\n",
      "           SDQ_SDQ_Peer_Problems     0.025528\n",
      "            female_symptom_score     0.012339\n",
      "      female_symptom_score_x_sex    -0.009089\n",
      "      ColorVision_CV_Score_x_sex    -0.015238\n",
      "                 APQ_P_APQ_P_OPD    -0.016949\n",
      "           SDQ_SDQ_Internalizing    -0.018389\n",
      "                  APQ_P_APQ_P_ID    -0.021111\n",
      "     SDQ_SDQ_Internalizing_x_sex    -0.029022\n",
      "                       sex_proba    -0.038428\n",
      "                  APQ_P_APQ_P_PP    -0.038470\n",
      "           APQ_P_APQ_P_INV_x_sex    -0.046142\n",
      "SDQ_SDQ_Emotional_Problems_x_sex    -0.047508\n",
      "            ColorVision_CV_Score    -0.052742\n",
      "      SDQ_SDQ_Emotional_Problems    -0.054403\n",
      "            APQ_P_APQ_P_PP_x_sex    -0.069594\n",
      "                 APQ_P_APQ_P_INV    -0.095372\n",
      "        male_symptom_score_x_sex    -0.102914\n",
      "        SDQ_SDQ_Conduct_Problems    -0.105255\n",
      "                  APQ_P_APQ_P_CP    -0.118671\n",
      "              male_symptom_score    -0.329130\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get feature names and coefficients\n",
    "feature_names = X_train_adhd.columns\n",
    "coefficients = model_adhd.coef_[0]\n",
    "\n",
    "# Create DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by coefficient value (descending: positive to negative)\n",
    "importance_df_sorted = importance_df.sort_values(by='coefficient', ascending=False)\n",
    "\n",
    "# Print sorted features\n",
    "print(\"\\n=== Feature Importances (Sorted by Coefficient Sign) ===\")\n",
    "print(importance_df_sorted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Submission saved to 'NormalMean6966HMean6503.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- Final Training on Full Data ---\n",
    "X_full = train[non_connectome_features].copy()\n",
    "y_sex = train['Sex_F']\n",
    "y_adhd = train['ADHD_Outcome']\n",
    "\n",
    "# Train sex model on full data\n",
    "model_sex.fit(X_full, y_sex)\n",
    "sex_test_proba = model_sex.predict_proba(test[non_connectome_features])[:, 1]\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test[non_connectome_features].copy()\n",
    "X_test['sex_proba'] = sex_test_proba\n",
    "\n",
    "# Add interaction features to test set\n",
    "for col in interaction_features:\n",
    "    if col in X_test.columns:\n",
    "        X_test[f'{col}_x_sex'] = X_test[col] * X_test['sex_proba']\n",
    "\n",
    "# Train ADHD model on full data with interaction features\n",
    "X_full_adhd = X_full.copy()\n",
    "X_full_adhd['sex_proba'] = model_sex.predict_proba(X_full)[:, 1]\n",
    "\n",
    "for col in interaction_features:\n",
    "    if col in X_full_adhd.columns:\n",
    "        X_full_adhd[f'{col}_x_sex'] = X_full_adhd[col] * X_full_adhd['sex_proba']\n",
    "\n",
    "model_adhd.fit(X_full_adhd, y_adhd)\n",
    "\n",
    "# Make predictions\n",
    "sex_pred_test = np.ones(len(test), dtype=int)\n",
    "adhd_pred_test = model_adhd.predict(X_test)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = test.reset_index()[['participant_id']].copy()\n",
    "submission['Sex_F'] = sex_pred_test\n",
    "submission['ADHD_Outcome'] = adhd_pred_test\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('NormalMean6966HMean6503Sex1.csv', index=False)\n",
    "print(\"\\n✅ Submission saved to 'NormalMean6966HMean6503.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "venv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
